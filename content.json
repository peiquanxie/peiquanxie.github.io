{"meta":{"title":"PQ.XIE BLOG","subtitle":"","description":"个人博客","author":"PQ.XIE","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2023-07-22T02:40:44.436Z","updated":"2023-07-22T02:40:44.436Z","comments":true,"path":"404.html","permalink":"http://example.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2023-07-23T13:55:59.625Z","updated":"2023-07-23T13:55:59.625Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"联系方式邮箱：&#x32;&#49;&#50;&#x39;&#53;&#x31;&#54;&#x39;&#x32;&#x40;&#113;&#113;&#x2e;&#x63;&#111;&#109; 版权声明站点内的所有原创内容（包括但不限于文章、图像等）除特别声明外均采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议，任何人都可以自由传播，但不得用于商用且必须署名并以相同方式分享。本站部分内容转载于网络，有出处的已在文中署名作者并附加原文链接，出处已不可寻的皆已标注来源于网络。若您认为本站点有部分内容侵犯了您的权益，请在电邮告知，我将认真处理。"},{"title":"友情链接","date":"2023-07-23T13:49:37.580Z","updated":"2023-07-23T13:49:37.580Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2023-07-22T02:37:59.687Z","updated":"2023-07-22T02:37:59.687Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2023-07-22T02:37:26.591Z","updated":"2023-07-22T02:37:26.591Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"3-数据准备","slug":"pytorch基础/3-数据准备","date":"2023-07-25T06:38:09.422Z","updated":"2023-07-25T06:38:09.474Z","comments":true,"path":"2023/07/25/pytorch基础/3-数据准备/","link":"","permalink":"http://example.com/2023/07/25/pytorch%E5%9F%BA%E7%A1%80/3-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87/","excerpt":"","text":"1 Dataset1.1 图像（path+label形式）12345678910111213141516171819202122232425import osimport pandas as pdfrom torchvision.io import read_imagefrom torchvision import datasetsfrom torchvision import transformsclass CustomImageDataset(Dataset): def __init__(self, annotations_file, img_dir, transform=None, target_transform=None): self.img_labels = pd.read_csv(annotations_file) self.img_dir = img_dir self.transform = transform self.target_transform = target_transform def __len__(self): return len(self.img_labels) def __getitem__(self, idx): img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]) image = read_image(img_path) label = self.img_labels.iloc[idx, 1] if self.transform: image = self.transform(image) if self.target_transform: label = self.target_transform(label) return image, label 1.2 图像（文件夹名为label 形式）12345data_dir = &#x27;data/hymenoptera_data&#x27;train_datasets = datasets.ImageFolder( os.path.join(data_dir, &quot;train&quot;) ,data_transforms[&quot;train&quot;])val_datasets = datasets.ImageFolder( os.path.join(data_dir, &quot;val&quot;) ,data_transforms[&quot;val&quot;]) 1.3 图像（在线拉取）12345train_data = datasets.MNIST(root=&#x27;data&#x27;, train=True, download=True, transform=data_transforms[&quot;train&quot;], target_transform=xxx) 1.4 图片转换1234567891011121314151617# input变换data_transforms = transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])# RandomResizedCrop: 随机长宽比裁剪# RandomHorizontalFlip: 随机水平翻转# RandomVerticalFlip: 随机垂直翻转# ToTensor: 转换为tensor# Normalize: 像素值进行归一化处理# target 变换# 把整数变成一个one-hot的tensortarget_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float) \\ .scatter_(dim=0, index=torch.tensor(y), value=1)) 2 DataLoader123456train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)for batch, (X, y) in enumerate(train_dataloader): X, y = X.to(device), y.to(device)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"2-tensor基础","slug":"pytorch基础/2-tensor操作","date":"2023-07-24T09:18:03.276Z","updated":"2023-07-25T06:26:52.819Z","comments":true,"path":"2023/07/24/pytorch基础/2-tensor操作/","link":"","permalink":"http://example.com/2023/07/24/pytorch%E5%9F%BA%E7%A1%80/2-tensor%E6%93%8D%E4%BD%9C/","excerpt":"","text":"1 tensor属性1.1 tensor初始化1234shape = (2,3,)rand_tensor = torch.rand(shape)ones_tensor = torch.ones(shape)zeros_tensor = torch.zeros(shape) 1.2 tensor性质1234tensor = torch.rand(3,4)print(f&quot;Shape of tensor: &#123;tensor.shape&#125;&quot;)print(f&quot;Datatype of tensor: &#123;tensor.dtype&#125;&quot;)print(f&quot;Device tensor is stored on: &#123;tensor.device&#125;&quot;) 2 对象转换2.1 list – tensor123456data = [[1, 2], [3, 4]]# list--&gt; tensor# 数据类型是自动推断出来x_tensor = torch.tensor(data)# tensor--&gt; listx_list = x_tensor.tolist() 2.2 numpy – tensor12345np_array = np.array(data)# numpy --&gt; tensorx_tensor = torch.from_numpy(np_array)# tensor --&gt; numpyx_numpy = x_tensor.numpy() 2.3 tensor – tensor12x_ones = torch.ones_like(x_data) # retains the properties of x_datax_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data 3 运算&amp;操作3.1 矩阵乘法1234y1 = tensor @ tensor.Ty2 = tensor.matmul(tensor.T)y3 = torch.rand_like(tensor)torch.matmul(tensor, tensor.T, out=y3) 3.2 矩阵点乘12345z1 = tensor * tensorz2 = tensor.mul(tensor)z3 = torch.rand_like(tensor)torch.mul(tensor, tensor, out=z3) 3.3 矩阵拼接1234# 指定的dim 数量增加，除了dim之外的dim需要相同才行t1 = torch.cat([tensor, tensor, tensor], dim=1)# 两个要进行stack的tensor的dim数量应该相同，stack操作之后得到的结果会多出一维，即dim的数量会+1。t1 = torch.stack([tensor, tensor, tensor], dim=1) 3.4 矩阵升降维123456# 升维。插入指定维度，值为1tensor.unsqueeze(dim=0)# 降维。压缩指定维度，该维度值必须为1# 当dim不指定时，压缩所有维度值为1的维tensor.squeeze(dim=0)tensor.squeeze()","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"1-pytorch快速开始","slug":"pytorch基础/1-pytorch快速开始","date":"2023-07-24T09:15:16.547Z","updated":"2023-07-24T10:01:37.638Z","comments":true,"path":"2023/07/24/pytorch基础/1-pytorch快速开始/","link":"","permalink":"http://example.com/2023/07/24/pytorch%E5%9F%BA%E7%A1%80/1-pytorch%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/","excerpt":"","text":"0 导库123456import torchfrom torch import nnfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision.transforms import ToTensor, Lambda, Composeimport matplotlib.pyplot as plt 1 数据准备torchvision.datasets模块包含了许多真实世界的视觉数据的数据集对象，如CIFAR、COCO。以下通过datasets在线加载FashionMNIST数据集。 123456789101112131415# Download training data from open datasets.training_data = datasets.FashionMNIST( root=&quot;data&quot;, train=True, download=True, transform=ToTensor(),)# Download test data from open datasets.test_data = datasets.FashionMNIST( root=&quot;data&quot;, train=False, download=True, transform=ToTensor(),) 将dataset装载入DataLoader中，DataLoader可认为是一个数据迭代器，其支持数据的自动批处理、采样、洗牌和多进程数据加载。这里定义一个 batch&#x3D;64，即dataloader可迭代的每个元素将返回一个批次，包括64个元素的特征和标签。 123456789batch_size = 64# Create data loaders.train_dataloader = DataLoader(training_data, batch_size=batch_size)test_dataloader = DataLoader(test_data, batch_size=batch_size)for X, y in test_dataloader: print(&quot;Shape of X [N, C, H, W]: &quot;, X.shape) print(&quot;Shape of y: &quot;, y.shape, y.dtype) break 2 创建模型为了在PyTorch中定义一个神经网络，我们创建一个继承自nn.Module的类。我们在__init__函数中定义网络的层，并在forward函数中指定数据将如何通过网络。为了加速神经网络的操作，如果有GPU的话，我们把它移到GPU上。 1234567891011121314151617181920212223# Get cpu or gpu device for training.device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;# Define modelclass NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10) ) def forward(self, x): x = self.flatten(x) logits = self.linear_relu_stack(x) return logitsmodel = NeuralNetwork().to(device)print(model) 3 优化模型参数3.1 模型训练函数12345678910111213141516171819202122loss_fn = nn.CrossEntropyLoss()optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)def train(dataloader, model, loss_fn, optimizer): size = len(dataloader.dataset) model.train() for batch, (X, y) in enumerate(dataloader): X, y = X.to(device), y.to(device) # Compute prediction error pred = model(X) loss = loss_fn(pred, y) # Backpropagation optimizer.zero_grad() loss.backward() optimizer.step() if batch % 100 == 0: loss, current = loss.item(), batch * len(X) print(f&quot;loss: &#123;loss:&gt;7f&#125; [&#123;current:&gt;5d&#125;/&#123;size:&gt;5d&#125;]&quot;) 3.2 模型评估函数1234567891011121314def test(dataloader, model, loss_fn): size = len(dataloader.dataset) num_batches = len(dataloader) model.eval() test_loss, correct = 0, 0 with torch.no_grad(): for X, y in dataloader: X, y = X.to(device), y.to(device) pred = model(X) test_loss += loss_fn(pred, y).item() correct += (pred.argmax(1) == y).type(torch.float).sum().item() test_loss /= num_batches correct /= size print(f&quot;Test Error: \\n Accuracy: &#123;(100*correct):&gt;0.1f&#125;%, Avg loss: &#123;test_loss:&gt;8f&#125; \\n&quot;)1 3.3 启动训练&amp;评估123456epochs = 5for t in range(epochs): print(f&quot;Epoch &#123;t+1&#125;\\n-------------------------------&quot;) train(train_dataloader, model, loss_fn, optimizer) test(test_dataloader, model, loss_fn)print(&quot;Done!&quot;) 4 保存模型12torch.save(model.state_dict(), &quot;model.pth&quot;)print(&quot;Saved PyTorch Model State to model.pth&quot;) 5 加载模型12model = NeuralNetwork()model.load_state_dict(torch.load(&quot;model.pth&quot;)) 6 模型推理12345678910111213141516171819classes = [ &quot;T-shirt/top&quot;, &quot;Trouser&quot;, &quot;Pullover&quot;, &quot;Dress&quot;, &quot;Coat&quot;, &quot;Sandal&quot;, &quot;Shirt&quot;, &quot;Sneaker&quot;, &quot;Bag&quot;, &quot;Ankle boot&quot;,]model.eval()x, y = test_data[0][0], test_data[0][1]with torch.no_grad(): pred = model(x) predicted, actual = classes[pred[0].argmax(0)], classes[y] print(f&#x27;Predicted: &quot;&#123;predicted&#125;&quot;, Actual: &quot;&#123;actual&#125;&quot;&#x27;)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-07-21T10:28:18.087Z","updated":"2023-07-23T10:23:20.541Z","comments":true,"path":"2023/07/21/hello-world/","link":"","permalink":"http://example.com/2023/07/21/hello-world/","excerpt":"","text":"今天坑坑洼洼可算是把网站给搭好了，看着简洁漂亮的首页，想着以后就有专属自己的网站，就很开心。背景图是《权游》里面的某一幕的简画，守夜人面对夜鬼的来袭，背水一战，颇为壮观。 为什么要做个人博客呢？说实话，没有特别的理由。或许是出于新鲜感；或许是工作太无聊；或许是外界太嘈杂，想在数字世界中寻找一片净土；或许是想把有趣的、新奇的东西系统地放进来，有一天可以带朋友来参观，看！这是我曾经的快乐和珍藏。 现实世界有太多约束，说话做事写文章处处存在隐形的规矩，这些规矩容易消磨本身藏在事物的乐趣。我想，在这里就少点规矩吧，说说废话，吹吹牛逼又怎么样呢？有时候写点生活感悟也不怕别人说我假正经。嗯，没错，这是我的展厅！当然，对于涉及实操性或理论性的文章，行文还是遵从逻辑，便于理解和回顾。 那么，第一篇写点啥呢，emmm…","categories":[{"name":"建站","slug":"建站","permalink":"http://example.com/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"建站","slug":"建站","permalink":"http://example.com/tags/%E5%BB%BA%E7%AB%99/"}]}],"categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"},{"name":"建站","slug":"建站","permalink":"http://example.com/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"},{"name":"建站","slug":"建站","permalink":"http://example.com/tags/%E5%BB%BA%E7%AB%99/"}]}