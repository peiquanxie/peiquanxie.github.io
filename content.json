{"meta":{"title":"PQ.XIE BLOG","subtitle":"","description":"个人博客","author":"PQ.XIE","url":"https://xie-peiquan.gitee.io","root":"/"},"pages":[{"title":"","date":"2023-07-22T02:40:44.436Z","updated":"2023-07-22T02:40:44.436Z","comments":true,"path":"404.html","permalink":"https://xie-peiquan.gitee.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2023-09-06T01:59:41.795Z","updated":"2023-09-06T01:59:41.795Z","comments":true,"path":"baidu_verify_codeva-xZof4oMUz5.html","permalink":"https://xie-peiquan.gitee.io/baidu_verify_codeva-xZof4oMUz5.html","excerpt":"","text":"c4b755cea86e877f0ef2d32416419c77"},{"title":"","date":"2023-07-28T09:26:16.461Z","updated":"2023-07-28T09:26:16.461Z","comments":true,"path":"googlef847041eb4e8ca77.html","permalink":"https://xie-peiquan.gitee.io/googlef847041eb4e8ca77.html","excerpt":"","text":"google-site-verification: googlef847041eb4e8ca77.html"},{"title":"","date":"2023-09-19T06:35:33.033Z","updated":"2023-09-19T06:35:33.033Z","comments":false,"path":"about/index.html","permalink":"https://xie-peiquan.gitee.io/about/index.html","excerpt":"","text":"联系方式邮箱：&#x32;&#49;&#x32;&#x39;&#53;&#x31;&#54;&#x39;&#50;&#x40;&#x71;&#x71;&#x2e;&#x63;&#111;&#x6d; 版权声明站点内的所有原创内容（包括但不限于文章、图像等）除特别声明外均采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议，任何人都可以自由传播，但不得用于商用且必须署名并以相同方式分享。 本站部分内容转载于网络，有出处的已在文中署名作者并附加原文链接，出处已不可寻的皆已标注来源于网络。若您认为本站点有部分内容侵犯了您的权益，请在电邮告知，我将认真处理。"},{"title":"所有分类","date":"2023-07-22T02:37:26.591Z","updated":"2023-07-22T02:37:26.591Z","comments":true,"path":"categories/index.html","permalink":"https://xie-peiquan.gitee.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2023-12-07T01:22:32.867Z","updated":"2023-12-07T01:22:32.867Z","comments":true,"path":"friends/index.html","permalink":"https://xie-peiquan.gitee.io/friends/index.html","excerpt":"","text":"Tech Friend kelecnhttps://kelecn.top北辰小栈https://www.mz-zone.cn/恋恋风辰https://llfc.club/ Tool Link 清华源pypi 清华ubuntu源 github代理 volantis插件 google编程规范 boost库指南 docker指南"},{"title":"所有标签","date":"2023-07-22T02:37:59.687Z","updated":"2023-07-22T02:37:59.687Z","comments":true,"path":"tags/index.html","permalink":"https://xie-peiquan.gitee.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"聊点音乐","slug":"音乐/聊点音乐","date":"2024-01-08T16:01:00.418Z","updated":"2024-01-08T16:01:00.514Z","comments":true,"path":"2024/01/09/音乐/聊点音乐/","link":"","permalink":"https://xie-peiquan.gitee.io/2024/01/09/%E9%9F%B3%E4%B9%90/%E8%81%8A%E7%82%B9%E9%9F%B3%E4%B9%90/","excerpt":"","text":"OK，今天不聊技术。技术只是为了谋生，在生存的基础上，艺术&#x2F;哲学或许才是人的最终追求和归宿。当然我没有这么高雅的追求啦，只不过在无聊和闲暇之际找一种寄托罢了。我并没有什么艺术细胞，20多年来似乎也从未真正地钻研过。只不过似乎跟艺术又有说不清道不明的关系，又加上每次稍微置身其中就有莫名感受。所以我想或许我应该记录些什么，也当做在无趣的技术文章中留点有趣的东西。 前面讲到艺术，其实是一个很抽象的概念，我也不晓得怎么去讲明白这个东西。不如直白一点，聊点音乐。最早接触音乐大概是在小时候唱儿歌的时候，那时候还是录音机&#x2F;DVD的时候，大致就是跟着老师一句一句地唱，至于唱了什么，唱的怎么样，我是一点印象都没有。我接受最“专业”的音乐教学大概是在小学吧，至于到了初中、高中，可以说基本上没有音乐这门课，因为似乎音乐老师也不认为这是一门重要的课，常常把音乐课变成电影课或者为主科让道的自习课。因此你若要问我稍微深一点的乐理，我大概是不懂的。等等，高中有音乐老师么。。 说回小学，为什么说小学是我接受最“专业”音乐教学的时候呢，或许还是偶然，我当时4,5年级的班主任是语文兼音乐老师，印象中是一位音乐专业的老师，她教的得很有趣也很专业，那大概是小学里面最放松最有趣的课堂了。课堂上老师会教一些开喉的技巧，一些简谱的发声，吸气停顿，以及一些简单的节拍。虽说只是一些简单的乐理，但对于我来说算是音乐的启蒙了。那时候家里有一个小的电子琴玩具，只有C3到C4的8个音，不过也够我弹《茉莉花》了。有些音不在那个音区，就拿最近的音来凑，感觉也像是那么回事，在那个时候就萌发了一点兴趣。后来我妈似乎看出点什么，在地摊上给我买了一根竖笛，我也只能吹出8个音，不过竖笛可以通过气息吹出悠扬的感觉，一度让我很是沉迷，甚至有些不务正业。那个时候自己写了一本小本子，记录一些老师教的技巧以及能通过8个音吹出来的曲子，中午上学前会经常拿出来吹。那时候感觉像啥，像躺在林荫下吹牧笛的牧童，巴适。事实上这是我上学期间唯一做的一本有关乐曲的笔记，后来没好好保存弄丢了，可惜了。在物质匮乏的年代，总能找些有意思的事情做，没人逼你，没有目标，随心而动。 到后来接触的就是乡里锣鼓班的曲目教学，这是一个不以盈利为目的的春节锣鼓班（当时），每年春节出动一次。演奏前几个月组织乡里的一批人过来学习演奏曲目，有年事已高的老头，也有一窍不通的年轻人。只要你有兴趣，都可以进来学习，有经验老道的老人教着一群小屁孩，不求完美，只图春节有个氛围。我曾经在里面的小房子泡过，大冷天的一到8点听到鼓声就凑过去了。因为对里面的乐器都不懂，我只能听着他们练习。emm，老头吹得潮汕曲目是真好听。后来不知道是什么途径，我妈向锣鼓班借来了一支萧和几首曲目，说可以让我先练习。因为在家没人教，我能吹出来的音并不全，曲子也只是吹了前面几段。其实那个时候如果我能自愿跟着他们学习，学会几首曲子应该是没问题，并且收获肯定也不止是音乐上的。可惜，那个时候我已经上初中了。。那也大概是我上学期间离 学音乐 最近也是最后的一次。 后来接触到流行音乐，同样的沉迷一发不可收拾，把歌词抄到一页纸上，花几个小时学着唱，不感觉到累。这种音乐几乎很近，近到你打开 CCTV3（当时智能手机并未普及，嘿嘿）这个频道就有，但这种音乐又很远，远到你感觉不到它是一种音乐。这种感觉很难说明白，似乎它把我的注意力吸引到歌词和旋律上面，让我像在读一首朗朗上口的诗歌，至于它背后是怎么把这些个音连起来的，谁又明白呢。或许，如果那时候没有那股信息技术大浪潮，我还就真的钻进去了。信息爆炸的时代，会有多少人专情于一件事情、一首歌呢？ 扯远了，直到现在，我的手机里面有上千首歌，几十张歌单，但是时不时能听出莫名感觉的，还是纯音乐。如钢琴、小提琴或者二胡，或者各种管弦乐的合奏，总能听出鸡皮疙瘩的生理反应。也正因为此，在工作后买回来的第一个电子设备，是电子琴。即使工作忙碌、乐理不全、手指不听使唤，但是若能在某个悠闲的周末，弹上一曲，情随琴动，便是感激不已。当然这也只是主观感受，旁人舍友看到可能在想这傻子在弄啥嘞。好了，下面记录一些零碎的记录，不足以称为音乐，某个时间 某个地点 某种情绪的记录罢了。 《问候歌》2021.01 深圳这是一首我经常拿来暖手的曲子，没有什么特别的理由，因为简单。如果非要说理由，那大概也是因为小时候（四年级暑假）在一部台剧中听过这首曲子，男主居然可以用这么简单的曲子打动女主？！，电视里都是骗人的啊呜呜，看过罗志祥的台剧应该对这首曲子有印象。说来也奇怪啊，童年的记忆明明都很潦草，却在某个时刻的点拨变得记忆犹新。 Your browser does not support the audio tag. 《萱草花》2021.04 深圳初次听到这首歌是在《你好，李焕英》这部电影中，一开始是当喜剧来看的，没想到最后贾玲来了段特别煽情的，BGM正是这首。共鸣有时是可怕的，即使是硬汉也挡不住排山倒海的情绪翻涌。印象中那几天是清明，远处山色朦胧，小雨绵延不绝，回想故人往事，心情很难平复，于是有了这首。大致是几个小时弹出来的，略有生疏，但情绪基本在每个音中。致，一直懂我的远方故人。 Your browser does not support the audio tag. 《想见你》2021.01 深圳弹这首是因为那段时间在刷《想见你》这部电视剧，其实我很少看电视剧，但如果看进去便一发不可收拾，会熬夜地看，哪怕第二天顶着黑眼圈在梦里写代(B)码(UG)。看完之后呢还要再过两三天才能从里面出来，这首便是在看完的那两三天弹下的，不完整，心血来潮，有感而发，和弦都没来得及合，见谅🥲。下面是我在网上找到的一张图，这种“莫比乌斯”式的双向穿越在看的时候还感觉蛮有意思的，这不比漫威最近整的什么平行时空来的好看。 Your browser does not support the audio tag. 《菊花台》 2021.02 深圳谁的记忆里没有一首周杰伦呢？因而弹这首的时候没有太多理由，单纯只是想有一首Jay. 当然周杰伦的歌这么多，为什么偏偏是这一首啊。我也不明白，可能这一首比较容易代入吧。《菊花台》总会让我想到《满城尽带黄金甲》结局的时候，元杰兵败被命令伺候母后服药，他无法保护自己的母亲，却也不愿亲手伤害母亲，自刎而尽。这种无助，我能理解。说回曲子，第一次弹这么长的曲子，也没好好练习，一次性弹下来不是很好，Jay粉别骂我。特意截取了一个简短版本，建议戳简短版。 Your browser does not support the audio tag. Your browser does not support the audio tag. 《这世界那么多人》 2021.10 深圳《老男孩弹唱》2023.07 深圳","categories":[{"name":"音乐","slug":"音乐","permalink":"https://xie-peiquan.gitee.io/categories/%E9%9F%B3%E4%B9%90/"}],"tags":[{"name":"聊点音乐","slug":"聊点音乐","permalink":"https://xie-peiquan.gitee.io/tags/%E8%81%8A%E7%82%B9%E9%9F%B3%E4%B9%90/"}]},{"title":"10-让pthread更好用","slug":"并发编程基础/10.让pthread更好用","date":"2023-12-25T12:07:09.874Z","updated":"2023-12-28T03:31:03.484Z","comments":true,"path":"2023/12/25/并发编程基础/10.让pthread更好用/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/12/25/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/10.%E8%AE%A9pthread%E6%9B%B4%E5%A5%BD%E7%94%A8/","excerpt":"","text":"事实上std::thread正是从pthread中继承发展而来的，你可以发现他们的用法几乎一致。由于一些历史原因，可能我们还是得用到pthread线程库。但pthread 有一些用法不太灵活，我们可以稍微对他进行包装，让它更好用。 123456789101112131415161718192021222324252627282930313233#include &lt;pthread.h&gt;#include &lt;functional&gt;#include &lt;iostream&gt;class x_thread &#123;public: typedef std::function&lt;void()&gt; ThreadFunc; explicit x_thread(ThreadFunc func)&#123; _thread_func = func; &#125; ~x_thread()&#123;&#125; void start()&#123; pthread_create(&amp;_thread_id,NULL,&amp;x_thread::run,this); &#125; void join()&#123; pthread_join(_thread_id,nullptr); &#125; void detach()&#123; pthread_detach(_thread_id); &#125;private: static void* run(void* arg)&#123; x_thread* xthread = static_cast&lt;x_thread*&gt;(arg); xthread-&gt;_thread_func(); return nullptr; &#125; private: ThreadFunc _thread_func; pthread_t _thread_id;&#125;; 新增功能： 2023&#x2F;12&#x2F;25：让 pthread 支持接收函数对象。 应用示例：1234567891011121314151617181920212223#include &lt;unistd.h&gt;#include &lt;functional&gt;#include &lt;iostream&gt;class Foo&#123;public: void memfunc(double d,int i,int j)&#123; std::cout&lt;&lt;d&lt;&lt;std::endl; std::cout&lt;&lt;i&lt;&lt;std::endl; std::cout&lt;&lt;j&lt;&lt;std::endl; &#125;&#125;;int main()&#123; Foo foo; //支持回调成员函数 x_thread t1(std::bind(&amp;Foo::memfunc, &amp;foo,0.5, 4, 100)); t1.start(); t1.join(); std::cout&lt;&lt;&quot;program over.&quot;&lt;&lt;std::endl; return 0;&#125;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"8-多线程消息传递","slug":"并发编程基础/8-多线程消息传递","date":"2023-12-25T12:07:06.762Z","updated":"2023-12-28T03:31:56.460Z","comments":true,"path":"2023/12/25/并发编程基础/8-多线程消息传递/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/12/25/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/8-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92/","excerpt":"","text":"1 简单阻塞消息队列12345678910111213141516171819202122232425262728#include &lt;mutex&gt;#include &lt;condition_variable&gt;#include &lt;queue&gt;#include &lt;memory&gt;template&lt;typename T&gt;class msgQueue&#123;public: void push(T const&amp; msg) &#123; std::lock_guard&lt;std::mutex&gt; lk(m); q.push(msg); c.notify_all(); &#125; T wait_and_pop() &#123; std::unique_lock&lt;std::mutex&gt; lk(m); c.wait(lk,[&amp;]&#123;return !q.empty();&#125;); //阻塞等待队列有消息 T res = q.front(); q.pop(); return res; &#125;private: std::mutex m; std::condition_variable c; std::queue&lt;T&gt; q; &#125;; 2 简单阻塞广义队列相信用过python的同学都对python的容器爱不释手，其实c++稍加处理也可以实现像python那样的广义容器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;mutex&gt;#include &lt;condition_variable&gt;#include &lt;queue&gt;#include &lt;memory&gt;namespace messaging&#123; struct message_base ⇽--- ①消息基类。队列中存储的项目 &#123; virtual ~message_base()&#123;&#125; &#125;; template&lt;typename Msg&gt; struct wrapped_message: ⇽--- ②对具体消息的包装 message_base &#123; Msg contents; explicit wrapped_message(Msg const&amp; contents_): contents(contents_)&#123;&#125; &#125;; class msgQueue &#123; public: template&lt;typename T&gt; void push(T const&amp; msg) &#123; std::lock_guard&lt;std::mutex&gt; lk(m); q.push(std::make_shared&lt;wrapped_message&lt;T&gt; &gt;(msg)); ⇽--- ⑤包装发布的消息，并存储相关的指针 c.notify_all(); &#125; std::shared_ptr&lt;message_base&gt; wait_and_pop() &#123; std::unique_lock&lt;std::mutex&gt; lk(m); c.wait(lk,[&amp;]&#123;return !q.empty();&#125;); ⇽--- ⑥如果队列为空，就发生阻塞 auto res=q.front(); q.pop(); return res; &#125; private: std::mutex m; std::condition_variable c; std::queue&lt;std::shared_ptr&lt;message_base&gt; &gt; q; &#125;;&#125;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"2-python调用C","slug":"混合编程/2-python调用C","date":"2023-12-20T06:02:35.192Z","updated":"2023-12-20T06:02:35.240Z","comments":true,"path":"2023/12/20/混合编程/2-python调用C/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/12/20/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/2-python%E8%B0%83%E7%94%A8C/","excerpt":"","text":"python调用C库是一种非常常见的做法，实际上很多python第三方库底层实现就是调用C动态库，以提高执行效率。这也是为什么python被称为“胶水语言”，即便捷地把各种C库粘结在一起。 1 Ctypes方法1.1 C部分注意：如果是C++代码，需要将接口extern “C”{}，告诉编译器按C语言风格来编译接口。 123int mul(int a,int b)&#123; return a*b;&#125; 编译：gcc -fPIC -shared ./c_call_python.c -o demo.so 1.2 python部分1234567import ctypeslib = ctypes.cdll.LoadLibrary(&#x27;./demo.so&#x27;)lib.mul.restype = ctypes.c_inta = ctypes.c_int(12)b = ctypes.c_int(5)print(f&#x27;result: &#123;lib.mul(a,b)&#125;&#x27;) 调用非常简单，其中需要多做的步骤是数据类型转换，这个没办法，C语言是静态类型语言，有明确的类型声明。 2 Boost.Python方法Ctypes的方法能做到C部分无感，但python部分有感，主要由于要做一些数据类型的转换适配。如果你想做到python无感，那么你可以使用Boost.Python的方法，当然代价是C++部分有感，并且要引入整个Boost库。 2.1 简单示例2.1.1 C++部分123456789101112#include &lt;boost/python.hpp&gt;char const* greet()&#123; return &quot;hello, boost&quot;;&#125;BOOST_PYTHON_MODULE(hello)&#123; using namespace boost::python; def(&quot;greet&quot;, greet);&#125; 编译：g++ -fPIC -shared -I /usr/include/python3.9/ hello.cc -o hello.so -lboost_python ，注意：需要提前安装boost.python库。 2.1.2 Python部分123456def test(): import hello return hello.greet()if __name__ == &quot;__main__&quot;: print test() 2.2 复杂示例2.2.1 C++部分123456789101112131415161718192021222324252627282930313233343536#include &lt;boost/python.hpp&gt;#include &lt;vector&gt;#include &lt;string&gt;#include &lt;sstream&gt;using namespace boost::python;struct Person&#123; void set_name(std::string name) &#123; this-&gt;name = name; &#125; std::string print_info(); void set_items(list&amp; prices, list&amp; discounts); std::string name; std::vector&lt;double&gt; item_prices; std::vector&lt;double&gt; item_discounts;&#125;;void Person::set_items(list&amp; prices, list&amp; discounts)&#123; for(int i = 0; i &lt; len(prices); ++i) &#123; //本质上是在C++这里做了类型转换 double price = extract&lt;double&gt;(prices[i]); double discount = extract&lt;double&gt;(discounts[i]); item_prices.push_back(price); item_discounts.push_back(discount); &#125;&#125;BOOST_PYTHON_MODULE(person)&#123; class_&lt;Person&gt;(&quot;Person&quot;) .def(&quot;set_name&quot;, &amp;Person::set_name) .def(&quot;print_info&quot;, &amp;Person::print_info) .def(&quot;set_items&quot;, &amp;Person::set_items) ; &#125; 2.2.2 python部分12345678910def test(): import person p = person.Person() p.set_name(&#x27;Qie&#x27;) p.set_items([100, 123.456, 888.8], [0.3, 0.1, 0.5]) print p.print_info()if __name__ == &quot;__main__&quot;: test()","categories":[{"name":"混合编程","slug":"混合编程","permalink":"https://xie-peiquan.gitee.io/categories/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"混合编程","slug":"混合编程","permalink":"https://xie-peiquan.gitee.io/tags/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"}]},{"title":"1-C调用python","slug":"混合编程/1-C调用python","date":"2023-12-20T03:48:54.670Z","updated":"2023-12-20T03:48:54.726Z","comments":true,"path":"2023/12/20/混合编程/1-C调用python/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/12/20/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/1-C%E8%B0%83%E7%94%A8python/","excerpt":"","text":"1 hello_python将python视为一个第三方库，即可通过python提供的C语言API调用python解释器。简单示例如下： 123456789#include &lt;python3.9/Python.h&gt;int main(int argc, char *argv[])&#123; Py_SetProgramName((wchar_t*)argv[0]); Py_Initialize(); PyRun_SimpleString(&quot;print(&#x27;Hello Python!&#x27;)&quot;); Py_Finalize(); return 0;&#125; 编译： 1gcc -I/usr/include/python3.9 ./c_call_python.c -lpython3.9 如果提示某些python相关头文件找不到，则可能需要安装python-dev版本。 1sudo apt install python3.9-dev 2 调用python模块1234567891011121314151617181920212223242526272829#include &lt;python3.9/Python.h&gt;int python_function_test(int a) &#123; int res; PyObject *pModule,*pFunc; PyObject *pArgs, *pValue; /* import */ PyRun_SimpleString(&quot;import sys&quot;); PyRun_SimpleString(&quot;sys.path.append(&#x27;./&#x27;)&quot;); pModule = PyImport_Import(PyUnicode_FromString(&quot;module_a&quot;)); /* module_a.test_func */ pFunc = PyObject_GetAttrString(pModule, &quot;test_func&quot;); /* build args */ pArgs = PyTuple_New(1); PyTuple_SetItem(pArgs,0, PyLong_FromLong(a)); /* call */ pValue = PyObject_CallObject(pFunc, pArgs); res = PyLong_AsLong(pValue); return res;&#125;int main(int argc, char *argv[])&#123; Py_SetProgramName((wchar_t*)argv[0]); Py_Initialize(); printf(&quot;result: %d\\n&quot;,python_function_test(2)); Py_Finalize(); return 0;&#125; 其中，module_a是python脚本的名字，test_func是脚本中的一个函数。","categories":[{"name":"混合编程","slug":"混合编程","permalink":"https://xie-peiquan.gitee.io/categories/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"混合编程","slug":"混合编程","permalink":"https://xie-peiquan.gitee.io/tags/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"}]},{"title":"7-设计并发代码","slug":"并发编程基础/7-设计并发代码","date":"2023-12-10T09:04:49.532Z","updated":"2023-12-28T03:30:49.932Z","comments":true,"path":"2023/12/10/并发编程基础/7-设计并发代码/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/12/10/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/7-%E8%AE%BE%E8%AE%A1%E5%B9%B6%E5%8F%91%E4%BB%A3%E7%A0%81/","excerpt":"","text":"设计并发代码时需考虑两个层面：线程安全 和 并发性能。 1 线程划分1.1 数据简单切分考虑将将一片较大的数据切分为若干块给各线程执行，最后按串行的方式执行规约操作。简单例子如下： 1234567891011121314151617181920212223242526272829303132333435363738394041template&lt;typename Iterator,typename T&gt;struct accumulate_block&#123; void operator()(Iterator first,Iterator last,T&amp; result) &#123; result=std::accumulate(first,last,result); &#125;&#125;;template&lt;typename Iterator,typename T&gt;T parallel_accumulate(Iterator first,Iterator last,T init)&#123; unsigned long const length=std::distance(first,last); if(!length) return init; ⇽--- ① unsigned long const min_per_thread=25; unsigned long const max_threads= (length+min_per_thread-1)/min_per_thread; ⇽--- ② unsigned long const hardware_threads= std::thread::hardware_concurrency(); unsigned long const num_threads= std::min(hardware_threads!=0?hardware_threads:2,max_threads); ⇽--- ③ unsigned long const block_size=length/num_threads; ⇽--- ④ std::vector&lt;T&gt; results(num_threads); std::vector&lt;std::thread&gt; threads(num_threads-1); ⇽--- ⑤ Iterator block_start=first; for(unsigned long i=0;i&lt;(num_threads-1);++i) &#123; Iterator block_end=block_start; std::advance(block_end,block_size); ⇽--- ⑥ threads[i]=std::thread( ⇽--- ⑦ accumulate_block&lt;Iterator,T&gt;(), block_start,block_end,std::ref(results[i])); block_start=block_end; ⇽--- ⑧ &#125; accumulate_block&lt;Iterator,T&gt;()( block_start,last,results[num_threads-1]); ⇽--- ⑨ for(auto&amp; entry: threads) entry.join(); ⇽--- ⑩ return std::accumulate(results.begin(),results.end(),init); ⇽--- ⑪&#125; 1.2 数据递归划分以快排算法为例，数据无法一开始就划分好，因为只有经过处理后，才会清楚它会归入到哪个部分。并行化这个算法需要利用递归来进行划分。 1234567891011121314151617181920212223template&lt;typename T&gt;std::list&lt;T&gt; parallel_quick_sort(std::list&lt;T&gt; input)&#123; if(input.empty()) &#123; return input; &#125; std::list&lt;T&gt; result; result.splice(result.begin(),input,input.begin()); T const&amp; pivot=*result.begin(); auto divide_point=std::partition(input.begin(),input.end(), [&amp;](T const&amp; t)&#123;return t&lt;pivot;&#125;); std::list&lt;T&gt; lower_part; lower_part.splice(lower_part.end(),input,input.begin(), divide_point); std::future&lt;std::list&lt;T&gt;&gt; new_lower( ⇽--- ① std::async(&amp;parallel_quick_sort&lt;T&gt;,std::move(lower_part))); auto new_higher( parallel_quick_sort(std::move(input))); ⇽--- ② result.splice(result.end(),new_higher); ⇽--- ③ result.splice(result.begin(),new_lower.get()); ⇽--- ④ return result;&#125; 以上代码随着每一层递归的深入，都借助std::async()生成新的异步任务处理前半部分数据，这样可以让左右两部分的数据并行排序起来。这里用到std::async()其实是让C++线程库自主决定，是否新起线程来运行新数据。快排不可能让所有的数据块排序并行起来，因为太多的线程反而让程序变慢，且消耗资源。 1.3 任务切分将串行的任务切块，让块并行，块与块之间通过队列等管道传输数据。即流水线模式。 2 影响并发性能的因素2.1 处理器数量处理器数量可谓是首要且关键的因素。当需同时运行的线程超过处理器实际能并行的线程数，各线程就会发生切换，导致浪费处理器时间，此称为线程过饱和。C++标准库提供了std::thread::hardware_concurrency()来查询硬件能并行的线程数，应用程序可以依此缩放实际执行任务的线程数量。 2.2 数据竞争&amp;缓存乒乓如果两个线程在不同的处理器上并行并共享数据，数据实际上会复制到两个处理器上的缓存中。如果其中一个线程改动了数据，变化必须传导至另一个处理器的缓存中，这之间可能导致另一个处理器半途暂停，以等待硬件变化。可怕的是，这种处理器暂停会让其他无关的线程也随着暂停。以以下代码为例： 12345678std::atomic&lt;unsigned long&gt; counter(0);void processing_loop()&#123; while(counter.fetch_add(1,std::memory_order_relaxed)&lt;100000000) &#123; do_something(); &#125;&#125; 当处理器执行原子变量的自增操作时，必须先确保自身缓存载入了变量的最新副本，然后再改变它的值，再通知其他处理器。这样，当do_something()函数足够短时，大量线程会阻塞在原子变量的更改处，且处理器缓存会发生多次的同步。由于原子变量的值在不同处理器缓存之间多次来回传递，因此称缓存乒乓。 互斥锁同样也会导致缓存乒乓，但其与原子争夺稍有不同。因为互斥锁是在操作系统层面的，不直接插手到处理器层面。 2.3 不经意共享你以为所有线程不共享数据就不会产生缓存乒乓的问题吗？NO! (好难啊)。 缓存是一块一块读取的，也就是说，当你读取自己线程所属的数据，有可能不经意把别人的数据也读取进来，这个时候相当于不经意共享。这里的解决方法是编排数据布局，不同线程的数据在内存中彼此隔离，减少不经意共享。 2.4 线程过饱和若线程数目过多，超过硬件可并行数，操作系统也会随之开始剧烈地切换任务，以公平分摊时间片。若数据分布不够紧凑，还会导致缓存问题，这两个问题叠加会导致严重后果。 3 线程异常保护当不对并发线程的异常进行处理，线程对象会通过析构函数调用std::terminate() 从而终结整个应用程序。 以下提供并行代码进行分析： 1234567891011121314151617181920212223242526272829303132333435363738394041template&lt;typename Iterator,typename T&gt;struct accumulate_block&#123; void operator()(Iterator first,Iterator last,T&amp; result) &#123; result=std::accumulate(first,last,result); ⇽--- ① &#125;&#125;;template&lt;typename Iterator,typename T&gt;T parallel_accumulate(Iterator first,Iterator last,T init)&#123; unsigned long const length=std::distance(first,last); ⇽--- ② if(!length) return init; unsigned long const min_per_thread=25; unsigned long const max_threads= (length+min_per_thread-1)/min_per_thread; unsigned long const hardware_threads= std::thread::hardware_concurrency(); unsigned long const num_threads= std::min(hardware_threads!=0?hardware_threads:2,max_threads); unsigned long const block_size=length/num_threads; std::vector&lt;T&gt; results(num_threads); ⇽--- ③ std::vector&lt;std::thread&gt; threads(num_threads-1); ⇽--- ④ Iterator block_start=first; ⇽--- ⑤ for(unsigned long i=0;i&lt;(num_threads-1);++i) &#123; Iterator block_end=block_start; ⇽--- ⑥ std::advance(block_end,block_size); threads[i]=std::thread( ⇽--- ⑦ accumulate_block&lt;Iterator,T&gt;(), block_start,block_end,std::ref(results[i])); block_start=block_end; ⇽--- ⑧ &#125; accumulate_block&lt;Iterator,T&gt;()( block_start,last,results[num_threads-1]); ⇽--- ⑨ std::for_each(threads.begin(),threads.end(), std::mem_fn(&amp;std::thread::join)); return std::accumulate(results.begin(),results.end(),init); ⇽--- ⑩&#125; 以上，新线程发起的 accumulate_block 块，此处没有任何的catch块，故代码不会处理产生的异常，结果令线程库调用 std::terminate()而终止整个应用程序。 3.1 加入异常安全以上代码，我们希望新起线程能抛出异常，并被父线程所捕获。我们借助 std::packaged_task 和 std::future 即可实现。以下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546template&lt;typename Iterator,typename T&gt;struct accumulate_block&#123; T operator()(Iterator first,Iterator last) ⇽--- ① &#123; return std::accumulate(first,last,T()); ⇽--- ② &#125;&#125;;template&lt;typename Iterator,typename T&gt;T parallel_accumulate(Iterator first,Iterator last,T init)&#123; unsigned long const length=std::distance(first,last); if(!length) return init; unsigned long const min_per_thread=25; unsigned long const max_threads= (length+min_per_thread-1)/min_per_thread; unsigned long const hardware_threads= std::thread::hardware_concurrency(); unsigned long const num_threads= std::min(hardware_threads!=0?hardware_threads:2,max_threads); unsigned long const block_size=length/num_threads; std::vector&lt;std::future&lt;T&gt; &gt; futures(num_threads-1); ⇽--- ③ std::vector&lt;std::thread&gt; threads(num_threads-1); Iterator block_start=first; for(unsigned long i=0;i&lt;(num_threads-1);++i) &#123; Iterator block_end=block_start; std::advance(block_end,block_size); std::packaged_task&lt;T(Iterator,Iterator)&gt; task( ⇽--- ④ accumulate_block&lt;Iterator,T&gt;()); futures[i]=task.get_future(); ⇽--- ⑤ threads[i]=std::thread(std::move(task),block_start,block_end); ⇽--- ⑥ block_start=block_end; &#125; T last_result=accumulate_block&lt;Iterator,T&gt;()(block_start,last); ⇽--- ⑦ std::for_each(threads.begin(),threads.end(), std::mem_fn(&amp;std::thread::join)); T result=init; ⇽--- ⑧ for(unsigned long i=0;i&lt;(num_threads-1);++i) &#123; result+=futures[i].get(); ⇽--- ⑨ &#125; result += last_result; ⇽--- ⑩ return result;&#125; 变化点： accumulate_block 直接返回值给 std::future. 用vector容器来存储 futrue对象，并用 std::packaged_task 打包任务。这样任务运行的最终结果会返回给future，如果出现异常，也会被future捕获。 最后线程汇合，利用futrue.get()获取计算的返回值并求和。如果线程抛出异常，那么此处调用get会再次抛出异常。 以上代码还有另一个问题，若有线程异常退出，则会导致线程泄漏。我们可以设计一个RAII形式的线程回收类避免这个问题。以下： 12345678910111213141516class join_threads&#123; std::vector&lt;std::thread&gt;&amp; threads;public: explicit join_threads(std::vector&lt;std::thread&gt;&amp; threads_): threads(threads_) &#123;&#125; ~join_threads() &#123; for(unsigned long i=0;i&lt;threads.size();++i) &#123; if(threads[i].joinable()) threads[i].join(); &#125; &#125;&#125;; 3.2 std::async的线程安全std::async()会让线程库替我们管控线程，线程一旦完成，对应的future就会进入就绪状态。如果不等future进入就绪状态就将其销毁，future对象的析构函数仍然会等待其线程运行结束。体现在，当父线程捕获到某一子线程的异常并准备向上抛时，也会等待其他子线程完成，以防止悬空线程。 4 线程可伸缩性程序是由串行片段和并行片段共同构成的。如果串行片段所占总体程序的比例是fs，那么N个处理器所取得的整体性能增益P是： $$Amdahl定律 ：P&#x3D;\\frac{1}{f_s + \\frac{1-f_s}{N}}$$ 若串行片段 fs 为0，则加速比为N；若串行片段为1&#x2F;3，则加速比不可能超过3. 5 并行代码实践5.1 std::for_each 并行版本12345678910111213141516171819202122232425262728293031323334353637template&lt;typename Iterator,typename Func&gt;void parallel_for_each(Iterator first,Iterator last,Func f)&#123; unsigned long const length=std::distance(first,last); if(!length) return; unsigned long const min_per_thread=25; unsigned long const max_threads= (length+min_per_thread-1)/min_per_thread; unsigned long const hardware_threads= std::thread::hardware_concurrency(); unsigned long const num_threads= std::min(hardware_threads!=0?hardware_threads:2,max_threads); unsigned long const block_size=length/num_threads; std::vector&lt;std::future&lt;void&gt;&gt; futures(num_threads-1); ⇽--- ① std::vector&lt;std::thread&gt; threads(num_threads-1); join_threads joiner(threads); Iterator block_start=first; for(unsigned long i=0;i&lt;(num_threads-1);++i) &#123; Iterator block_end=block_start; std::advance(block_end,block_size); std::packaged_task&lt;void(void)&gt; task( ⇽--- ② [=]() &#123; std::for_each(block_start,block_end,f); &#125;); futures[i]=task.get_future(); threads[i]=std::thread(std::move(task)); ⇽--- ③ block_start=block_end; &#125; std::for_each(block_start,last,f); for(unsigned long i=0;i&lt;(num_threads-1);++i) &#123; futures[i].get(); ⇽--- ④ &#125;&#125; 由于以上工作线程没有返回值，因此future.get()调用的意义在于提供一种捕获异常的方法。若不想传递异常，亦可以忽略这一操作。 5.2 std::async() 递归版本123456789101112131415161718192021template&lt;typename Iterator,typename Func&gt;void parallel_for_each(Iterator first,Iterator last,Func f)&#123; unsigned long const length=std::distance(first,last); if(!length) return; unsigned long const min_per_thread=25; if(length&lt;(2*min_per_thread)) &#123; std::for_each(first,last,f); ⇽--- ① &#125; else &#123; Iterator const mid_point=first+length/2; std::future&lt;void&gt; first_half= ⇽--- ② std::async(&amp;parallel_for_each&lt;Iterator,Func&gt;, first,mid_point,f); parallel_for_each(mid_point,last,f); ⇽--- ③ first_half.get(); ⇽--- ④ &#125;&#125; 5.3 std::find并行版本对于find这类任务，他的特点就是尽早地完成任务，这可以避免浪费资源和时间。若某一线程找到目标元素，如何中断其他线程呢？可以将一原子变量作为标志，每处理一次元素就查验一次该标志。如果这个标志被置为成立，则表明某个线程已找到匹配的元素。这种并行的代价是要反复查验原子变量。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768template&lt;typename Iterator,typename MatchType&gt;Iterator parallel_find(Iterator first,Iterator last,MatchType match)&#123; struct find_element ⇽--- ① &#123; void operator()(Iterator begin,Iterator end, MatchType match, std::promise&lt;Iterator&gt;* result, std::atomic&lt;bool&gt;* done_flag) &#123; try &#123; for(;(begin!=end) &amp;&amp; !done_flag-&gt;load();++begin) ⇽--- ② &#123; if(*begin==match) &#123; result-&gt;set_value(begin); ⇽--- ③ done_flag-&gt;store(true); ⇽--- ④ return; &#125; &#125; &#125; catch(...) ⇽--- ⑤ &#123; try &#123; result-&gt;set_exception(std::current_exception()); ⇽--- ⑥ done_flag-&gt;store(true); &#125; catch(...) ⇽--- ⑦ &#123;&#125; &#125; &#125; &#125;; unsigned long const length=std::distance(first,last); if(!length) return last; unsigned long const min_per_thread=25; unsigned long const max_threads= (length+min_per_thread-1)/min_per_thread; unsigned long const hardware_threads= std::thread::hardware_concurrency(); unsigned long const num_threads= std::min(hardware_threads!=0?hardware_threads:2,max_threads); unsigned long const block_size=length/num_threads; std::promise&lt;Iterator&gt; result; ⇽--- ⑧ std::atomic&lt;bool&gt; done_flag(false); ⇽--- ⑨ std::vector&lt;std::thread&gt; threads(num_threads-1); &#123; ⇽--- ⑩ join_threads joiner(threads); Iterator block_start=first; for(unsigned long i=0;i&lt;(num_threads-1);++i) &#123; Iterator block_end=block_start; std::advance(block_end,block_size); threads[i]=std::thread(find_element(), ⇽--- ⑪ block_start,block_end,match, &amp;result,&amp;done_flag); block_start=block_end; &#125; find_element()(block_start,last,match,&amp;result,&amp;done_flag); ⇽--- ⑫ &#125; if(!done_flag.load()) ⇽--- ⑬ &#123; return last; &#125; return result.get_future().get(); ⇽--- ⑭&#125;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"5-基于锁的数据结构","slug":"并发编程基础/5-基于锁的数据结构","date":"2023-12-10T09:04:46.872Z","updated":"2023-12-28T03:31:38.376Z","comments":true,"path":"2023/12/10/并发编程基础/5-基于锁的数据结构/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/12/10/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/5-%E5%9F%BA%E4%BA%8E%E9%94%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"1 线程安全栈基于互斥锁实现，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;exception&gt;struct empty_stack: std::exception&#123; const char* what() const throw();&#125;;template&lt;typename T&gt;class threadsafe_stack&#123;private: std::stack&lt;T&gt; data; mutable std::mutex m;public: threadsafe_stack()&#123;&#125; threadsafe_stack(const threadsafe_stack&amp; other) &#123; std::lock_guard&lt;std::mutex&gt; lock(other.m); data=other.data; &#125; threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); data.push(std::move(new_value)); ⇽--- ① &#125; std::shared_ptr&lt;T&gt; pop() &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); ⇽--- ② std::shared_ptr&lt;T&gt; const res( std::make_shared&lt;T&gt;(std::move(data.top()))); ⇽--- ③ data.pop(); ⇽--- ④ return res; &#125; void pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); value=std::move(data.top()); ⇽--- ⑤ data.pop(); ⇽--- ⑥ &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lock(m); return data.empty(); &#125;&#125;; 2 线程安全队列基于锁和条件变量实现，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657template&lt;typename T&gt;class threadsafe_queue&#123;private: mutable std::mutex mut; std::queue&lt;T&gt; data_queue; std::condition_variable data_cond;public: threadsafe_queue() &#123;&#125; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); data_queue.push(std::move(new_value)); data_cond.notify_one(); ⇽--- ① &#125; void wait_and_pop(T&amp; value) ⇽--- ② &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); value=std::move(data_queue.front()); data_queue.pop(); &#125; std::shared_ptr&lt;T&gt; wait_and_pop() ⇽--- ③ &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); ⇽--- ④ std::shared_ptr&lt;T&gt; res( std::make_shared&lt;T&gt;(std::move(data_queue.front()))); data_queue.pop(); return res; &#125; bool try_pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); if(data_queue.empty()) return false; value=std::move(data_queue.front()); data_queue.pop(); return true; &#125; std::shared_ptr&lt;T&gt; try_pop() &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); if(data_queue.empty()) return std::shared_ptr&lt;T&gt;(); ⇽--- ⑤ std::shared_ptr&lt;T&gt; res( std::make_shared&lt;T&gt;(std::move(data_queue.front()))); data_queue.pop(); return res; &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); return data_queue.empty(); &#125;&#125;; 3 线程安全map123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#include &lt;vector&gt;#include &lt;memory&gt;#include &lt;mutex&gt;#include &lt;functional&gt;#include &lt;list&gt;#include &lt;utility&gt;#include &lt;boost/thread/shared_mutex.hpp&gt;template&lt;typename Key,typename Value,typename Hash=std::hash&lt;Key&gt; &gt;class threadsafe_lookup_table&#123;private: class bucket_type &#123; private: typedef std::pair&lt;Key,Value&gt; bucket_value; typedef std::list&lt;bucket_value&gt; bucket_data; typedef typename bucket_data::iterator bucket_iterator; bucket_data data; mutable boost::shared_mutex mutex; bucket_iterator find_entry_for(Key const&amp; key) const &#123; return std::find_if(data.begin(),data.end(), [&amp;](bucket_value const&amp; item) &#123;return item.first==key;&#125;); &#125; public: Value value_for(Key const&amp; key,Value const&amp; default_value) const &#123; boost::shared_lock&lt;boost::shared_mutex&gt; lock(mutex); bucket_iterator const found_entry=find_entry_for(key); return (found_entry==data.end())? default_value : found_entry-&gt;second; &#125; void add_or_update_mapping(Key const&amp; key,Value const&amp; value) &#123; std::unique_lock&lt;boost::shared_mutex&gt; lock(mutex); bucket_iterator const found_entry=find_entry_for(key); if(found_entry==data.end()) &#123; data.push_back(bucket_value(key,value)); &#125; else &#123; found_entry-&gt;second=value; &#125; &#125; void remove_mapping(Key const&amp; key) &#123; std::unique_lock&lt;boost::shared_mutex&gt; lock(mutex); bucket_iterator const found_entry=find_entry_for(key); if(found_entry!=data.end()) &#123; data.erase(found_entry); &#125; &#125; &#125;; std::vector&lt;std::unique_ptr&lt;bucket_type&gt; &gt; buckets; Hash hasher; bucket_type&amp; get_bucket(Key const&amp; key) const &#123; std::size_t const bucket_index=hasher(key)%buckets.size(); return *buckets[bucket_index]; &#125;public: typedef Key key_type; typedef Value mapped_type; typedef Hash hash_type; threadsafe_lookup_table( unsigned num_buckets=19, Hash const&amp; hasher_=Hash()): buckets(num_buckets),hasher(hasher_) &#123; for(unsigned i=0;i&lt;num_buckets;++i) &#123; buckets[i].reset(new bucket_type); &#125; &#125; threadsafe_lookup_table(threadsafe_lookup_table const&amp; other)=delete; threadsafe_lookup_table&amp; operator=( threadsafe_lookup_table const&amp; other)=delete; Value value_for(Key const&amp; key, Value const&amp; default_value=Value()) const &#123; return get_bucket(key).value_for(key,default_value); &#125; void add_or_update_mapping(Key const&amp; key,Value const&amp; value) &#123; get_bucket(key).add_or_update_mapping(key,value); &#125; void remove_mapping(Key const&amp; key) &#123; get_bucket(key).remove_mapping(key); &#125; std::map&lt;Key,Value&gt; get_map() const &#123; std::vector&lt;std::unique_lock&lt;boost::shared_mutex&gt; &gt; locks; for(unsigned i=0;i&lt;buckets.size();++i) &#123; locks.push_back( std::unique_lock&lt;boost::shared_mutex&gt;(buckets[i].mutex)); &#125; std::map&lt;Key,Value&gt; res; for(unsigned i=0;i&lt;buckets.size();++i) &#123; for(bucket_iterator it=buckets[i].data.begin(); it!=buckets[i].data.end(); ++it) &#123; res.insert(*it); &#125; &#125; return res; &#125;&#125;; 4 线程安全链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687template&lt;typename T&gt;class threadsafe_list&#123; struct node ⇽--- ① &#123; std::mutex m; std::shared_ptr&lt;T&gt; data; std::unique_ptr&lt;node&gt; next; node(): ⇽--- ② next() &#123;&#125; node(T const&amp; value): ⇽--- ③ data(std::make_shared&lt;T&gt;(value)) &#123;&#125; &#125;; node head;public: threadsafe_list() &#123;&#125; ~threadsafe_list() &#123; remove_if([](node const&amp;)&#123;return true;&#125;); &#125; threadsafe_list(threadsafe_list const&amp; other)=delete; threadsafe_list&amp; operator=(threadsafe_list const&amp; other)=delete; void push_front(T const&amp; value) &#123; std::unique_ptr&lt;node&gt; new_node(new node(value)); ⇽--- ④ std::lock_guard&lt;std::mutex&gt; lk(head.m); new_node-&gt;next=std::move(head.next); ⇽--- ⑤ head.next=std::move(new_node); ⇽--- ⑥ &#125; template&lt;typename Function&gt; void for_each(Function f) ⇽--- ⑦ &#123; node* current=&amp;head; std::unique_lock&lt;std::mutex&gt; lk(head.m); ⇽--- ⑧ while(node* const next=current-&gt;next.get()) ⇽--- ⑨ &#123; std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m); ⇽--- ⑩ lk.unlock(); ⇽--- ⑪ f(*next-&gt;data); ⇽--- ⑫ current=next; lk=std::move(next_lk); ⇽--- ⑬ &#125; &#125; template&lt;typename Predicate&gt; std::shared_ptr&lt;T&gt; find_first_if(Predicate p) ⇽--- ⑭ &#123; node* current=&amp;head; std::unique_lock&lt;std::mutex&gt; lk(head.m); while(node* const next=current-&gt;next.get()) &#123; std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m); lk.unlock(); if(p(*next-&gt;data)) ⇽--- ⑮ &#123; return next-&gt;data; ⇽--- ⑯ &#125; current=next; lk=std::move(next_lk); &#125; return std::shared_ptr&lt;T&gt;(); &#125; template&lt;typename Predicate&gt; void remove_if(Predicate p) ⇽--- ⑰ &#123; node* current=&amp;head; std::unique_lock&lt;std::mutex&gt; lk(head.m); while(node* const next=current-&gt;next.get()) &#123; std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m); if(p(*next-&gt;data)) ⇽--- ⑱ &#123; std::unique_ptr&lt;node&gt; old_next=std::move(current-&gt;next); current-&gt;next=std::move(next-&gt;next); ⇽--- ⑲ next_lk.unlock(); &#125; ⇽--- ⑳ else &#123; lk.unlock(); ⇽--- ㉑ current=next; lk=std::move(next_lk); &#125; &#125; &#125;&#125;;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"4-原子操作","slug":"并发编程基础/4-原子操作","date":"2023-12-10T09:04:43.408Z","updated":"2023-12-28T03:30:35.952Z","comments":true,"path":"2023/12/10/并发编程基础/4-原子操作/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/12/10/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/4-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/","excerpt":"","text":"1 原子操作原子操作是不可分割的操作，对于操作共享数据之外的其他线程，观察到这种操作要么完全做好，要么完全没做，不会处于半完成状态。 2 原子类型标准原子类型的定义位于头文件 &lt;atomic&gt;内，这些类型全都是原子化的。我们可以通过 atomic&lt;T&gt;定义原子类型的变量，如 atomic&lt;bool&gt;,atomic&lt;int&gt; 这些都是原子类型。原子类型的出现是为了取代共享数据的互斥的同步方式，若原子类型是无锁实现，会带来一定的性能提升，以及让代码更加直观可靠。 从C++17开始，所有的原子类型都包含一个静态成员变量，std::atomic::is_always_lock_free。这个成员变量的值表示在任意给定的目标硬件上，原子类型X是否始终以无锁结构形式实现。如果在所有支持该程序运行的硬件上，原子类型X都以无锁结构形式实现，那么这个成员变量的值就为true；否则为false。 2.1 atomic_flagatomic_flag 是一个简单的布尔类型，它一定是无锁操作，因而不提供 is_lock_free()成员函数 。atomic_flag的对象在初始化时清零，随后即可通过成员函数 test_and_set()查值并设置成立，或者由 clear()清零。整个过程只有这两个操作。其他的 atomic&lt;&gt;的原子类型都可以基于其实现。 test_and_set成员函数是一个原子操作，他会先检查 std::atomic_flag当前的状态是否被设置过： 如果没被设置过(比如初始状态或者清除后)，将 std::atomic_flag当前的状态设置为 true，并返回 false。 如果被设置过则直接返回 ture。 2.2 atomic&lt;T&gt;其他的原子类型都是通过atomic&lt;T&gt; 特例化而成的，但可能不是无锁结构。通过atomic&lt;T&gt; 实例化的原子类型都具有以下接口： load()：从原子对象中以原子方式读取值，并返回读取的值。 store(val)：以原子方式将给定的值 val存储到原子对象中。 exchange(val)：以原子方式将给定的值 val存储到原子对象中，并返回原子对象之前的值。 compare_exchange_weak(expected, val)和 compare_exchange_strong(expected, val)：使用原子比较和交换操作，将原子对象的值与 expected进行比较，如果相等，则将原子对象的值设置为 val。这两个函数的区别在于对比较失败时的行为 compare_exchange_weak可能会失败但不会给出明确的失败原因，而 compare_exchange_strong在比较失败时会返回失败的原子对象的值。 fetch_add(val)和 fetch_sub(val)：以原子方式将原子对象的值与 val相加或相减，并返回操作之前的原子对象的值。 operator T()：将原子对象转换为 T类型的操作数，可以通过此操作符获取原子对象的值。 这些接口只是原子类型提供的一部分功能，还有其他接口可以用于原子操作。使用原子类型可以确保多个线程对共享数据的访问是安全的，避免了数据竞争的问题。请注意，原子类型只能保证单个操作的原子性，而不能保证多个操作的原子性。如果需要实现更复杂的原子操作序列，可以使用互斥锁或其他同步机制。 2.3 atomic&lt;UDT&gt;对于用户自定义类型UDT，需要满足一定条件才能被atomic&lt;&gt;具现化： 必须具备平实拷贝赋值操作符，由编译器代其隐式生成拷贝赋值操作符。 不得含有任何虚函数，不可以从虚基类派生得出。 若具有基类或非静态数据成员，必须具备平实拷贝赋值操作符。 由于以上限制，赋值操作不涉及任何用户编写的代码，因此编译器可借用memcpy()完成。另外，compare_exchange 操作采用的是逐位比较运算，效果等同于直接使用memcmp()函数，即使UDT自行定义了比较运算符，也会被忽略。编译器之所以这样限制，是为了使得可以将UDT视为原始字节，从而让UDT按无锁方式具现化。 3 内存次序对于原子类型上的每一种操作，我们都可以提供额外的参数，从枚举类std::memory_order取值，用于设定所需的内存次序语义。枚举类std::memory_order具有6个可能的值： 宽松次序：memory_order_relaxed； 获取-释放次序：memory_order_consume（建议不予采用）、memory_order_acquire、memory_order_release、memory_order_acq_rel； 先后一致次序：memory_order_seq_cst（默认）. 先后一致次序是最严格的内存次序，同时也是默认参数。如果程序服从该次序，就简单地把一切事件视为按先后顺序发生，所有线程所见的一切操作都必须服从相同的次序。这样最符合直觉，比较容易理解。但其他次序中，不同线程看到的同一组操作的次序和效果可能呈现差异。 以下以atomic_flag构成的自旋锁为例： 12345678910111213141516class spinlock_mutex&#123; std::atomic_flag flag;public: spinlock_mutex(): flag(ATOMIC_FLAG_INIT) &#123;&#125; void lock() &#123; while(flag.test_and_set(std::memory_order_acquire)); &#125; void unlock() &#123; flag.clear(std::memory_order_release); &#125;&#125;;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"1-线程管理","slug":"并发编程基础/1-线程管理","date":"2023-11-28T12:39:40.377Z","updated":"2023-12-28T03:30:22.772Z","comments":true,"path":"2023/11/28/并发编程基础/1-线程管理/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/11/28/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/1-%E7%BA%BF%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"","text":"每个C++程序至少有一个线程，即main线程。随后，程序可以发起更多线程，他们以别的函数作为入口。当main函数返回时，程序随即退出，其他线程也会随着终结（当然如果有detach线程，情况不一样）。其中，任何线程发生错误崩溃，都会导致整个进程退出。 1 新起线程123#include &lt;thread&gt;void do_some_work();std::thread my_thread(do_some_work); 不限于普通函数，任何可调用类型都可以初始化 std::thread 。如函数对象，lambda表达式等。如下： 1234567891011class background_task&#123;public: void operator()() const &#123; do_something(); do_something_else(); &#125;&#125;;background_task f;std::thread my_thread(f); 需要注意的是，这样的传参，函数对象 f 是被复制到新线程空间中的，要关注对象副本运行是否会影响正常功能。另外，请不要让新创建的线程访问当前上下文的局部变量，否则当上下文执行后，该局部变量失效。 2 回收线程1my_thread.join() 在 std:thread 对象被销毁前，我们需要确保已经调用 join() 或 detach() 方法，以确保能够回收线程空间。 ① 若调用 join 方法，则需要格外小心，因为我们需要确保在每一个函数的出口都能调用join方法，尤其是抛出异常的情况。以下提供一种 RAII 方法，确保总能回收线程。 1234567891011121314151617181920212223242526class thread_guard&#123; std::thread&amp; t;public: explicit thread_guard(std::thread&amp; t_): t(t_) &#123;&#125; ~thread_guard() &#123; if(t.joinable()) &#123; t.join(); &#125; &#125; thread_guard(thread_guard const&amp;)=delete; thread_guard&amp; operator=(thread_guard const&amp;)=delete;&#125;; struct func; void f()&#123; int some_local_state=0; func my_func(some_local_state); std::thread t(my_func); thread_guard g(t); do_something_in_current_thread();&#125; 以上，无论 f 函数正常退出还是异常退出，都会析构thread_guard 对象，从而保证一定会调用线程join方法。 ② 若使用detach方法，父线程不需要显式地等待子线程，整个进程会等到子线程运行完才完全退出，因此也回收了线程空间。 3 线程传参3.1 直接传值std::thread是可以直接传递参数的，如：std::thread t(func, 3, “hello”); 需要注意的是，默认参数是拷贝到线程独立内存中。即使传递的是对象的引用，传递给函数的参数是对象拷贝的引用，而非对象本身的引用。 3.2 传引用当传递引用时，使用std::ref进行传参。 1std::thread t(update_data_for_widget, w, std::ref(data)); 3.3 成员函数传参对于成员函数传参，采用以下形式。若添加第三个参数，则它会作为成员函数的第一个参数。 123456class X &#123;public: void do_lengthy_work();&#125;;X my_x;std::thread t(&amp;X::do_lengthy_work, &amp;my_x); 4 移交线程管理权12345678void f(std::thread t);void g()&#123; void some_function(); f(std::thread(some_function)); std::thread t(some_function); f(std::move(t));&#125; 移交线程管理权，可以将线程交由类掌管。另外一个好处是，只要将线程归属权转移给某个thread_guard对象，其他对象就无法做汇合或分离操作。 由于线程支持移动语义，因而标准库容器可以合适地装载 std:thread 对象。以下代码经常用于数据并行处理，如下： 1234567891011void do_work(unsigned id);void f()&#123; std::vector&lt;std::thread&gt; threads; for(unsigned i=0;i&lt;20;++i) &#123; threads.emplace_back(do_work,i); &#125; for(auto&amp; entry: threads) entry.join();&#125;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"3-线程同步","slug":"并发编程基础/3-线程同步","date":"2023-11-28T10:40:04.602Z","updated":"2023-12-28T03:30:31.448Z","comments":true,"path":"2023/11/28/并发编程基础/3-线程同步/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/11/28/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/3-%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/","excerpt":"","text":"何为线程同步？有时候我们需要规范线程的执行顺序，令独立线程上的行为同步。以下介绍C++标准库提供的线程同步工具。 1 信号量1234567891011121314151617#include &lt;semaphore.h&gt;sem_t semaphore;sem_init(&amp;semaphore, 0, 0);void data_preparation_thread()&#123; while(more_data_to_prepare())&#123; ...... sem_post(&amp;semaphore); //信号量发送（增加） &#125;&#125;void data_processing_thread() &#123; while(true)&#123; sem_wait(&amp;semaphore); //等待信号量（减小） ...... &#125;&#125; 2 条件变量123456789101112131415161718192021222324252627282930std::mutex mut;std::queue&lt;data_chunk&gt; data_queue; ⇽--- ①std::condition_variable data_cond;void data_preparation_thread() // 由线程乙运行&#123; while(more_data_to_prepare()) &#123; data_chunk const data=prepare_data(); &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); data_queue.push(data); ⇽--- ② &#125; data_cond.notify_one(); ⇽--- ③ &#125;&#125;void data_processing_thread() // 由线程甲运行&#123; while(true) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); ⇽--- ④ data_cond.wait( lk,[]&#123;return !data_queue.empty();&#125;); ⇽--- ⑤ data_chunk data=data_queue.front(); data_queue.pop(); lk.unlock(); ⇽--- ⑥ process(data); if(is_last_chunk(data)) break; &#125;&#125; 以上，data_cond.wait() 建议配合 data_cond.notify_one() 一起用。notify_one() 通知条件变量，使wait() 从阻塞中被唤醒，重新尝试获取锁，再次查验条件。也就是 data_cond.wait() 并非一直检查条件，而是需要 notify_one() 触发。 当有多个线程阻塞等待时，用notify_all() . 另外，为什么这里要使用 std::unique_lock 呢？因为当条件不成立时，wait()要释放锁。而std::lock_guard 无法提供这种灵活性。 利用条件变量构建线程安全队列虽然std::queue 的操作是原子性的，但是并不代表线程安全，其接口还是存在固有的条件竞争。我们需要把front()和pop()合并成一个函数，这与栈容器的top()和pop()合并相似。另外，为了增加灵活性，这里提供pop的两个变体，try_pop()和wait_and_pop()，一个非阻塞一个阻塞。以下是类定义： 12345678910111213141516#include &lt;memory&gt; ⇽--- ①为使用std::shared_ptr而包含此头文件template&lt;typename T&gt;class threadsafe_queue&#123;public: threadsafe_queue(); threadsafe_queue(const threadsafe_queue&amp;); threadsafe_queue&amp; operator=( const threadsafe_queue&amp;) = delete; ⇽--- ②为简化设计而禁止赋值操作 void push(T new_value); bool try_pop(T&amp; value); ⇽--- ③ std::shared_ptr&lt;T&gt; try_pop(); ⇽--- ④ void wait_and_pop(T&amp; value); std::shared_ptr&lt;T&gt; wait_and_pop(); bool empty() const;&#125;; 完整接口实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;queue&gt;#include &lt;memory&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;template&lt;typename T&gt;class threadsafe_queue&#123;private: mutable std::mutex mut; ⇽--- ①互斥必须用mutable修饰（针对const对象，准许其数据成员发生变动） std::queue&lt;T&gt; data_queue; std::condition_variable data_cond;public: threadsafe_queue() &#123;&#125; threadsafe_queue(threadsafe_queue const&amp; other) &#123; std::lock_guard&lt;std::mutex&gt; lk(other.mut); data_queue=other.data_queue; &#125; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); data_queue.push(new_value); data_cond.notify_one(); &#125; void wait_and_pop(T&amp; value) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); value=data_queue.front(); data_queue.pop(); &#125; std::shared_ptr&lt;T&gt; wait_and_pop() &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front())); data_queue.pop(); return res; &#125; bool try_pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); if(data_queue.empty()) return false; value=data_queue.front(); data_queue.pop(); return true; &#125; std::shared_ptr&lt;T&gt; try_pop() &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); if(data_queue.empty()) return std::shared_ptr&lt;T&gt;(); std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front())); data_queue.pop(); return res; &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); return data_queue.empty(); &#125;&#125;; 3 future机制如果某个线程按计划只需等待一次，那么利用 future 等待更合适。标准库中有std::future 和 std::shared_future，其参照了std::unique_ptr 和 std::shared_ptr. 注意，虽然future对象能用于线程间通信，但是future对象不提供同步访问。若有多个线程访问同一个future对象，必须用互斥访问。 3.1 async 异步运行使用 std::async 启动一个异步任务。与 std::thread 对象等待运行方式的不同， std::async 会返回一个 std::future 对象，这个对象持有最终计算出来的结果。当你需要这个值时，你只需要调用 future 对象的get()方法阻塞获取。 std::async是C++中一种快速建立并行的方法，类似的，python中ProcessPoolExecutor也可以快速并行。 12345678910#include &lt;future&gt;#include &lt;iostream&gt;int find_the_answer_to_ltuae();void do_other_stuff();int main()&#123; std::future&lt;int&gt; the_answer=std::async(find_the_answer_to_ltuae); do_other_stuff(); std::cout&lt;&lt;&quot;The answer is &quot;&lt;&lt;the_answer.get()&lt;&lt;std::endl; //阻塞获取&#125; std::async 的传参与 std::thread的传参一致，若传入的是普通函数，则第一个参数是函数对象，其余为函数的入参；若传入的是类成员函数，则第一个参数为类成员函数地址，第二个参数是对象地址，其余为函数入参。注意如果要传引用，用std::ref()包装。 std::async 有两种运行方式，一种是起新线程的异步运行方法，一种是在当前线程的同步运行方法。通过设定 std::async 的第一个参数，可以指定运行方式。该参数值可以是 std::launch::deferred 或 std::launch::async，前者指定在本线程上延迟执行函数，后者则新起一个线程执行。注：若不设定，则由系统自行选择。 3.2 packaged_task 打包任务std::packaged_task&lt;&gt;可打包函数对象和future对象，他可以作为线程池的构件单元。std::packaged_task&lt;&gt;是一个类模板，其模板参数是函数签名，如：void()表示一个函数，无入参，无返回值。std::packaged_task&lt;&gt;对象具有 get_futrue()方法，能够返回future对象。std::packaged_task 是个可调用对象，调用时函数开始运行。 std::packaged_task 这种特性使得可以在线程间传递任务，即当前线程将任务包装在 std::packaged_task 中，获得对应 future 对象后，传递给另外的线程，并由其触发任务运行。等需要用到结果时，再用future 对象获取。以下代码是GUI前端向后台线程推处理任务，其将用户的请求（点击事件等）传递给后台线程。 123456789101112131415161718192021222324252627282930313233343536#include &lt;deque&gt;#include &lt;mutex&gt;#include &lt;future&gt;#include &lt;thread&gt;#include &lt;utility&gt;std::mutex m;std::deque&lt;std::packaged_task&lt;void()&gt;&gt; tasks;bool gui_shutdown_message_received();void get_and_process_gui_message();void gui_thread() ⇽--- ①&#123; while(!gui_shutdown_message_received()) ⇽--- ② &#123; get_and_process_gui_message(); ⇽--- ③ std::packaged_task&lt;void()&gt; task; &#123; std::lock_guard&lt;std::mutex&gt; lk(m); if(tasks.empty()) ⇽--- ④ continue; task=std::move(tasks.front()); ⇽--- ⑤ tasks.pop_front(); &#125; task(); ⇽--- ⑥ &#125;&#125;std::thread gui_bg_thread(gui_thread);template&lt;typename Func&gt;std::future&lt;void&gt; post_task_for_gui_thread(Func f)&#123; std::packaged_task&lt;void()&gt; task(f); ⇽--- ⑦ std::future&lt;void&gt; res=task.get_future(); ⇽--- ⑧ std::lock_guard&lt;std::mutex&gt; lk(m); tasks.push_back(std::move(task)); ⇽--- ⑨ return res; ⇽--- ⑩&#125; 3.3 promise 等待设定值std::promise 配合 std::futrue 可实现以下机制：等待数据的线程在 futrue 上阻塞，提供数据的线程则利用 promise 设定关联值，使futrue就绪。 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;future&gt;void initiazer(std::promise&lt;int&gt; * promObj)&#123; std::cout&lt;&lt;&quot;新线程内部&quot;&lt;&lt;std::endl; promObj-&gt;set_value(35);&#125;int main()&#123; std::promise&lt;int&gt; promiseObj; std::future&lt;int&gt; futureObj = promiseObj.get_future(); std::thread th(initiazer, &amp;promiseObj); std::cout&lt;&lt;futureObj.get()&lt;&lt;std::endl; th.join(); return 0;&#125; 3.4 shared_future 共享期待std::future只有一个实例可以获得特定的同步结果，而 std::shared_future 实例是可拷贝的，所以多个对象可以引用同一关联“期望”的结果。 12std::promise&lt;std::string&gt; p;std::shared_future&lt;std::string&gt; sf(p.get_future()); ⇽--- ①隐式转移归属权 3.5 等待多个futrue当线程需要汇总各个std::async任务的处理结果时，需要逐个等待future对象，可能写出如下代码： 123456789101112131415161718192021std::future&lt;FinalResult&gt; process_data(std::vector&lt;MyData&gt;&amp; vec)&#123; size_t const chunk_size=whatever; std::vector&lt;std::future&lt;ChunkResult&gt;&gt; results; for(auto begin=vec.begin(),end=vec.end();beg!=end;)&#123; size_t const remaining_size=end-begin; size_t const this_chunk_size=std::min(remaining_size,chunk_size); results.push_back( std::async(process_chunk,begin,begin+this_chunk_size)); begin+=this_chunk_size; &#125; return std::async([all_results=std::move(results)]()&#123; std::vector&lt;ChunkResult&gt; v; v.reserve(all_results.size()); for(auto&amp; f: all_results) &#123; v.push_back(f.get()); ⇽--- ① &#125; return gather_results(v); &#125;);&#125; 当有任务完成时，代码①被唤醒，随之又进入休眠，等待下一个任务唤醒。我们有更简洁的写法，可以减少这种切换开销。采用 std::experimental::when_all 等待所有任务结束再唤醒。 1234567891011121314151617181920212223242526272829std::experimental::future&lt;FinalResult&gt; process_data( std::vector&lt;MyData&gt;&amp; vec)&#123; size_t const chunk_size=whatever; std::vector&lt;std::experimental::future&lt;ChunkResult&gt;&gt; results; for(auto begin=vec.begin(),end=vec.end();beg!=end;)&#123; size_t const remaining_size=end-begin; size_t const this_chunk_size=std::min(remaining_size,chunk_size); results.push_back( spawn_async( process_chunk,begin,begin+this_chunk_size)); begin+=this_chunk_size; &#125; return std::experimental::when_all( results.begin(),results.end()).then( ⇽--- ① [](std::future&lt;std::vector&lt; std::experimental::future&lt;ChunkResult&gt;&gt;&gt; ready_results) &#123; std::vector&lt;std::experimental::future&lt;ChunkResult&gt;&gt; all_results=ready_results .get(); std::vector&lt;ChunkResult&gt; v; v.reserve(all_results.size()); for(auto&amp; f: all_results) &#123; v.push_back(f.get()); ⇽--- ② &#125; return gather_results(v); &#125;);&#125;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"2-共享数据","slug":"并发编程基础/2-共享数据","date":"2023-11-28T10:40:04.178Z","updated":"2023-12-28T03:30:27.576Z","comments":true,"path":"2023/11/28/并发编程基础/2-共享数据/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/11/28/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/2-%E5%85%B1%E4%BA%AB%E6%95%B0%E6%8D%AE/","excerpt":"","text":"如果线程间所有的共享数据都是只读，就不会有问题。多线程共享数据的问题大多由写数据引起，以下介绍线程间共享数据的安全做法。 1 互斥锁C++中，保护共享数据最基础的方式就是互斥（std::lock_guard + std:mutex）。互斥意味着，两个或两个以上线程操作同一个数据，必须排队等待。 12345678910#include &lt;list&gt;#include &lt;mutex&gt;std::list&lt;int&gt; some_list; std::mutex some_mutex; void add_to_list(int new_value)&#123; std::lock_guard&lt;std::mutex&gt; guard(some_mutex); some_list.push_back(new_value);&#125; C++提供的 std::lock_guard，构造时对 mutex 上锁，析构时对 mutex 解锁，这种RAII方式保证了mutex无论如何都能够被解锁。 利用互斥锁构造线程安全栈即使C++标准库容器的操作是原子性的，但这并不代表容器的操作就是线程安全的。举个例子： 123456stack&lt;int&gt; s;if(!s.empty()) &#123; int const value=s.top(); s.pop(); &#125; 当 stack 判定为非空时，会对栈顶元素弹出。如果这时刚好另外一个线程弹出栈的最后一个元素，那么此时的操作便是: 对一个空栈进行pop，这是一个未定义的行为。我们可以利用互斥锁来构建线程安全的栈，说白了是用一个粗粒度的锁来控制容器各接口的访问，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;exception&gt;#include &lt;memory&gt;#include &lt;mutex&gt;#include &lt;stack&gt;struct empty_stack: std::exception&#123; const char* what() const throw();&#125;;template&lt;typename T&gt;class threadsafe_stack&#123;private: std::stack&lt;T&gt; data; mutable std::mutex m;public: threadsafe_stack()&#123;&#125; threadsafe_stack(const threadsafe_stack&amp; other) &#123; std::lock_guard&lt;std::mutex&gt; lock(other.m); data=other.data; ⇽--- ①在构造函数的函数体（constructor body）内进行复制操作 &#125; threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); data.push(std::move(new_value)); &#125; std::shared_ptr&lt;T&gt; pop() &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); ⇽--- ②试图弹出前检查是否为空栈 std::shared_ptr&lt;T&gt; const res(std::make_shared&lt;T&gt;(data.top())); ⇽--- ③改动栈容器前设置返回值 data.pop(); return res; &#125; void pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); value=data.top(); data.pop(); &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lock(m); return data.empty(); &#125;&#125;; 2 死锁当两个线程互相等待对方解锁，则形成死锁。（递归获取普通锁也会形成死锁），以下两个建议：① 固定顺序上锁：避免死锁的通常建议，就是让两个互斥量总以相同的顺序上锁，如总在互斥量B之前锁住互斥量A，一般不会死锁。② 同时上锁：当然有些时候我们很难保证固定的顺序，比如操作同一个类的两个实例，互相交换他们的内部数据，访问时需获得互斥锁。此时，如果两个线程都在执行这件事，只不过入参（实例1，实例2）的顺序不一样，就会发生死锁，这个时候是没有什么固定顺序可言的。std:lock 可以解决这个问题，同时锁住两个互斥量，就没有所谓的顺序了，如下： 12345678910111213141516171819class some_big_object;void swap(some_big_object&amp; lhs, some_big_object&amp; rhs);class X&#123;private: some_big_object some_detail; std::mutex m;public: X(some_big_object const&amp; sd):some_detail(sd)&#123;&#125; friend void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; std::lock(lhs.m,rhs.m); ⇽--- ① std::lock_guard&lt;std::mutex&gt; lock_a(lhs.m, std::adopt_lock); ⇽--- ② std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m, std::adopt_lock); ⇽--- ③ swap(lhs.some_detail,rhs.some_detail); &#125;&#125;; 其中，std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m, std::adopt_lock); 是接管锁的管理权，并非创建新锁。std::lock 会阻塞等待所有锁均可获得。 C++17对以上写法进行了简化，如下： 1234567void swap(X&amp; lhs, X&amp; rhs)&#123; if(&amp;lhs==&amp;rhs) return; std::scoped_lock guard(lhs.m,rhs.m); //构造时同时锁定，析构时释放。 swap(lhs.some_detail,rhs.some_detail);&#125; 避免死锁的准则 避免嵌套锁：假设已经持有锁，就不要试图获取第二个锁。如果有多个锁，请使用 std::lock 同时上锁。 固定顺序上锁：当不允许使用 std::lock 同时上锁时，请使用固定顺序依次上锁。 上锁时尽量避免用户接口：因为我们不知道用户接口里面时候也持有锁，因而尽可能在已经持有锁的条件下不要调用用户接口。 使用层次锁：层次锁需要对你的应用进行分层，并且识别在给定层上所有可上锁的互斥量。当代码试图对一个互斥量上锁，在该层锁已被低层持有时，上锁是不允许的。 3 其他锁3.1 unique_lockunique_lock 支持灵活的锁定和解锁操作：std::unique_lock提供了 lock()和 unlock()成员函数，允许在需要的时候手动锁定和解锁互斥量。这样可以灵活地控制临界区的访问时间，而不仅限于对象的构造和析构时，如下： 123456789void get_and_process_data()&#123; std::unique_lock&lt;std::mutex&gt; my_lock(the_mutex); some_class data_to_process=get_next_data_chunk(); my_lock.unlock(); // 1 不要让锁住的互斥量越过process()函数的调用 result_type result=process(data_to_process); my_lock.lock(); // 2 为了写入数据，对互斥量再次上锁 write_result(data_to_process,result);&#125; 3.2 shared_lockshared_lock 是一种多线程同步机制，它允许多个线程同时读取共享资源，但只允许一个线程写入共享资源。shared_lock 直到 C++17才被标准库提供，在此之前，可以使用 boost::shared_lock 。如下为dns缓存表的读写控制： 1234567891011121314151617181920212223#include &lt;map&gt;#include &lt;string&gt;#include &lt;mutex&gt;#include &lt;shared_mutex&gt;class dns_entry;class dns_cache&#123; std::map&lt;std::string,dns_entry&gt; entries; mutable std::shared_mutex entry_mutex; public: dns_entry find_entry(std::string const&amp; domain) const &#123; std::shared_lock&lt;std::shared_mutex&gt; lk(entry_mutex); ⇽--- ① std::map&lt;std::string,dns_entry&gt;::const_iterator const it= entries.find(domain); return (it==entries.end())?dns_entry():it-&gt;second; &#125; void update_or_add_entry(std::string const&amp; domain,dns_entry const&amp; dns_details) &#123; std::lock_guard&lt;std::shared_mutex&gt; lk(entry_mutex); ⇽--- ② entries[domain]=dns_details; &#125;&#125;; 以上代码使用的互斥量为 std::shared_mutex，该互斥量被 shared_lock 持有时，多线程均可持锁访问。被 lock_guard 或 unique_lock 持有时只能当线程持有该锁。 12345// 读时用：std::shared_lock&lt;std::shared_mutex&gt; lk(entry_mutex);// 写时用：std::lock_guard&lt;std::shared_mutex&gt; lk(entry_mutex); 或 std::unique_lock&lt;std::shared_mutex&gt; lk(entry_mutex); 3.3 递归锁C++标准库提供了 std::recursive_mutex 类。其功能与 std::mutex 类似，除了你可以从同一线程的单个实例上获取多个锁。在互斥量锁住其他线程前，你必须释放你拥有的所有锁，所以当你调用lock()三次时，你也必须调用unlock()三次。 4 再看单例模式double-check 单例模式： 1234567if (instance_ == nullptr) &#123; \\\\ 语句1 std::lock_guardstd::mutex lock(mutex_); if (instance_ == nullptr) &#123; instance_ = new Singleton; \\\\ 语句2 &#125;&#125;return instance_; 如上代码，对于 语句2是一个写操作 ，我们用mutex来保护instance_这个变量。但是 语句1是一个读操作 ，if (instance_ &#x3D;&#x3D; nullptr)，这个语句是用来读取instance_这个变量，而这个读操作是没有锁的。所以在多线程情况下，这种写法明显存在线程安全问题。 不同的编译器表现是不一样的。可能先将该内存地址赋给instance_，然后再调用构造函数。这是线程A恰好申请完成内存，并且将内存地址赋给instance_，但是还没调用构造函数的时候。线程B执行到语句1，判断instance_此时不为空，则返回该变量，然后调用该对象的函数，但是该对象还没有进行构造，此时调用会发生错误。 C++11对单例模式提供了语言级别的支持，std::call_once可保证在多线程中函数只被调用一次。std::call_once 可以和任何函数或可调用对象一起使用。如：std::call_once(connection_init_flag,&amp;X::open_connection,this); 如下： 1234567891011std::shared_ptr resource_ptr;std::once_flag resource_flag; // 1void init_resource()&#123; resource_ptr.reset(new some_resource);&#125;void foo()&#123; std::call_once(resource_flag,init_resource); // 可以完整的进行一次初始化 resource_ptr-&gt;do_something();&#125;","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"0-并发简述","slug":"并发编程基础/0-并发简述","date":"2023-11-28T10:40:03.318Z","updated":"2023-12-28T03:30:16.728Z","comments":true,"path":"2023/11/28/并发编程基础/0-并发简述/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/11/28/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/0-%E5%B9%B6%E5%8F%91%E7%AE%80%E8%BF%B0/","excerpt":"","text":"为什么使用并发？分离关注点和性能提升。（唯一原因）性能提升的两种方式：任务并行 &amp; 数据并行。 为什么不使用并发？收益小于代价。使用并发的代码通常更难理解，会直接拉高开发和维护成本，同时也更可能引起错误。因而除非并发能带来明显的性能提升和代码清晰度，否则别使用并发。 多线程带来的代价 线程启动开销。系统为线程分配内核资源和栈空间，都会耗费时间。 资源消耗：每个线程都需要独立的堆栈空间，太多的线程也会耗尽进程的可用内存或地址空间。 切换性能：线程越多，系统所做的上下文切换越频繁。太多的线程会拉低应用软件的整体性能。","categories":[{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"2-protobuf的使用","slug":"C++那些事/2-protobuf的使用","date":"2023-11-15T01:59:01.793Z","updated":"2023-11-15T01:59:01.841Z","comments":true,"path":"2023/11/15/C++那些事/2-protobuf的使用/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/11/15/C++%E9%82%A3%E4%BA%9B%E4%BA%8B/2-protobuf%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1 软件包介绍protobuf是google定义的一套数据传输格式和规范，用于不同应用或进程之间进行通信时使用。protobuf 支持跨平台, 跨语言, 支持目前绝大多数语言, 例如C++, C#, Java, Python等。 2 Why protobuf ?先来看看目前常用的 序列化 &#x2F; 反序列化 方法: 将原始数据结构序列化为 字节流 传输。(这是一种脆弱的数据传输方法，它要求 接收端 必须遵守完全相同的内存布局，并禁止扩展数据格式.) 将原始数据结构序列化为 XML 形式。(这是一种广泛使用的数据传输格式，但是 XML 因为冗长而占用了大量的存储空间.) protobuf 通过定义的 message 数据结构进行打包，然后编译成二进制的码流再进行传输或者存储。相比XML，其序列化后的消息大小只有XML的1&#x2F;10 ~ 1&#x2F;3，解析速度比XML快20 ~ 100倍。并且protobuf 的设计具有更好的兼容性和扩展性。 3 proto文件.proto文件用于定义语言无关的消息结构，使用.proto文件时，需要先用 protobuf-compiler 将.proto文件编译成语言相关的文件（如C++则生成 .pb.cc 和 .pb.h 文件），然后应用代码包含这些文件即可调用消息结构。 3.1 消息定义12345678910111213141516171819202122syntax = &quot;proto2&quot;; //指定版本package tutorial; //添加域名message Person &#123; optional string name = 1; optional int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; optional string number = 1; optional PhoneType type = 2 [default = HOME]; &#125; repeated PhoneNumber phones = 4;&#125;message AddressBook &#123; repeated Person people = 1;&#125; 3.2 修饰符required: 表示是一个必须字段。对于发送方，在发送消息时必须设置该字段的值；对于接收方，必须能够识别该字段的意思。由于required可能会导致兼容性问题，实际应用中比较少用。 optional：表示是一个可选字段。对于发送方，在发送消息时可以设置或者不设置该字段的值；对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则忽略该字段。由于optional字段的特性，很多接口在升级版本中都把后来添加的字段都统一的设置为optional字段，这样老的版本无需升级程序也可以正常的与新的软件进行通信，只不过新的字段无法识别而已，因为并不是每个节点都需要新的功能，因此可以做到按需升级和平滑过渡。 repeated：表示是一个可重复字段，可以包含0~N个元素。其特性和optional一样，但是每一次可以包含多个值，可以看作是在传递一个元素数组。 3.3 字段编码值字段编码值表示该字段在二进制编码中使用的唯一 “标记”。标签号 1-15 比起更大数字需要少一个字节进行编码，因此可以用于标识常用或重复的元素。1900~2000 编码值为Google protobuf 系统内部保留值，建议不要在自己的项目中使用。消息中的字段的编码值无需连续，只要是合法的，并且不能在同一个消息中有字段包含相同的编码值。 3.4 数据类型 数据类型 描述 bool 布尔类型 double 64-bit 浮点数 float 32-bit 浮点数 int32 32-bit 整数 uin32 32-bit 无符号整数 int64 64-bit 整数 uint64 64-bit 无符号整数 sint32 32-bit 整数，处理负数效率更高 sing64 64-bit 整数，处理负数效率更高 fixed32 32-bit 无符号整数 fixed64 64-bit 无符号整数 sfixed32 32-bit 整数，处理负数效率更高 sfixed64 64-bit 整数，处理负数效率更高 string 字符串，只能处理 ASCII字符 bytes 用于处理多字节的语言字符、如中文 enum 枚举类型 message 可以包含一个用户自定义的消息类型 关于 fixed32 和int32的区别。fixed32的打包效率比int32的效率高，但是使用的空间一般比int32多。因此一个属于时间效率高，一个属于空间效率高。根据项目的实际情况，一般选择fixed32，如果遇到对传输数据量要求比较苛刻的环境，可以选择int32. 3.5 编译.proto编译器安装 1sudo apt install libprotobuf-dev protobuf-compiler 编译proto文件 1protoc --cpp_out=. example.proto 编译产生 example.pb.cc 和 example.pb.h 文件，以下是example.pb.h 片段，可见protoc已经为我们生成字段的getter和setter函数。 123456789101112131415161718192021// optional string name = 1; bool has_name() const; void clear_name(); static const int kNameFieldNumber = 1; const ::std::string&amp; name() const; void set_name(const ::std::string&amp; value); #if LANG_CXX11 void set_name(::std::string&amp;&amp; value); #endif void set_name(const char* value); void set_name(const char* value, size_t size); ::std::string* mutable_name(); ::std::string* release_name(); void set_allocated_name(::std::string* name); // optional int32 id = 2; bool has_id() const; void clear_id(); static const int kIdFieldNumber = 2; ::google::protobuf::int32 id() const; void set_id(::google::protobuf::int32 value); 4 序列化&#x2F;反序列化我们使用protobuf最终是要将消息进行序列化和反序列化，用于消息传输或存储。protobuf提供了以下序列化和反序列化API： 123456789101112class MessageLite &#123;public: //序列化： bool SerializeToOstream(ostream* output) const; bool SerializeToArray(void *data, int size) const; bool SerializeToString(string* output) const; //反序列化： bool ParseFromIstream(istream* input); bool ParseFromArray(const void* data, int size); bool ParseFromString(const string&amp; data);&#125;; 以下列举序列化和反序列化的代码示例： 4.1 序列化12345678910111213141516171819202122void serialize_process() &#123; cout &lt;&lt; &quot;serialize_process&quot; &lt;&lt; endl; tutorial::Person person; person.set_name(&quot;Obama&quot;); person.set_id(1234); person.set_email(&quot;1234@qq.com&quot;); tutorial::Person::PhoneNumber *phone1 = person.add_phones(); phone1-&gt;set_number(&quot;110&quot;); phone1-&gt;set_type(tutorial::Person::MOBILE); tutorial::Person::PhoneNumber *phone2 = person.add_phones(); phone2-&gt;set_number(&quot;119&quot;); phone2-&gt;set_type(tutorial::Person::HOME); fstream output(&quot;person_file&quot;, ios::out | ios::trunc | ios::binary); if( !person.SerializeToOstream(&amp;output) ) &#123; cout &lt;&lt; &quot;Fail to SerializeToOstream.&quot; &lt;&lt; endl; &#125; cout &lt;&lt; &quot;person.ByteSizeLong() : &quot; &lt;&lt; person.ByteSizLong() &lt;&lt; endl;&#125; 4.2 反序列化12345678910111213141516171819202122232425262728293031void parse_process() &#123; cout &lt;&lt; &quot;parse_process&quot; &lt;&lt; endl; tutorial::Person result; fstream input(&quot;person_file&quot;, ios::in | ios::binary); if(!result.ParseFromIstream(&amp;input)) &#123; cout &lt;&lt; &quot;Fail to ParseFromIstream.&quot; &lt;&lt; endl; &#125; cout &lt;&lt; result.name() &lt;&lt; endl; cout &lt;&lt; result.id() &lt;&lt; endl; cout &lt;&lt; Buy and Sell Domain Names() &lt;&lt; endl; for(int i = 0; i &lt; result.phones_size(); ++i) &#123; const tutorial::Person::PhoneNumber &amp;person_phone = result.phones(i); switch(person_phone.type()) &#123; case tutorial::Person::MOBILE : cout &lt;&lt; &quot;MOBILE phone : &quot;; break; case tutorial::Person::HOME : cout &lt;&lt; &quot;HOME phone : &quot;; break; case tutorial::Person::WORK : cout &lt;&lt; &quot;WORK phone : &quot;; break; default: cout &lt;&lt; &quot;phone type err.&quot; &lt;&lt; endl; &#125; cout &lt;&lt; person_phone.number() &lt;&lt; endl; &#125;&#125; 4.3 应用代码12345678#include &quot;example.pb.h&quot;int main(int argc, char *argv[]) &#123; serialize_process(); parse_process(); google::protobuf::ShutdownProtobufLibrary(); //删除所有已分配的内存（Protobuf使用的堆内存） return 0;&#125; g++编译时添加链接 -lprotobuf -lpthread 即可。 https://github.com/protocolbuffers/protobufhttps://zhuanlan.zhihu.com/p/641283776","categories":[{"name":"C++那些事","slug":"C-那些事","permalink":"https://xie-peiquan.gitee.io/categories/C-%E9%82%A3%E4%BA%9B%E4%BA%8B/"}],"tags":[{"name":"C++库","slug":"C-库","permalink":"https://xie-peiquan.gitee.io/tags/C-%E5%BA%93/"}]},{"title":"3-gtest的使用","slug":"C++那些事/3-gtest的使用","date":"2023-11-08T09:07:49.376Z","updated":"2023-11-08T09:13:52.538Z","comments":true,"path":"2023/11/08/C++那些事/3-gtest的使用/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/11/08/C++%E9%82%A3%E4%BA%9B%E4%BA%8B/3-gtest%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1 软件包介绍gtest是google提供的一个轻量级单元测试框架，它提供了丰富的断言、致命和非致命失败判断，能进行值参数化测试、类型参数化测试、“死亡测试”。 2 软件包安装12345git clone https://github.com/google/googletest.gitcd googletest mkdir build &amp;&amp; cd buildcmake .. &amp;&amp; makesudo make install 3 软件包使用3.1 快速开始123456789101112131415#include &quot;gtest/gtest.h&quot;int Factorial(int n) &#123; int result = 1; for (int i = 1; i &lt;= n; i++) &#123; result *= i; &#125; return result;&#125;namespace sample1&#123;TEST(FactorialTest, Zero) &#123; EXPECT_EQ(1, Factorial(0)); &#125;&#125; 编译运行： 1g++ ./mytest.cpp -lgtest -std=c++14 -lgtest_main -lpthread -o mytest 其中链接 -lgtest_main 是因为测试的 main 函数在 gtest_main.a 库中，由它拉起所有的测试用例。 3.2 断言接口gtest中，断言的宏可以分为两类，一类是ASSERT系列，一类是EXPECT系列。ASSERT_* 系列的断言（Fatal assertion），当检查点失败时，退出当前函数（注意：并非退出当前案例）。EXPECT_* 系列的断言(Nonfatal assertion)，当检查点失败时，继续执行下一个检查点（每一个断言表示一个测试点）。通常情况应该首选使用 EXPECT_ ，因为 ASSERT_ 在报告完错误后不会进行清理工作，有可能导致内存泄露问题。 3.2.1 布尔型检查 Fatal assertion Nonfatal assertion Verifies ASSERT_TRUE(condition); EXPECT_TRUE(condition); condition is true ASSERT_FALSE(condition); EXPECT_FALSE(condition); condition is false 3.2.2 二值检查 Fatal assertion Nonfatal assertion Verifies ASSERT_EQ(expected, actual); EXPECT_EQ(expected, actual); expected &#x3D;&#x3D; actual ASSERT_NE(val1, val2); EXPECT_NE(val1, val2); val1 !&#x3D; val2 ASSERT_LT(val1, val2); EXPECT_LT(val1, val2); val1 &lt; val2 ASSERT_LE(val1, val2); EXPECT_LE(val1, val2); val1 &lt;&#x3D; val2 ASSERT_GT(val1, val2); EXPECT_GT(val1, val2); val1 &gt; val2 ASSERT_GE(val1, val2); EXPECT_GE(val1, val2); val1 &gt;&#x3D; val2 3.2.3 字符串检查 Fatal assertion Nonfatal assertion Verifies ASSERT_STREQ(expected_str, actual_str); EXPECT_STREQ(expected_str,actual_str); the two C strings have the same content ASSERT_STRNE(str1, str2); EXPECT_STRNE(str1, str2); the two C strings have different content ASSERT_STRCASEEQ(expected_str, actual_str); EXPECT_STRCASEEQ(expected_str, actual_str); the two C strings have the same content, ignoring case （忽略大小写） ASSERT_STRCASENE(str1, str2); EXPECT_STRCASENE(str1, str2); the two C strings have different content, ignoring case （忽略大小小） 3.2.4 异常检查 Fatal assertion Nonfatal assertion Verifies ASSERT_THROW(statement, exception_type); EXPECT_THROW(statement, exception_type); statement throws an exception of the given type ASSERT_ANY_THROW(statement); EXPECT_ANY_THROW(statement); statement throws an exception of any type ASSERT_NO_THROW(statement); EXPECT_NO_THROW(statement); statement doesn’t throw any exception 3.2.5 浮点检查 Fatal assertion Nonfatal assertion Verifies ASSERT_FLOAT_EQ(expected, actual); EXPECT_FLOAT_EQ(expected, actual); the two float values are almost equal ASSERT_DOUBLE_EQ(expected, actual); EXPECT_DOUBLE_EQ(expected, actual); the two double values are almost equal 3.2.6 相近值检查 Fatal assertion Nonfatal assertion Verifies ASSERT_NEAR(val1, val2, abs_error); EXPECT_NEAR(val1, val2, abs_error); the difference between val1 and val2 doesn’t exceed the given absolute error 3.3 宏测试接口3.3.1 TESTTEST(test_suite_name, test_name) 其中，test_suite_name 为测试组名，test_name 为测试用例名，一个测试组可包含多个测试用例。注意这里同一个 test_suite 下的 test 会可能相互影响。 3.3.2 TEST_FTEST_F(test_fixture, test_name) TEST_F与TEST的区别是，TEST_F提供了一个初始化函数（SetUp）和一个清理函数(TearDown)，运行每一个TEST_F都会调用 SetUp 和 TearDown 函数，因此所有的TEST_F是互相独立的，都是在初始化状态下运行。多个测试场景需要相同数据配置的情况，用 TEST_F。 使用 TEST_F 前需要创建一个测试类，继承于::testing::Test类。在类内部使用public或者protected定义其成员，使测试子类可以使用其成员。为什么要定义这个测试类？是为了方便我们为每个 TEST_F 创建一个干净独立的环境，即需要定义初始化和清理函数。一般的，“构造函数&#x2F;析构函数” 和 “SetUp&#x2F;TearDown” 这两对都可以用来进行初始化和清理。需要注意不要在 构造&#x2F;析构函数 里抛出异常。 以下选自 apollo 项目的 ConfigManagerTest 片段： 123456789101112131415161718192021222324class ConfigManagerTest : public testing::Test &#123; protected: ConfigManagerTest() : config_manager_(NULL) &#123;&#125; virtual ~ConfigManagerTest() &#123;&#125; virtual void SetUp() &#123; FLAGS_work_root = &quot;modules/perception/data&quot;; FLAGS_config_manager_path = &quot;./config_manager_test/config_manager.config&quot;; config_manager_ = ConfigManager::instance(); &#125; protected: ConfigManager* config_manager_;&#125;;TEST_F(ConfigManagerTest, test_Init) &#123; EXPECT_TRUE(config_manager_-&gt;Init()); EXPECT_EQ(config_manager_-&gt;NumModels(), 3u);&#125;TEST_F(ConfigManagerTest, test_Reset) &#123; EXPECT_TRUE(config_manager_-&gt;Reset()); std::string wrong_root = &quot;wrong_root&quot;; config_manager_-&gt;SetWorkRoot(wrong_root); EXPECT_FALSE(config_manager_-&gt;Reset()); config_manager_-&gt;SetWorkRoot(FLAGS_work_root); 3.4 预处理事件机制在单元测试中，我们经常需要在某个测试套件、测试用例或者整个测试运行之前进行前置条件设置及检查，或者运行之后对运行结果进行校验等操作。在gtest中，称之为事件机制。gtest将事件按照作用的范围不同进行划分，从大到小总共分为3个层次： 整个测试层面，即在测试工程开始前和结束后进行；（Environment层面） 测试套件层面，即在某个测试套件开始前和结束后进行；（TestSuite层面） 测试用例层面，即在某个测试用例开始前和结束后进行；（TestCase层面） 3.4.1 Environment层面实现 Environment 层面的环境构造，需要写一个类，继承testing::Environment类，覆盖里面的 SetUp 和 TearDown 方法。 1234567891011121314151617class myEnvirment : public testing::Environment &#123;public: virtual void SetUp() &#123; cout &lt;&lt; &quot;environment setup&quot; &lt;&lt; endl; &#125; virtual void TearDown() &#123; cout &lt;&lt; &quot;environment teardown&quot; &lt;&lt; endl; &#125;&#125;;int main(int argc, char **argv)&#123; ::testing::InitGoogleTest(&amp;argc, argv); ::testing::AddGlobalTestEnvironment(new myEnvirment()); return RUN_ALL_TESTS();&#125; 3.4.2 TestSuite层面实现 TestSuite 层面的环境构造，需要写一个类，继承testing::Test类，并覆盖它的静态方法：SetUpTestCase 和 TearDownTestCase. 1234567891011121314class FooTest : public testing::Test &#123; protected: static void SetUpTestCase() &#123; shared_resource_ = new ; &#125; static void TearDownTestCase() &#123; delete shared_resource_; shared_resource_ = NULL; &#125; static T* shared_resource_;&#125;;TEST(FooTest, case1)TEST(FooTest, case2) 3.4.3 TestCase层面实现 TestCase 层面的环境构造，需要写一个类，继承testing::Test类，并覆盖它 SetUp 和 TearDown 方法。具体见 3.3.2 TEST_F 小节。 引用： https://google.github.io/googletest/https://cloud.tencent.com/developer/article/2159398","categories":[{"name":"C++那些事","slug":"C-那些事","permalink":"https://xie-peiquan.gitee.io/categories/C-%E9%82%A3%E4%BA%9B%E4%BA%8B/"}],"tags":[{"name":"C++库","slug":"C-库","permalink":"https://xie-peiquan.gitee.io/tags/C-%E5%BA%93/"}]},{"title":"1-glog的使用","slug":"C++那些事/1-glog的使用","date":"2023-11-01T07:16:37.336Z","updated":"2023-11-01T07:16:37.384Z","comments":true,"path":"2023/11/01/C++那些事/1-glog的使用/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/11/01/C++%E9%82%A3%E4%BA%9B%E4%BA%8B/1-glog%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1 软件包介绍glog是google提供的一个轻量级C&#x2F;C++日志库，提供日志文件记录管理等功能。 2 软件包安装123456git clone https://github.com/google/glog.gitsudo apt install autoconf automake libtoolcd glog &amp;&amp; mkdir build &amp;&amp; cd buildcmake ..makesudo make install 3 软件包使用3.1 初始化glog12345678910#include &lt;glog/logging.h&gt;#include &lt;glog/raw_logging.h&gt;int main(int argc, char** argv)&#123; FLAGS_log_dir = &quot;~/logs&quot;; //日志保存目录，需要已存在 google::InitGoogleLogging(&quot;main&quot;); //括号内是程序名 ... google::ShutdownGoogleLogging(); //必要，防止内存溢出 return 0;&#125; 3.2 等级记录12345VLOG(4) &lt;&lt; &quot;[DEBUG] &quot; &lt;&lt; ...LOG(INFO) &lt;&lt; ...LOG(WARNING) &lt;&lt; ...LOG(ERROR) &lt;&lt; ...LOG(FATAL) &lt;&lt; ... 3.3 条件记录12LOG_IF(INFO, cond) &lt;&lt; ...LOG_IF(ERROR, cond) &lt;&lt; ... 3.4 频次记录123LOG_EVERY_N(INFO, freq) //每隔freq次记录一次LOG_EVERY_N(WARNING, freq)LOG_EVERY_N(ERROR, freq) 3.5 扩展参数12345678FLAGS_logtostderr = true; //设置日志消息是否转到标准输出而不是日志文件FLAGS_alsologtostderr = true; //设置日志消息除了日志文件之外是否输出到标准输出FLAGS_colorlogtostderr = true; //设置记录到标准输出的颜色消息（如果终端支持）FLAGS_log_prefix = true; //设置日志前缀是否应该添加到每行输出FLAGS_logbufsecs = 0; //设置可以缓冲日志的最大秒数，0指实时输出FLAGS_max_log_size = 10; //设置最大日志文件大小（以MB为单位）,超过会对文件进行分割FLAGS_stop_logging_if_full_disk = true; //设置是否在磁盘已满时避免日志记录到磁盘FLAGS_minloglevel = google::GLOG_WARNING； //设置最小处理日志的级别 3.6 扩展函数123google::SetLogDestination(google::GLOG_FATAL, &quot;~/logs/FATAL_&quot;); //FATAL级别的日志都存放到logs目录下且前缀为FATAL_google::SetLogFilenameExtension(&quot;logExtension&quot;); //在日志文件名中级别后添加一个扩展名,适用于所有严重级别google::SetStderrLogging(google::GLOG_INFO); //大于指定级别的日志都输出到标准输出 4 应用编译g++ 编译添加链接 -lglog 即可。 https://github.com/google/gloghttps://www.cnblogs.com/xl2432/p/11825966.html","categories":[{"name":"C++那些事","slug":"C-那些事","permalink":"https://xie-peiquan.gitee.io/categories/C-%E9%82%A3%E4%BA%9B%E4%BA%8B/"}],"tags":[{"name":"C++库","slug":"C-库","permalink":"https://xie-peiquan.gitee.io/tags/C-%E5%BA%93/"}]},{"title":"0-Gflags的使用","slug":"C++那些事/0-Gflags的使用","date":"2023-10-31T06:51:42.187Z","updated":"2023-10-31T06:51:42.239Z","comments":true,"path":"2023/10/31/C++那些事/0-Gflags的使用/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/10/31/C++%E9%82%A3%E4%BA%9B%E4%BA%8B/0-Gflags%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1 软件包介绍Gflags是一种命令行解析工具(处理命令行参数的库)，主要用于C++程序 解析用命令行执行可执行文件时传入的参数。 Gflags支持的参数定义类型如下: 123456DEFINE_bool: booleanDEFINE_int32: 32-bit integerDEFINE_int64: 64-bit integerDEFINE_uint64: unsigned 64-bit integerDEFINE_double: doubleDEFINE_string: C++ string 2 软件包安装12345git clone https://github.com/gflags/gflags.gitmkdir build &amp;&amp; cd buildcmake ..makemake install 3 软件包使用3.1 参数变量定义&#x2F;声明参数定义通过DEFINE_type宏实现，具体接口见 第1节，使用如下： 12//该宏的三个参数含义分别为：参数名，默认值，参数的帮助信息。DEFINE_bool(big_menu, true, &quot;Include &#x27;advanced&#x27; options in the menu listing&quot;); 参数声明通过 DECLARE_type宏实现，即将 第1节 的 DEFINE_ 改为 DECLARE_，一般将 DECLARE_type 放在头文件中。 1DECLARE_bool(big_menu) 运行程序时使用 ./app --port 17201 即可设置参数。 3.2 参数引用参数引用通过在参数名前添加 FLAGS_ 引用，如：FLAGS_big_menu . 3.3 参数解析参数解析一般放置于main函数入口对argc和argv 进行解析，使用如下： 12345678#include &lt;gflags/gflags.h&gt;int main(int argc, char** argv)&#123; gflags::ParseCommandLineFlags(&amp;argc, &amp;argv, true); ...... gflags::ShutDownCommandLineFlags(); return 0;&#125; 其中，argc 传递的参数个数，argv为命令行传递的参数表，第三个参数功能如下 ture: 函数处理完成后，argv中只保留argv[0]，argc会被设置为1。 false: argv和argc会被保留，但是注意函数会调整argv中的顺序。 3.4 参数检验Gflags库支持用户定制对输入参数的检验函数，使用如下： 12345678static bool ValidatePort(const char* flagname, int32 value) &#123; if (value &gt; 0 &amp;&amp; value &lt; 32768) // value is ok return true; printf(&quot;Invalid value for --%s: %d\\n&quot;, flagname, (int)value); return false;&#125;DEFINE_int32(port, 0, &quot;What port to listen on&quot;);static const bool port_dummy = gflags::RegisterFlagValidator(&amp;FLAGS_port, &amp;ValidatePort); 3.5 设定程序 help &#x2F;version 信息12google::SetVersionString(string_type);google::SetUsageMessage(string_type); 运行程序时使用 ./app --version 和 ./app --help 即可访问版本和帮助信息。 3.6 从文件加载参数配置文件 app.conf 配置信息格式如下： 123--host=172.16.12.10--port=8955--sign=false 运行程序时使用 ./app --flagfile=app.conf 来加载参数文件。 4 程序编译g++ 编译添加链接 -lgflags 即可。 https://gflags.github.io/gflagshttps://blog.csdn.net/kenjianqi1647/article/details/106598057","categories":[{"name":"C++那些事","slug":"C-那些事","permalink":"https://xie-peiquan.gitee.io/categories/C-%E9%82%A3%E4%BA%9B%E4%BA%8B/"}],"tags":[{"name":"C++库","slug":"C-库","permalink":"https://xie-peiquan.gitee.io/tags/C-%E5%BA%93/"}]},{"title":"11-发布ROS功能包","slug":"ROS1/11-发布ROS功能包","date":"2023-09-14T06:59:50.529Z","updated":"2023-09-14T06:59:50.581Z","comments":true,"path":"2023/09/14/ROS1/11-发布ROS功能包/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/14/ROS1/11-%E5%8F%91%E5%B8%83ROS%E5%8A%9F%E8%83%BD%E5%8C%85/","excerpt":"","text":"当我们开发完某个功能包，要将功能包发布出去。如果是带源码发布，直接将工作空间下 src 目录下的整个功能包源码直接拷贝出去，重新编译运行即可。有时候我们不想公开源码，希望不带源码发布，怎么处理呢？ROS提供了相关的工具支持，具体如下： 1 catkin_make install1.1 修改CMakeLists在功能包下的CMakeLists文件里，找到以下项进行修改： 将编译好的可执行文件，依赖库拷贝到 install 的 lib&#x2F; 和 bin&#x2F; 目录下： 123456## Mark executables and/or libraries for installation install(TARGETS talker_node listener_node ARCHIVE DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125; LIBRARY DESTINATION $&#123;CATKIN_PACKAGE_LIB_DESTINATION&#125; RUNTIME DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125; ) 将头文件拷贝到 install 的 include&#x2F; 目录下，非必要。 123456## Mark cpp header files for installation install(DIRECTORY include/$&#123;PROJECT_NAME&#125;/ DESTINATION $&#123;CATKIN_PACKAGE_INCLUDE_DESTINATION&#125; FILES_MATCHING PATTERN &quot;*.h&quot; PATTERN &quot;.svn&quot; EXCLUDE ) 将其他资源文件拷贝到 install 的share&#x2F; 目录下，如 urdf mesh rviz ，其下的所有子目录的文件也会拷贝过去，非必要。 123456789101112install(DIRECTORY model DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125; )install(DIRECTORY urdf DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125; )install(DIRECTORY mesh DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125; )install(DIRECTORY rviz DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125; ) 将 launch 文件拷贝到 install 的 launch&#x2F; 目录下，非必要。 123456## Mark other files for installation (e.g. launch and bag files, etc.)install(FILES launch/bringup.launch DESTINATION $&#123;CATKIN_PACKAGE_SHARE_DESTINATION&#125;/launch) 将 python 脚本拷贝到 install 的 lib&#x2F; 目录下，非必要。遗憾的是，ROS并未对发布的 python 脚本进行任何加密，哪怕是转成 pyc 文件，所以用 C++ 写吧哈哈… 当然也并非没有其他方法，可以借助 pyinstaller 工具把 python 脚本打包（pyinstaller -F -w xxx.py）成可执行文件，放到 install 的 lib&#x2F; 目录下，我初步验证是可以的。当然 pyinstaller 本身也并不安全，关于python源码的保护，或许还有其他方法？ 123456## Mark executable scripts (Python etc.) for installation install(PROGRAMS scripts/talker.py scripts/listener.py DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125; ) 1.2 生成 install 目录在工作空间下执行 catkin_make install 则会生成 install 目录，目录内容如下。发布后 source 该目录下的 setup.bash 便可以运行。当然运行的前提是同处理器架构，不同处理器架构得用交叉编译，后续再补一节。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465install├── _setup_util.py├── env.sh├── include│ └── learning_service│ ├── Person.h│ ├── PersonRequest.h│ └── PersonResponse.h├── lib│ ├── learning_service│ │ ├── person_client│ │ ├── person_server│ │ ├── turtle_command_server│ │ └── turtle_spawn│ ├── pkgconfig│ │ └── learning_service.pc│ └── python3│ └── dist-packages│ └── learning_service│ ├── __init__.py│ ├── __pycache__│ │ └── __init__.cpython-38.pyc│ └── srv│ ├── _Person.py│ ├── __init__.py│ └── __pycache__│ ├── _Person.cpython-38.pyc│ └── __init__.cpython-38.pyc├── local_setup.bash├── local_setup.sh├── local_setup.zsh├── setup.bash├── setup.sh├── setup.zsh└── share ├── common-lisp │ └── ros │ └── learning_service │ └── srv │ ├── Person.lisp │ ├── _package.lisp │ ├── _package_Person.lisp │ └── learning_service-srv.asd ├── gennodejs │ └── ros │ └── learning_service │ ├── _index.js │ └── srv │ ├── Person.js │ └── _index.js ├── learning_service │ ├── cmake │ │ ├── learning_service-msg-extras.cmake │ │ ├── learning_service-msg-paths.cmake │ │ ├── learning_serviceConfig-version.cmake │ │ └── learning_serviceConfig.cmake │ ├── package.xml │ └── srv │ └── Person.srv └── roseus └── ros └── learning_service ├── manifest.l └── srv └── Person.l 2 bloom-generate从上节可以发现 catkin_make install 生成出来的 install 目录很庞大，有很多冗余的文件。并且以那种形式发布出去的功能包，每次运行都得 source 一下，有没有办法让我们的功能包安装进ROS的系统目录呢？ bloom-generate 提供了更简单的方法，其将源码编译成一个ROS的二进制安装包，安装时将可执行文件等必要文件注入到ROS系统目录下，在功能包的管理上更方便，具体如下： 2.1 修改CMakeLists由于bloom-generate 同样借助 catkin 编译，因此我们同样需要修改 CMakeLists 文件，步骤跟以上一模一样，这里不再赘述。 2.2 编译二进制安装包1234安装工具：sudo apt install python-bloom fakerootcd 到功能包目录下，运行以下命令：bloom-generate rosdebian --os-name ubuntu --ros-distro noeticfakeroot debian/rules binary 2.3 安装与卸载12sudo apt install ros-noetic-xxxx.debsudo apt remove ros-noetic-xxxx 3 遗留问题以上两种方式发布功能包还是有问题，暂且把它记下来，等搞明白了再做更新。 如果需要不对 python 开源，如何保护？ 自定义的 msg , srv, action 接口都会跟着发布出去，如果不开源，如何保护？ http://wiki.ros.org/cn/ROS/Tutorials","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"ROS1零碎笔记","slug":"ROS1/ROS1零碎笔记","date":"2023-09-09T09:00:30.490Z","updated":"2023-09-11T03:22:55.201Z","comments":true,"path":"2023/09/09/ROS1/ROS1零碎笔记/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/09/ROS1/ROS1%E9%9B%B6%E7%A2%8E%E7%AC%94%E8%AE%B0/","excerpt":"","text":"ros::spin 和 ros::spinOnce 的区别这俩函数学名叫ROS消息回调处理函数，即消息回调要经过他俩中一个才能回调执行。两者区别在于 spin 有进无出，一直阻塞等待消息到来才去回调处理函数；而 **spinOnce ** 查询一次消息队列，不管有没有消息都会往下执行，spinOnce 往往需要考虑调用消息的时机，调用频率，以及消息池的大小，这些都要根据现实情况协调好，不然会造成数据丢包或者延迟的错误。 while(1) 和 while(ros::ok())的区别最大的区别在于，进程接收ctrl-C指令时，while(1)的程序中止退出，而while(ros::ok())则是跳出循环，注意此时程序并未中止，继续执行循环体外的清理工作。这里同时列出while(ros::ok())会在什么情况下退出： 程序接收到 Ctrl-C 信号 本节点被一个同名同姓的节点从网络中踢出 程序中调用 ros::shutdown() 程序中所有的 ros::NodeHandles 都被销毁 消息结构查询https://wiki.ros.org/+消息包名 功能包查询https://index.ros.org/ API查询http://wiki.ros.org/APIs","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"10-动态参数机制简汇","slug":"ROS1/10-动态参数机制简汇","date":"2023-09-08T09:16:20.641Z","updated":"2023-09-08T09:16:20.693Z","comments":true,"path":"2023/09/08/ROS1/10-动态参数机制简汇/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/08/ROS1/10-%E5%8A%A8%E6%80%81%E5%8F%82%E6%95%B0%E6%9C%BA%E5%88%B6%E7%AE%80%E6%B1%87/","excerpt":"","text":"1 动态参数的作用​ ROS中的参数服务器无法在线动态更新，也就是说如果Listener不主动查询参数值，就无法获知Talker是否已经修改了参数。这就对ROS参数服务器的使用造成了很大的局限，很多场景下我们还是需要动态更新参数的机制，例如参数调试、功能切换等，所以ROS提供了另外一个非常有用的功能包 —— dynamic_reconfigure，实现这种动态配置参数的机制。​ 动态重配置的重点是提供一种标准的方法，将节点的一个子集参数公开给外部重配置。使用客户端程序，例如gui，可以向节点查询一组可动态配置的参数，包括它们的名称、类型、范围，并向用户提供一个自定义接口。​ 以下介绍如何给功能包添加动态参数。 2 添加动态参数2.1 添加 cfg 文件在功能包下新建 cfg 目录，并新建 cfg 文件（其实是python脚本），记得给 cfg 文件添加可执行权限。这里以典型的pid.cfg文件为例，内容如下： 1234567891011121314151617#!/usr/bin/env pythonPACKAGE = &quot;learning_topic&quot; #所属功能包名 #初始化ROS，并导入参数生成器from dynamic_reconfigure.parameter_generator_catkin import *#初始化参数生成器gen = ParameterGenerator()#定义需动态配置的参数，格式为#gen.add(name , type, level, description, default, min, max)gen.add(&quot;KP&quot;, double_t, 0, &quot;KP_param&quot;, 225.0, 0, 500)gen.add(&quot;KI&quot;, double_t, 0, &quot;KI_param&quot;, 150.0, 0, 300)gen.add(&quot;KD&quot;, double_t, 0, &quot;KD_param&quot;, 50.0, 0, 300)#生成必要文件并退出#dynamic_PID为运行时的节点名，pid为生成文件的前缀exit(gen.generate(PACKAGE, &quot;dynamic_PID&quot;, &quot;pid&quot;)) 参数解释：gen.add(name , type, level, description, default, min, max) – name：参数名，使用字符串描述；– type：定义参数的类型，可以是int_t, double_t, str_t, 或者bool_t；– level：需要传入参数动态配置回调函数中的掩码，在回调函数中会修改所有参数的掩码，表示参数已经进行修改；– description：描述参数作用的字符串；– default：设置参数的默认值；– min：可选，设置参数的最小值，对于字符串和布尔类型值不生效；– max：可选，设置参数的较大值，对于字符串和布尔类型值不生效； gen.generate(PACKAGE, &quot;dynamic_PID&quot;, &quot;pid&quot;) dynamic_PID：为运行时的节点名。pid：为生成文件的前缀，如pidConfig，该前缀需要与配置文件名相同。 补python版本： 123456789101112131415161718#! /usr/bin/env pythonimport rospyfrom dynamic_reconfigure.server import Serverfrom learning_topic.cfg import pidConfigdef dp_callback(config,level): rospy.loginfo(&quot;Reconfigure Request:%d %d %d&quot;, config.KP, config.KI, config.KD ) return configif __name__ == &quot;__main__&quot;: rospy.init_node(&quot;pid_app&quot;) server = Server(pidConfig, dp_callback) rospy.loginfo(&quot;Spinning node&quot;) rospy.spin() 2.2 编译修改cmake修改：在CmakeLists找到如下项进行修改： 12generate_dynamic_reconfigure_options(... cfg/pid.cfg)find_package(... dynamic_reconfigure) catkin_make 后便可在devel&#x2F;include 目录下发现 pidConfig.h 头文件. 3 应用节点编写3.1 添加动态参数应用节点在功能包 src 目录下新增 pid_app.cpp 文件，内容如下： 1234567891011121314151617181920212223242526272829#include &lt;ros/ros.h&gt;#include &lt;dynamic_reconfigure/server.h&gt;#include &lt;learning_topic/pidConfig.h&gt;//定义回调函数，当客户端请求修改参数时，服务端即可跳转到回调函数中进行处理。//传入值有两个，一个是参数更新的配置值，一个是表示参数修改的掩码void callback(learning_topic::pidConfig &amp;config, uint32_t level) &#123; ROS_INFO(&quot;Reconfigure Request: %f %f %f&quot;, config.KP, config.KI, config.KD);&#125;int main(int argc, char **argv)&#123; //初始化ROS节点 ros::init(argc, argv, &quot;pid_app&quot;); //创建了一个参数动态配置的服务端实例，参数配置的类型就是配置文件中描述的类型 //该服务端实例会监听客户端的参数配置请求。 dynamic_reconfigure::Server&lt;learning_topic::pidConfig&gt; server; dynamic_reconfigure::Server&lt;learning_topic::pidConfig&gt;::CallbackType f; //并将回调函数和服务端绑定 f = boost::bind(&amp;callback, _1, _2); server.setCallback(f); ROS_INFO(&quot;Spinning node&quot;); ros::spin(); return 0;&#125; 3.2 编译修改cmake修改：在CmakeLists末尾添加如下修改： 123add_executable(pid_app src/pid_app.cpp)target_link_libraries(pid_app $&#123;catkin_LIBRARIES&#125;)add_dependencies(pid_app $&#123;PROJECT_NAME&#125;_gencfg) 3.3 GUI动态调参123终端1：roscore终端2：rosrun learning_topic pid_app终端3：rosrun rqt_reconfigure rqt_reconfigure 效果如下： http://wiki.ros.org/cn/ROS/Tutorialshttps://blog.csdn.net/weixin_43569276/article/details/102928817","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"9-action通信机制简汇","slug":"ROS1/9-action通信机制简汇","date":"2023-09-04T09:12:07.398Z","updated":"2023-09-04T09:12:07.454Z","comments":true,"path":"2023/09/04/ROS1/9-action通信机制简汇/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/04/ROS1/9-action%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E6%B1%87/","excerpt":"","text":"action实现了一种类似于service的请求&#x2F;响应通讯机制，区别在于action带有反馈机制，用来不断向客户端反馈任务的进度，并且还支持在任务中途中止运行。操作起来就像这样子，客户端给服务端抛出一个目标，然后客户端就可以去干别的事情了，在任务执行期间，客户端会以消息的形式，周期性地接收到来自服务端的进度反馈，如果没有终止任务的话这个过程会一直延续到收到最终的结果。当然也可以随时终止当前的操作，开始一个全新的操作。 1 action的实现机制action 的 client和server之间通过actionlib定义的“action protocol”进行通讯。这种通讯协议是基于ROS的 topic 机制实现的，为用户提供了client和server的接口，接口如下图所示： goal：client 发送任务目标 cancel：client 请求取消任务 status：server通知client当前的状态 feedback：server周期反馈任务运行的监控数据 result：server向client发送任务的执行结果，这个topic只会发布一次。 2 自定义接口2.1 action文件编写在 ros_ws&#x2F;src&#x2F;hello&#x2F;action目录下创建 DoDishes.action接口文件，注意首字母必须大写。接口示例如下： 12345678# Define the goaluint32 dishwasher_id---# Define the resultuint32 total_dishes_cleaned---# Define a feedback messagefloat32 percent_complete 2.2 编译修改 CMakeLists修改：在对应位置进行如下修改：(查找对应项改，不要改变各项的顺序) 123find_package(catkin REQUIRED ... genmsg actionlib_msgs actionlib)add_action_files(DIRECTORY action FILES DoDishes.action)generate_messages(DEPENDENCIES ... actionlib_msgs) package.xml修改：在对应位置添加如下： 1234&lt;build_depend&gt;actionlib&lt;/build_depend&gt;&lt;build_depend&gt;actionlib_msgs&lt;/build_depend&gt;&lt;exec_depend&gt;actionlib&lt;/exec_depend&gt;&lt;exec_depend&gt;actionlib_msgs&lt;/exec_depend&gt; 编译完成之后会在 devel&#x2F;share&#x2F;hello&#x2F;msg&#x2F; 目录下产生相关的.msg文件： 2 action Client（CPP）注意要将**DoDishesAction **的前缀修改为自己创建的功能包名字。 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;actionlib/client/simple_action_client.h&gt;#include &quot;hello/DoDishesAction.h&quot;typedef actionlib::SimpleActionClient&lt;hello::DoDishesAction&gt; Client;// 当action完成后会调用次回调函数一次void doneCb(const actionlib::SimpleClientGoalState&amp; state, const hello::DoDishesResultConstPtr&amp; result)&#123; ROS_INFO(&quot;Yay! The dishes are now clean&quot;); ros::shutdown();&#125;// 当action激活后会调用次回调函数一次void activeCb()&#123; ROS_INFO(&quot;Goal just went active&quot;);&#125;// 收到feedback后调用的回调函数void feedbackCb(const hello::DoDishesFeedbackConstPtr&amp; feedback)&#123; ROS_INFO(&quot; percent_complete : %f &quot;, feedback-&gt;percent_complete);&#125;int main(int argc, char** argv)&#123; ros::init(argc, argv, &quot;do_dishes_client&quot;); // 定义一个客户端 Client client(&quot;do_dishes&quot;, true); // 等待服务器端 ROS_INFO(&quot;Waiting for action server to start.&quot;); client.waitForServer(); ROS_INFO(&quot;Action server started, sending goal.&quot;); // 创建一个action的goal hello::DoDishesGoal goal; goal.dishwasher_id = 1; // 发送action的goal给服务器端，并且设置回调函数 client.sendGoal(goal, &amp;doneCb, &amp;activeCb, &amp;feedbackCb); ros::spin(); return 0;&#125; 3 action Client（Python）123456789101112131415161718#! /usr/bin/env python# -*- coding: utf-8 -*-import roslibroslib.load_manifest(&#x27;my_pkg_name&#x27;)import rospyimport actionlibfrom chores.msg import DoDishesAction, DoDishesGoalif __name__ == &#x27;__main__&#x27;: rospy.init_node(&#x27;do_dishes_client&#x27;) client = actionlib.SimpleActionClient(&#x27;do_dishes&#x27;, DoDishesAction) client.wait_for_server() goal = DoDishesGoal() # Fill in the goal here client.send_goal(goal) client.wait_for_result(rospy.Duration.from_sec(5.0)) 4 action Server（CPP）123456789101112131415161718192021222324252627282930313233343536#include &lt;ros/ros.h&gt;#include &lt;actionlib/server/simple_action_server.h&gt;#include &quot;hello/DoDishesAction.h&quot;typedef actionlib::SimpleActionServer&lt;hello::DoDishesAction&gt; Server;// 收到action的goal后调用的回调函数void execute(const hello::DoDishesGoalConstPtr&amp; goal, Server* as)&#123; ros::Rate r(1); hello::DoDishesFeedback feedback; ROS_INFO(&quot;Dishwasher %d is working.&quot;, goal-&gt;dishwasher_id); // 假设洗盘子的进度，并且按照1hz的频率发布进度feedback for(int i=1; i&lt;=10; i++) &#123; feedback.percent_complete = i * 10; as-&gt;publishFeedback(feedback); r.sleep(); &#125; // 当action完成后，向客户端返回结果 ROS_INFO(&quot;Dishwasher %d finish working.&quot;, goal-&gt;dishwasher_id); as-&gt;setSucceeded();&#125;int main(int argc, char** argv)&#123; ros::init(argc, argv, &quot;do_dishes_server&quot;); ros::NodeHandle n; // 定义一个服务器 Server server(n, &quot;do_dishes&quot;, boost::bind(&amp;execute, _1, &amp;server), false); // 服务器开始运行 server.start(); ros::spin(); return 0;&#125; 5 action Server（Python）1234567891011121314151617181920212223#! /usr/bin/env python# -*- coding: utf-8 -*-import roslibroslib.load_manifest(&#x27;my_pkg_name&#x27;)import rospyimport actionlibfrom chores.msg import DoDishesActionclass DoDishesServer: def __init__(self): self.server = actionlib.SimpleActionServer(&#x27;do_dishes&#x27;, DoDishesAction, self.execute, False) self.server.start() def execute(self, goal): # Do lots of awesome groundbreaking robot stuff here self.server.set_succeeded()if __name__ == &#x27;__main__&#x27;: rospy.init_node(&#x27;do_dishes_server&#x27;) server = DoDishesServer() rospy.spin() http://wiki.ros.org/cn/ROS/Tutorialshttps://www.guyuehome.com/","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"8-坐标变换TF简述","slug":"ROS1/8-坐标变换TF简述","date":"2023-09-04T03:16:23.916Z","updated":"2023-09-04T03:16:23.964Z","comments":true,"path":"2023/09/04/ROS1/8-坐标变换TF简述/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/04/ROS1/8-%E5%9D%90%E6%A0%87%E5%8F%98%E6%8D%A2TF%E7%AE%80%E8%BF%B0/","excerpt":"","text":"在一个机器人系统中，一般会存在多个部件，每个部件可能会有自己的运动轨迹，这样在一个机器人中就存在多个坐标系。通常，我们会根据坐标系间的差距来驱动某个部件的运动，这里就存在坐标变换。这里简单举例，如下图(古月居)，我们常见的ROS小车激光雷达测距，假设这里只存在车身和雷达两个部件，这里有两个坐标系：车身坐标系（base_link）和雷达坐标系（base_laser）。雷达测距的结果是墙面相对于雷达坐标系的距离，而通常我们需要车身相对于墙面的距离，这里就需要将雷达距离转换为车身距离。 1 TF 功能包ROS中的TF功能包为我们提供坐标变换功能，可以帮助我们免去复杂的坐标转换。以下为TF常用命令： rosrun tf tf_echo node1 node2 该命令可用于查看两个坐标系之间的差距。rosrun rviz rviz -d &#39;rospack find turtle_tf&#39; /rviz/turtle_rviz.rviz 可视化坐标系之间的关系。 2 坐标系广播（CPP）1234567891011121314151617181920212223242526272829303132#include &lt;ros/ros.h&gt;#include &lt;tf/transform_broadcaster.h&gt;#include &lt;turtlesim/Pose.h&gt;std::string turtle_name;void poseCallback(const turtlesim::PoseConstPtr&amp; msg)&#123; // 创建tf的广播器 static tf::TransformBroadcaster br; // 初始化tf数据 tf::Transform transform; transform.setOrigin( tf::Vector3(msg-&gt;x, msg-&gt;y, 0.0) ); tf::Quaternion q; q.setRPY(0, 0, msg-&gt;theta); transform.setRotation(q); // 广播world与海龟坐标系之间的tf数据 br.sendTransform(tf::StampedTransform(transform, ros::Time::now(), &quot;world&quot;, turtle_name));&#125;int main(int argc, char** argv)&#123; // 初始化ROS节点 ros::init(argc, argv, &quot;my_tf_broadcaster&quot;); turtle_name = argv[1]; // 订阅海龟的位姿话题 ros::NodeHandle node; ros::Subscriber sub = node.subscribe(turtle_name+&quot;/pose&quot;, 10, &amp;poseCallback); // 循环等待回调函数 ros::spin(); return 0;&#125;; cmake修改，在CMakeLists里面找到以下项并修改： 1234567find_package(catkin REQUIRED COMPONENTS ...... tf turtlesim)add_executable(turtle_tf_broadcaster src/turtle_tf_broadcaster.cpp)target_link_libraries(turtle_tf_broadcaster $&#123;catkin_LIBRARIES&#125;) 3 坐标系广播（Python）12345678910111213141516171819202122232425#!/usr/bin/env python# -*- coding: utf-8 -*-import roslibroslib.load_manifest(&#x27;learning_tf&#x27;)import rospyimport tfimport turtlesim.msgdef handle_turtle_pose(msg, turtlename): br = tf.TransformBroadcaster() br.sendTransform((msg.x, msg.y, 0), tf.transformations.quaternion_from_euler(0, 0, msg.theta), rospy.Time.now(), turtlename, &quot;world&quot;)if __name__ == &#x27;__main__&#x27;: rospy.init_node(&#x27;turtle_tf_broadcaster&#x27;) turtlename = rospy.get_param(&#x27;~turtle&#x27;) rospy.Subscriber(&#x27;/%s/pose&#x27; % turtlename, turtlesim.msg.Pose, handle_turtle_pose, turtlename) rospy.spin() 4 坐标系监听（CPP）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;ros/ros.h&gt;#include &lt;tf/transform_listener.h&gt;#include &lt;geometry_msgs/Twist.h&gt;#include &lt;turtlesim/Spawn.h&gt;int main(int argc, char** argv)&#123; // 初始化ROS节点 ros::init(argc, argv, &quot;my_tf_listener&quot;); // 创建节点句柄 ros::NodeHandle node; // 请求产生turtle2 ros::service::waitForService(&quot;/spawn&quot;); ros::ServiceClient add_turtle = node.serviceClient&lt;turtlesim::Spawn&gt;(&quot;/spawn&quot;); turtlesim::Spawn srv; add_turtle.call(srv); // 创建发布turtle2速度控制指令的发布者 ros::Publisher turtle_vel = node.advertise&lt;geometry_msgs::Twist&gt;(&quot;/turtle2/cmd_vel&quot;, 10); // 创建tf的监听器 tf::TransformListener listener; ros::Rate rate(10.0); while (node.ok()) &#123; // 获取turtle1与turtle2坐标系之间的tf数据 tf::StampedTransform transform; try &#123; listener.waitForTransform(&quot;/turtle2&quot;, &quot;/turtle1&quot;, ros::Time(0), ros::Duration(3.0)); listener.lookupTransform(&quot;/turtle2&quot;, &quot;/turtle1&quot;, ros::Time(0), transform); &#125; catch (tf::TransformException &amp;ex) &#123; ROS_ERROR(&quot;%s&quot;,ex.what()); ros::Duration(1.0).sleep(); continue; &#125; // 根据turtle1与turtle2坐标系之间的位置关系，发布turtle2的速度控制指令 geometry_msgs::Twist vel_msg; vel_msg.angular.z = 4.0 * atan2(transform.getOrigin().y(), transform.getOrigin().x()); vel_msg.linear.x = 0.5 * sqrt(pow(transform.getOrigin().x(), 2) + pow(transform.getOrigin().y(), 2)); turtle_vel.publish(vel_msg); rate.sleep(); &#125; return 0;&#125;; 5 坐标系监听（Python）1234567891011121314151617181920212223242526272829303132#!/usr/bin/env python# -*- coding: utf-8 -*-import roslibroslib.load_manifest(&#x27;learning_tf&#x27;)import rospyimport mathimport tfimport geometry_msgs.msgimport turtlesim.srvif __name__ == &#x27;__main__&#x27;: rospy.init_node(&#x27;turtle_tf_listener&#x27;) listener = tf.TransformListener() rospy.wait_for_service(&#x27;spawn&#x27;) spawner = rospy.ServiceProxy(&#x27;spawn&#x27;, turtlesim.srv.Spawn) spawner(4, 2, 0, &#x27;turtle2&#x27;) turtle_vel = rospy.Publisher(&#x27;turtle2/cmd_vel&#x27;, geometry_msgs.msg.Twist,queue_size=1) rate = rospy.Rate(10.0) while not rospy.is_shutdown(): try: (trans,rot) = listener.lookupTransform(&#x27;/turtle2&#x27;, &#x27;/turtle1&#x27;, rospy.Time(0)) except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException): continue angular = 4 * math.atan2(trans[1], trans[0]) linear = 0.5 * math.sqrt(trans[0] ** 2 + trans[1] ** 2) cmd = geometry_msgs.msg.Twist() cmd.linear.x = linear cmd.angular.z = angular turtle_vel.publish(cmd) rate.sleep() http://wiki.ros.org/cn/ROS/Tutorialshttps://www.guyuehome.com/","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"7-launch启动节点","slug":"ROS1/7-launch启动节点","date":"2023-09-03T16:46:30.237Z","updated":"2023-09-03T16:46:30.297Z","comments":true,"path":"2023/09/04/ROS1/7-launch启动节点/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/04/ROS1/7-launch%E5%90%AF%E5%8A%A8%E8%8A%82%E7%82%B9/","excerpt":"","text":"1 基本语法 &lt;launch&gt; launch文件中的根元素采用&lt;launch&gt;标签定义 &lt;node&gt; 启动节点，格式： 1&lt;node pkg=&quot;package-name&quot; name=&quot;node-name&quot; type=&quot;exec-name&quot;/&gt; 其中，pkg 是节点所在功能包名称，type是节点的可执行文件名称，name是节点运行时名称，可取代源码中的节点名。除此之外，还有output参数，可控制日志是否打印在终端里面；respawn可以控制节点如果挂掉是否要重新拉起；required可以控制某个节点是否要启动；ns可以给节点添加域名空间；args可以给节点输入参数。 &lt;param&gt; &#x2F; &lt;rosparam&gt; 设置ROS系统运行中的参数，存储在参数服务器中。格式： 12设置某个值形式：&lt;param name=&quot;output_frame&quot; value=&quot;odom&quot;/&gt;加载参数文件形式：&lt;rosparam file=&quot;params.yaml&quot; command=&quot;load&quot; ns=&quot;params&quot;/&gt; 注：写在&lt;node&gt;里面的 param 其在参数服务器的名字为 node-name&#x2F;param-name,多了node-name的前缀。 &lt;arg&gt; launch文件内部的局部变量，仅限于launch文件使用，格式： 1234&lt;arg name=&quot;arg-name&quot; default=&quot;arg-value&quot;/&gt;调用：&lt;param name=&quot;foo&quot; value=&quot;$(arg arg-name)&quot;/&gt;&lt;node pkg=&quot;package-name&quot; name=&quot;node-name&quot; type=&quot;exec-name&quot; args=&quot;$(arg arg-name)&quot;/&gt; &lt;remap&gt; 重映射ROS计算图资源的命名，格式： 1&lt;remap from=&quot;/turtlebot/cmd_vel&quot; to=&quot;/cmd_vel&quot;/&gt; &lt;include&gt; 包含其他 launch 文件，类似C语言中的头文件包含，格式： 1&lt;include file=&quot;$(dirname)/other.launch&quot;/&gt; 2 创建 launch 文件在 ros_ws&#x2F;src&#x2F;hello&#x2F;launch 目录下创建 simple.launch文件。 1234&lt;launch&gt; &lt;node pkg=&quot;learning_topic&quot; type=&quot;person_subscriber&quot; name=&quot;talker&quot; output=&quot;screen&quot; /&gt; &lt;node pkg=&quot;learning_topic&quot; type=&quot;person_publisher&quot; name=&quot;listener&quot; output=&quot;screen&quot; /&gt; &lt;/launch&gt; 3 运行 launch文件1234cd ros_wscatkin_makesource devel/setup.bashroslaunch &lt;pack-name&gt; &lt;launch-name&gt;","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"6-param通信机制简汇","slug":"ROS1/6-param通信机制简汇","date":"2023-09-03T16:46:29.861Z","updated":"2023-09-03T16:46:29.969Z","comments":true,"path":"2023/09/04/ROS1/6-param通信机制简汇/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/04/ROS1/6-param%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E6%B1%87/","excerpt":"","text":"1 全局参数模型 1.1 全局参数配置（CPP）1234567891011121314151617181920212223242526272829#include &lt;string&gt;#include &lt;ros/ros.h&gt;#include &lt;std_srvs/Empty.h&gt;int main(int argc, char **argv)&#123; int red, green, blue; // ROS节点初始化 ros::init(argc, argv, &quot;parameter_config&quot;); // 创建节点句柄 ros::NodeHandle node; // 读取背景颜色参数 ros::param::get(&quot;/background_r&quot;, red); ros::param::get(&quot;/background_g&quot;, green); ros::param::get(&quot;/background_b&quot;, blue); ROS_INFO(&quot;Get Backgroud Color[%d, %d, %d]&quot;, red, green, blue); // 设置背景颜色参数 ros::param::set(&quot;/background_r&quot;, 255); ros::param::set(&quot;/background_g&quot;, 255); ros::param::set(&quot;/background_b&quot;, 255); ROS_INFO(&quot;Set Backgroud Color[255, 255, 255]&quot;); // 调用服务，刷新背景颜色 ros::service::waitForService(&quot;/clear&quot;); ros::ServiceClient clear_background = node.serviceClient&lt;std_srvs::Empty&gt;(&quot;/clear&quot;); std_srvs::Empty srv; clear_background.call(srv); sleep(1); return 0;&#125; 1.2 全局参数配置（Python）与CPP类似，只是API稍微不同，get &#x2F; set接口如下： 12red = rospy.get_param(&#x27;/background_r&#x27;)rospy.set_param(&quot;/background_r&quot;, 255)","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"5-service通信机制简汇","slug":"ROS1/5-service通信机制简汇","date":"2023-09-03T08:26:35.431Z","updated":"2023-09-03T08:26:35.495Z","comments":true,"path":"2023/09/03/ROS1/5-service通信机制简汇/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/03/ROS1/5-service%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E6%B1%87/","excerpt":"","text":"1 Client（CPP）123456789101112131415161718192021222324252627#include &lt;ros/ros.h&gt;#include &lt;turtlesim/Spawn.h&gt;int main(int argc, char** argv)&#123; // 初始化ROS节点 ros::init(argc, argv, &quot;turtle_spawn&quot;); // 创建节点句柄 ros::NodeHandle node; // 发现/spawn服务后，创建一个服务客户端，连接名为/spawn的service（阻塞） ros::service::waitForService(&quot;/spawn&quot;); ros::ServiceClient add_turtle = node.serviceClient&lt;turtlesim::Spawn&gt;(&quot;/spawn&quot;); // 初始化turtlesim::Spawn的请求数据 turtlesim::Spawn srv; srv.request.x = 2.0; srv.request.y = 2.0; srv.request.name = &quot;turtle2&quot;; // 请求服务调用 ROS_INFO(&quot;Call service to spwan turtle[x:%0.6f, y:%0.6f, name:%s]&quot;, srv.request.x, srv.request.y, srv.request.name.c_str()); //同步阻塞 add_turtle.call(srv); // 显示服务调用结果 ROS_INFO(&quot;Spwan turtle successfully [name:%s]&quot;, srv.response.name.c_str()); return 0;&#125;; cmake修改：在CmakeLists最底部添加如下修改： 1234add_executable(turtle_spawn src/turtle_spawn.cpp)target_link_libraries(turtle_spawn $&#123;catkin_LIBRARIES&#125;) 2 Client（Python）1234567891011121314151617181920#!/usr/bin/env python# -*- coding: utf-8 -*-import sysimport rospyfrom turtlesim.srv import Spawn if __name__ == &quot;__main__&quot;: # ROS节点初始化 rospy.init_node(&#x27;turtle_spawn&#x27;) # 发现/spawn服务后，创建一个服务客户端，连接名为/spawn的service rospy.wait_for_service(&#x27;/spawn&#x27;) try: add_turtle = rospy.ServiceProxy(&#x27;/spawn&#x27;, Spawn) # 请求服务调用，输入请求数据 # 也可以调用 add_turtle.call() response = add_turtle(2.0, 2.0, 0.0, &quot;turtle2&quot;) return response.name except rospy.ServiceException as e: print (&quot;Service call failed: %s&quot;%e) cmake修改：找到catkin_install_python项，添加脚本。 1234catkin_install_python(PROGRAMS scripts/turtle_spawn.py DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;) 3 Server（CPP）12345678910111213141516171819202122232425262728293031323334353637#include &lt;ros/ros.h&gt;#include &lt;geometry_msgs/Twist.h&gt;#include &lt;std_srvs/Trigger.h&gt;// service回调函数，输入参数req，输出参数resbool commandCallback(std_srvs::Trigger::Request &amp;req, std_srvs::Trigger::Response &amp;res)&#123; // 设置反馈数据 res.success = true; res.message = &quot;Change turtle command state!&quot;; return true;&#125;int main(int argc, char **argv)&#123; // ROS节点初始化 ros::init(argc, argv, &quot;turtle_command_server&quot;); // 创建节点句柄 ros::NodeHandle n; // 创建一个名为/turtle_command的server，注册回调函数commandCallback ros::ServiceServer command_service = n.advertiseService(&quot;/turtle_command&quot;, commandCallback); // 循环等待回调函数 ROS_INFO(&quot;Ready to receive turtle command.&quot;); // 设置循环的频率 ros::Rate loop_rate(10); while(ros::ok()) &#123; // 查看一次回调函数队列 ros::spinOnce(); // 业务代码..... //按照循环频率延时 loop_rate.sleep(); &#125; return 0;&#125; cmake修改：在CmakeLists最底部添加如下修改： 1234add_executable(turtle_command_server src/turtle_command_server.cpp)target_link_libraries(turtle_command_server $&#123;catkin_LIBRARIES&#125;) 4 Server（Python）12345678910111213141516171819202122232425262728293031323334#!/usr/bin/env python# -*- coding: utf-8 -*-import rospyimport thread,timefrom std_srvs.srv import Trigger, TriggerResponsedef command_thread(): while True: if pubCommand: vel_msg = Twist() vel_msg.linear.x = 0.5 vel_msg.angular.z = 0.2 turtle_vel_pub.publish(vel_msg) time.sleep(0.1)def commandCallback(req): global pubCommand pubCommand = bool(1-pubCommand) # 显示请求数据 rospy.loginfo(&quot;Publish turtle velocity command![%d]&quot;, pubCommand) # 反馈数据 return TriggerResponse(1, &quot;Change turtle command state!&quot;)if __name__ == &quot;__main__&quot;: # ROS节点初始化 rospy.init_node(&#x27;turtle_command_server&#x27;) # 创建一个名为/turtle_command的server，注册回调函数commandCallback s = rospy.Service(&#x27;/turtle_command&#x27;, Trigger, commandCallback) # 循环等待回调函数 print &quot;Ready to receive turtle command.&quot; # 由于python没有spinOnce()接口，因此新启一个线程 thread.start_new_thread(command_thread, ()) rospy.spin() cmake修改：找到catkin_install_python项，添加脚本。 1234catkin_install_python(PROGRAMS scripts/turtle_command_server.py DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;) 5 自定义接口5.1 srv文件编写在 ros_ws&#x2F;src&#x2F;hello&#x2F;srv目录下创建 Person.srv 接口文件，注意首字母必须大写。接口示例如下： 12345string nameuint8 ageuint8 sex---string result 接口中，— 以上为request内容，以下为response内容。 编译修改： CMakeLists修改：在对应位置进行如下修改： 1234find_package(...... message_generation)add_message_files(FILES Person.srv)generate_messages(DEPENDENCIES std_msgs)catkin_package(...... message_runtime) package.xml修改：在对应位置添加如下： 12&lt;build_depend&gt;message_generation&lt;/build_depend&gt;&lt;exec_depend&gt;message_runtime&lt;/exec_depend&gt; 自定义接口需经过编译形成C++和Python的引用文件，可以在devel&#x2F;include里面找到C++所需的.h接口文件。 5.2 C&#x2F;S代码编写Client &#x2F; Server 代码与前几节几乎一模一样，这里不再赘述。 编译修改：由于应用代码对接口产生依赖，因此在编译应用代码时，也应添加相应的依赖（Python不需要）： 1add_dependencies(person_client $&#123;PROJECT_NAME&#125;_gencpp) http://wiki.ros.org/cn/ROS/Tutorialshttps://www.guyuehome.com/bubble/index","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"4-topic通信机制简汇","slug":"ROS1/4-topic通信机制简汇","date":"2023-09-03T08:26:35.103Z","updated":"2023-09-03T08:26:35.163Z","comments":true,"path":"2023/09/03/ROS1/4-topic通信机制简汇/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/03/ROS1/4-topic%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E6%B1%87/","excerpt":"","text":"1 Publisher（CPP）12345678910111213141516171819202122232425262728#include &lt;ros/ros.h&gt;#include &lt;geometry_msgs/Twist.h&gt;int main(int argc, char **argv)&#123; // ROS节点初始化 ros::init(argc, argv, &quot;publisher&quot;); // 创建节点句柄 ros::NodeHandle n; // 创建一个Publisher，发布名为/turtle1/cmd_vel的topic，消息类型为geometry_msgs::Twist，队列长度10 ros::Publisher = n.advertise&lt;geometry_msgs::Twist&gt;(&quot;/turtle1/cmd_vel&quot;, 10); // 设置循环的频率 ros::Rate loop_rate(10); while (ros::ok()) &#123; // 初始化geometry_msgs::Twist类型的消息 geometry_msgs::Twist vel_msg; vel_msg.linear.x = 0.5; vel_msg.angular.z = 0.2; // 发布消息 turtle_vel_pub.publish(vel_msg); ROS_INFO(&quot;Publsh turtle velocity command[%0.2f m/s, %0.2f rad/s]&quot;, vel_msg.linear.x, vel_msg.angular.z); // 按照循环频率延时 loop_rate.sleep(); &#125; return 0;&#125; cmake修改：在CmakeLists最底部添加如下修改： 1234add_executable(publisher src/publisher.cpp)target_link_libraries(publisher $&#123;catkin_LIBRARIES&#125;) 2 Publisher（Python）123456789101112131415161718192021#!/usr/bin/env python# -*- coding: utf-8 -*-import rospyfrom geometry_msgs.msg import Twist# ROS节点初始化rospy.init_node(&#x27;publisher&#x27;, anonymous=True)# 创建一个Publisher，发布名为/turtle1/cmd_vel的topic，消息类型为geometry_msgs::Twist，队列长度10turtle_vel_pub = rospy.Publisher(&#x27;/turtle1/cmd_vel&#x27;, Twist, queue_size=10)#设置循环的频率rate = rospy.Rate(10) while not rospy.is_shutdown(): # 初始化geometry_msgs::Twist类型的消息 vel_msg = Twist() vel_msg.linear.x = 0.5 vel_msg.angular.z = 0.2 # 发布消息 turtle_vel_pub.publish(vel_msg) rospy.loginfo(&quot;Publsh turtle velocity command[%0.2f m/s, %0.2f rad/s]&quot;, vel_msg.linear.x, vel_msg.angular.z) rate.sleep() cmake修改：找到catkin_install_python项，添加脚本。 1234catkin_install_python(PROGRAMS scripts/publisher.py DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;) 3 Subscriber（C++）123456789101112131415161718192021222324#include &lt;ros/ros.h&gt;#include &quot;turtlesim/Pose.h&quot;// 接收到订阅的消息后，会进入消息回调函数// turtlesim::Pose为消息类型，来源于 #include &quot;turtlesim/Pose.h&quot;void poseCallback(const turtlesim::Pose::ConstPtr&amp; msg)&#123; // 将接收到的消息打印出来 ROS_INFO(&quot;Turtle pose: x:%0.6f, y:%0.6f&quot;, msg-&gt;x, msg-&gt;y);&#125;int main(int argc, char **argv)&#123; // 初始化ROS节点 ros::init(argc, argv, &quot;subscriber&quot;); // 创建节点句柄 ros::NodeHandle n; // 创建一个Subscriber，订阅名为/turtle1/pose的topic，注册回调函数poseCallback ros::Subscriber pose_sub = n.subscribe(&quot;/turtle1/pose&quot;, 10, poseCallback); // 循环等待回调函数 ros::spin(); return 0;&#125; cmake修改：在CmakeLists最底部添加如下修改： 1234add_executable(subscriber src/subscriber.cpp)target_link_libraries(subscriber $&#123;catkin_LIBRARIES&#125;) 4 Subscriber（Python）123456789101112131415#!/usr/bin/env python# -*- coding: utf-8 -*-import rospyfrom turtlesim.msg import Posedef poseCallback(msg): rospy.loginfo(&quot;Turtle pose: x:%0.6f, y:%0.6f&quot;, msg.x, msg.y)# ROS节点初始化rospy.init_node(&#x27;subscriber&#x27;, anonymous=True)# 创建一个Subscriber，订阅名为/turtle1/pose的topic，注册回调函数poseCallback# Pose为消息类型，来源于 from turtlesim.msg import Poserospy.Subscriber(&quot;/turtle1/pose&quot;, Pose, poseCallback)# 循环等待回调函数rospy.spin() cmake修改：找到catkin_install_python项，添加脚本。 1234catkin_install_python(PROGRAMS scripts/subscriber.py DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;) 5 自定义接口5.1 msg文件编写在 ros_ws&#x2F;src&#x2F;hello&#x2F;msg目录下创建 Person.msg 接口文件，注意首字母必须大写。接口示例如下： 12345678string nameuint8 sexuint8 age# 以下相当于宏uint8 unknown = 0uint8 male = 1uint8 female = 2 编译修改： CMakeLists修改：在对应位置进行如下修改： 1234find_package(...... message_generation)add_message_files(FILES Person.msg)generate_messages(DEPENDENCIES std_msgs)catkin_package(...... message_runtime) package.xml修改：在对应位置添加如下： 12&lt;build_depend&gt;message_generation&lt;/build_depend&gt;&lt;exec_depend&gt;message_runtime&lt;/exec_depend&gt; 自定义接口需经过编译形成C++和Python的引用文件，可以在devel&#x2F;include里面找到C++所需的.h接口文件。 5.2 发布&#x2F;订阅代码编写发布&#x2F;订阅代码与前几节几乎一模一样，这里不再赘述。对于接口里面的宏的引用，在C++里面这样引用：learning_topic::Person::male; Python里面这样引用：Person.male 。 编译修改：由于应用代码对接口产生依赖，因此在编译应用代码时，也应添加相应的依赖（Python不需要）： 1add_dependencies(person_subscriber $&#123;PROJECT_NAME&#125;_generate_messages_cpp) http://wiki.ros.org/cn/ROS/Tutorialshttps://www.guyuehome.com/bubble/index","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"3-ROS1快速开始","slug":"ROS1/3-ROS1快速开始","date":"2023-09-03T08:26:34.687Z","updated":"2023-12-20T01:17:43.719Z","comments":true,"path":"2023/09/03/ROS1/3-ROS1快速开始/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/03/ROS1/3-ROS1%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/","excerpt":"","text":"0 安装工作环境：x86_64 + ubuntu20.04 + ros-noetic 12345678sudo mkdir /etc/apt/sources.list.d/sudo sh -c &#x27;echo &quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#x27;sudo apt-key adv --keyserver &#x27;hkp://keyserver.ubuntu.com:80&#x27; --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654sudo apt updatesudo apt install ros-noetic-ros-baseecho &quot;source /opt/ros/noetic/setup.bash&quot; &gt;&gt; ~/.bashrcsource ~/.bashrcsudo apt install python3-rosinstall python3-rosinstall-generator python3-wstool -y 1 创建功能包1.1 创建工作空间123mkdir -p ros_ws/srccd ros_ws/srccatkin_init_workspace 1.2 创建功能包12catkin_create_pkg hello std_msgs roscpp rospy格式：catkin_create_pkg &lt;pkg_name&gt; &lt;depend&gt; &lt;depend&gt; 1.3 编译工作空间12cd ..catkin_make 1.4 激活环境变量1source devel/setup.bash 注：同一个工作空间不能有同名功能包；不同工作空间可以有同名功能包。 2 编写CPP节点2.1 创建节点文件在 ros_ws&#x2F;src&#x2F;hello&#x2F;src 目录下创建hello.cpp 节点文件。 2.1 节点代码12345678910111213#include &lt;ros/ros.h&gt;int main(int argc, char **argv)&#123; // ROS节点初始化 ros::init(argc, argv, &quot;hello_node&quot;); // 创建节点句柄 ros::NodeHandle n; ROS_INFO(&quot;Hello world.&quot;); ros::spin(); return 0;&#125; 2.2 修改CmakeLists修改 ros_ws&#x2F;src&#x2F;hello&#x2F;src&#x2F;CmakeLists，找到以下项，并进行如下修改： 1234567## 编译节点源码，hello_node为节点可执行文件名字，可以与源码指定的节点名字一致add_executable(hello_node src/hello.cpp)## 添加链接库target_link_libraries(hello_node $&#123;catkin_LIBRARIES&#125;) 2.3 编译运行1234cd ros_wscatkin_makesource devel/setup.bashrosrun hello hello_node 3 编写Python节点3.1 创建节点文件在 ros_ws&#x2F;src&#x2F;hello&#x2F;scripts 目录下创建hello.py节点文件。 2.1 节点代码12345678910#!/usr/bin/env python# -*- coding: utf-8 -*-import rospy if __name__ == &#x27;__main__&#x27;: # ROS节点初始化 rospy.init_node(&#x27;hello_node_py&#x27;) rospy.loginfo(&#x27;hello world.&#x27;) rospy.spin() 2.2 修改CmakeLists修改 ros_ws&#x2F;src&#x2F;hello&#x2F;src&#x2F;CmakeLists，找到以下项，并进行如下修改： 12345## 添加节点python脚本，python无需编译，只需添加到路径即可catkin_install_python(PROGRAMS scripts/hello.py DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;) 2.3 编译运行1234cd ros_wscatkin_makesource devel/setup.bashrosrun hello hello.py http://wiki.ros.org/cn/ROS/Tutorialshttps://www.guyuehome.com/bubble/index","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"2-ROS1命令汇总","slug":"ROS1/2-ROS1命令汇总","date":"2023-09-03T08:26:34.255Z","updated":"2023-09-09T10:38:55.370Z","comments":true,"path":"2023/09/03/ROS1/2-ROS1命令汇总/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/03/ROS1/2-ROS1%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/","excerpt":"","text":"命令一页纸：https://blog-images-submit.oss-cn-beijing.aliyuncs.com/ROS1/ROScheatsheet_catkin.pdf 1 node相关命令rosnode listrosnode info &lt;node_name&gt;rosnode ping &lt;node_name&gt;rosnode ping –allrosnode kill &lt;node_name&gt;rosnode kill –all 2 topic相关命令rostopic listrostopic type &lt;topic_name&gt;rostopic info &lt;topic_name&gt; 查看话题具体信息(消息类型，发布&#x2F;订阅者)rostopic echo &lt;topic_name&gt; 实时查看话题内容rostopic hz &lt;topic_name&gt;rostopic bw &lt;topic_name&gt;rostopic pub &lt;topic_name&gt; &lt;message_type&gt; &lt;message_content&gt; 3 msg相关命令rosmsg show &lt;msg_name&gt; 查看消息格式 5 service相关命令rosservice listrosservice call &lt;ser_name&gt;rosservice type &lt;ser_name&gt;rosservice findrosservice uri 6 param相关命令rosparam setrosparam getrosparam loadrosparam deleterosparam list 7 pkg相关命令rospack find &lt;pkg_name&gt;rospack list 8 run节点：rosrun &lt;pkg_name&gt; &lt;node_name&gt; 9 记录运行话题记录：rosbag record -a -O cmd_record话题复现：rosbag play cmd_record.bag 10 可视化：rqt:rqt_console 终端控制台rqt_plot 绘制波形曲线rqt_graph 查看节点关联关系rqt_image_view 查看摄像头图像 rviz：可用于构建机器人模型、坐标、点云、图像、导航、运动规划等等。 gazebo:用于三维物理仿真 http://wiki.ros.org/cn/ROS/Tutorials","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"1-ROS概览","slug":"ROS1/1-ROS概览","date":"2023-09-03T08:26:33.919Z","updated":"2023-09-03T08:26:33.971Z","comments":true,"path":"2023/09/03/ROS1/1-ROS概览/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/09/03/ROS1/1-ROS%E6%A6%82%E8%A7%88/","excerpt":"","text":"ROS: Robot Operating SystemROS已经成为机器人领域的普遍标准.ROS包含：通信框架 + 开发工具 + 应用功能 + 生态系统开发工具包括：CLI命令，rqt，Rviz，TF-Tree，Gazebo仿真等等。应用功能包括：导航Navigation，建图SLAM，机械臂规划Movelt等等。生态系统包括：发行版，软件源，wiki，Blog等等。 相关概念：节点（Node）– 执行单元 执行具体任务的进程、独立运行的可执行文件。 不同节点可使用不同的编程语言，可分布式运行在不同的主机。 节点在系统中的名称必须是唯一的。 节点管理器（ROS Master）– 控制中心 为节点提供命名和注册服务。 跟踪和记录话题&#x2F;服务通信，辅助节点相互查找、建立连接。 提供参数服务器，节点使用该服务器存储和检索运行时的参数。 话题（Topic）– 异步通信机制 节点间用来传输数据的重要总线。 使用发布&#x2F;订阅模型，数据由发布者传输到订阅者，同一个话题的订阅者或发布者可以不唯一。 消息（Message） – 话题接口 具有一定的类型和数据结构，包括ROS提供的标准类型和用户自定义的类型。 使用编程语言无关的.msg文件定义，编译过程中生成对应的代码文件。 服务（Service）– 同步通信机制 使用客户端&#x2F;服务端（C&#x2F;S）模型，客户端发送请求数据，服务器完成处理后返回应答数据。 使用编程语言无关的.srv文件定义请求和应答数据结构，编译过程中生成对应的代码文件。 话题和服务的区别： 参数（Parameter）– 全局共享字典 可通过网络访问的共享、多变量字典。 节点使用此服务器来存储和检索运行时的参数。 适合存储静态、非二进制的配置参数，不适合存储动态配置的数据。 功能包（Package） ROS软件中的基本单元，包含节点源码、配置文件、数据定义等。 功能包清单（Package Manifest） 记录功能包的基本信息，包含作者信息、许可信息、依赖选项、编译标志等。 元功能包（Meta Package） 组织多个用于同一目的的功能包 http://wiki.ros.org/cn/ROS/Tutorialshttps://www.guyuehome.com/bubble/index","categories":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"}],"tags":[{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"}]},{"title":"7-ROS2通信汇总(Python篇)","slug":"ROS2基础/7-ROS2 通信汇总(Python篇)","date":"2023-08-20T09:29:20.492Z","updated":"2023-08-20T09:29:20.540Z","comments":true,"path":"2023/08/20/ROS2基础/7-ROS2 通信汇总(Python篇)/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/08/20/ROS2%E5%9F%BA%E7%A1%80/7-ROS2%20%E9%80%9A%E4%BF%A1%E6%B1%87%E6%80%BB(Python%E7%AF%87)/","excerpt":"","text":"1 topic发布与订阅发布端接口： 12publisher_ = node.create_publisher(msg_type,&quot;topic_name&quot;, 10) publisher_.publish(msg) 订阅者接口： 1subscribe_ = node.create_subscription(msg_type, &quot;topic_name&quot;, recv_callback, 10) 2 service发送和接收client 接口： 1234client = node.create_client(srv_type,&quot;srv_name&quot;)while not client.wait_for_service(1.0): node.get_logger().warn(&quot;等待服务&quot;)client.call_async(request) # .add_done_callback(reponse_callback) server 接口： 1234server = node.create_service(srv_type,&quot;srv_name&quot;, request_callback)def request_callback(request, response): ...... return response 3 action控制与执行执行 接口： 123456789101112from rclpy.action import ActionServerfrom rclpy.action.server import ServerGoalHandleaction_server_ = ActionServer( node, action_type, &quot;action_name&quot;, execute_callback # ,callback_group=MutuallyExclusiveCallbackGroup() )def execute_callback(goal_handle: ServerGoalHandle): ... ... result = action_type.Result() result = ... return result 控制 接口： 12345678910111213141516from rclpy.action import ActionClientaction_client_ = ActionClient(node, action_type, &#x27;action_name&#x27;)goal_msg = MoveRobot.Goal()goal_msg = ...action_client_.wait_for_server()send_goal_future = action_client_.send_goal_async(goal_msg,feedback_callback=feedback_callback)send_goal_future.add_done_callback(goal_response_callback)def feedback_callback(feedback_msg): feedback = feedback_msg.feedback ... def goal_response_callback(future): goal_handle = future.result() get_result_future = goal_handle.get_result_async() get_result_future.add_done_callback(get_result_callback)","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"6-ROS2 接口介绍","slug":"ROS2基础/6-ROS2 接口介绍","date":"2023-08-20T09:29:20.220Z","updated":"2023-08-20T09:29:20.268Z","comments":true,"path":"2023/08/20/ROS2基础/6-ROS2 接口介绍/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/08/20/ROS2%E5%9F%BA%E7%A1%80/6-ROS2%20%E6%8E%A5%E5%8F%A3%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"ROS2提供了四种通信方式，包括：话题（topic）、服务（service）、动作（action）和 参数（parameter）。通信会涉及到接口，我们可以通过 ros2 interface list 列出ROS2提供的所有接口，通过 ros2 interface show &lt;interface_name&gt; 或 ros2 interface proto &lt;message_name&gt; 查看接口的具体格式。但是，当我们不能在内置接口中找到适合于我们项目的接口时，我们需要自定义接口。以下讲解如何自定义接口。 1 接口格式1.1 topic接口格式接口存放路径：interface_pkg&#x2F;msg&#x2F;Xxx.msg 12string namesensor_msgs/Image image #支持嵌套 1.2 service接口格式接口存放路径：interface_pkg&#x2F;srv&#x2F;Xxx.srv 12345string nameint32 aint64 b---int32 ret # 返回值 1.3 action接口格式接口存放路径：interface_pkg&#x2F;action&#x2F;Xxx.action 12345int32 target # 目标值 ---int32[] sequence # 差值---int32[] partial_sequence # 当前值 2 创建接口2.1 创建接口功能包1ros2 pkg create example_test_interfaces --build-type ament_cmake --dependencies rosidl_default_generators 其中，–build-type 参数值必须为 ament_cmake； –dependencies 指定功能包依赖，rosidl_default_generators必须添加，其他根据自己接口依赖添加即可，当然也可以通过事后修改 package.xml 添加依赖。创建完后可看见新增接口文件夹，目录如下： 2.2 添加接口文件将自己定义的接口放入 example_test_interfaces 文件夹合适位置，注意要按照上一节的接口格式来定义和存放接口。我们这个先定义一个简单的 topic 接口，在 example_test_interfaces 下新建 msg 目录，并在 msg 目录下新建 Test.msg 文件(首字母大写)，内容如下： 123string nameuint32 valuebool flag 2.3 修改CMakeLists文件在CMakeLists里面添加要编译的接口，为什么接口也要编译？其实ROS需要将 msg、srv、action文件转换为Python和C++的头文件，这样我们的节点代码才能读取接口。CMakeLists修改如下： 12345678# 查找依赖，有新增需添加find_package(rosidl_default_generators REQUIRED)# 生成接口头文件rosidl_generate_interfaces($&#123;PROJECT_NAME&#125; &quot;msg/Test.msg&quot; # DEPENDENCIES geometry_msgs # 有依赖需要添加) 2.4 修改package.xml文件12在 &lt;depend&gt;rosidl_default_generators&lt;/depend&gt; 下面添加：&lt;member_of_group&gt;rosidl_interface_packages&lt;/member_of_group&gt; 2.5 编译接口包12cd workspacecolcon build --packages-select example_test_interfaces 2.6 查看测试12source install/setup.bashros2 interface show example_test_interfaces/msg/Test","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"5-ROS2创建第一个节点","slug":"ROS2基础/5-ROS2创建第一个节点","date":"2023-08-20T09:29:19.940Z","updated":"2023-08-20T09:29:19.992Z","comments":true,"path":"2023/08/20/ROS2基础/5-ROS2创建第一个节点/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/08/20/ROS2%E5%9F%BA%E7%A1%80/5-ROS2%E5%88%9B%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9/","excerpt":"","text":"1 创建cpp节点1.1 创建工作空间1mkdir -p workspace/src/ 1.2 创建功能包12cd workspace/srcros2 pkg create example_cpp --build-type ament_cmake --dependencies rclcpp 此时可以看到ROS2为我们创建了example_cpp文件夹，且该文件夹下包含include、src、CMakeLists.txt、package.xml 文件及目录。其中，src和include目录放节点源码和相应的头文件，CMakeLists.txt是编译节点源码的配置文件，package.xml是该功能包的配置文件。 1.3 创建节点在功能包的src目录下创建节点文件 mynode.cpp，该文件的main函数则为该节点的入口。cpp文件代码如下： 12345678910111213141516#include &quot;rclcpp/rclcpp.hpp&quot;int main(int argc, char **argv)&#123; /* 初始化rclcpp */ rclcpp::init(argc, argv); /*创建一个名为test_node的节点*/ auto node = std::make_shared&lt;rclcpp::Node&gt;(&quot;test_node&quot;); /*利用RCLCPP 打印*/ RCLCPP_INFO(node-&gt;get_logger(), &quot;Hello World. test_node start.&quot;); /* 运行节点，并检测退出信号 Ctrl+C*/ rclcpp::spin(node); /* 停止运行 */ rclcpp::shutdown(); return 0;&#125; 1.4 修改CMakeLists将mynode.cpp 添加到CMakeLists中，让cmake编译节点并安装节点。在CMakeLists末尾添加以下配置： 1234567add_executable(test_node src/mynode.cpp)ament_target_dependencies(test_node rclcpp)install(TARGETS test_node DESTINATION lib/$&#123;PROJECT_NAME&#125;) 1.5 编译功能包12cd workspacecolcon build --packages-select example_cpp 1.6 source环境1source install/setup.bash 1.7 运行节点1ros2 run example_cpp test_node 2 创建python节点2.1 创建工作空间1mkdir -p workspace/src/ 2.2 创建功能包12cd workspace/srcros2 pkg create example_py --build-type ament_python --dependencies rclpy 此时可以看到ROS2为我们创建了example_py文件夹，且该文件夹下包含example_py、resource、test、package.xml、setup.py、setup.cfg文件及目录。其中，example_py文件夹放我们的节点代码。 2.3 创建节点在功能包的example_py目录下创建节点文件 mynode.py，该文件的main函数则为该节点的入口。python文件代码如下： 123456789101112import rclpyfrom rclpy.node import Nodedef main(args=None): # 初始化rclpy rclpy.init(args=args) # 创建一个test_node node = Node(&quot;test_node_py&quot;) node.get_logger().info(&quot;Hello World. node_py start.&quot;) # 保持节点运行 rclpy.spin(node) rclpy.shutdown() 2.4 修改 setup.py在setup文件中声明该python节点，以及指定该节点的入口。这样之后使用colcon build才能检测到该节点，从而将其添加到install目录下。修改如下： 123456 entry_points=&#123; &#x27;console_scripts&#x27;: [ &quot;test_node_py = example_py.mynode:main&quot; ], &#125;,) 2.5 编译功能包12cd workspacecolcon build --packages-select example_py 2.6 source环境1source install/setup.bash 2.7 运行节点1ros2 run example_py test_node_py","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"4-ROS2命令行汇总","slug":"ROS2基础/4-ROS2命令行汇总","date":"2023-08-20T09:29:19.576Z","updated":"2023-08-20T09:29:19.624Z","comments":true,"path":"2023/08/20/ROS2基础/4-ROS2命令行汇总/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/08/20/ROS2%E5%9F%BA%E7%A1%80/4-ROS2%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%B1%87%E6%80%BB/","excerpt":"","text":"0 节点运行命令 命令格式： ros2 run &lt;package_name&gt; &lt;node_name&gt; 1 pkg相关命令1.1 ros2 pkg create 命令功能：创建功能包并指定包相关参数命令格式：ros2 pkg create &lt;pkgname&gt; –build-type &lt;ament_python&gt; –node-name &lt;xx_node&gt; –dependencies &lt;rclpy&gt;参数列表： 参数 参数作用 参数示例 –build-type 指定编译类型 ament_python &#x2F; ament_cmake –node-name 指定要生成的源码文件，可以后期创建 xxx.py &#x2F; xxx.cpp –dependencies 指定依赖模块 rclpy &#x2F; std_msgs &#x2F; sensor_msgs 1.2 ros2 pkg list 命令功能：查看系统中功能包列表命令格式：ros2 pkg list注意：记得要通过source指令将自己的功能包添加到ROS2环境中。 1.3 ros2 pkg executables 命令功能：查看功能包内所有可执行节点命令格式：ros2 pkg executables &lt;package_name&gt; 2 node相关命令2.1 ros2 node list 命令功能： 查看当前域内（ROS_DOMAIN_ID）的节点列表命令格式： ros2 node list 2.2 ros2 node info 命令功能： 查看节点详细信息，包括订阅、发布的消息，开启的服务和动作等命令格式： ros2 node info &lt;node_name&gt; 3 topic相关命令3.1 ros2 topic list 命令功能：列出域内可使用的topic列表命令格式：ros2 topic list 3.2 ros2 topic info 命令功能：显示主题消息类型，订阅者数量，发布者数量等命令格式：ros2 topic info &lt;topic_name&gt; 3.3 ros2 topic type 命令功能：查看主题消息类型命令格式：ros2 topic type &lt;topic_name&gt; 3.4 ros2 topic find 命令功能：按消息类型查找相关主题命令格式：ros2 topic find &lt;message_type&gt; 3.5 ros2 topic hz 命令功能：显示主题平均发布频率命令格式：ros2 topic hz &lt;topic_name&gt; 3.6 ros2 topic bw 命令功能：显示所查阅主题的带宽命令格式：ros2 topic bw &lt;topic_name&gt; 3.7 ros2 topic delay 命令功能：通过header中的时间戳计算消息延迟命令格式：ros2 topic delay &lt;topic_name&gt; 3.8 ros2 topic echo 命令功能：在控制台显示主题消息命令格式：ros2 topic echo &lt;topic_name&gt; 3.9 ros2 topic pub 命令功能：通过命令行发布指定主题消息命令格式：ros2 topic pub &lt;topic_name&gt; &lt;message_type&gt; &lt;message_content&gt;命令示例：ros2 topic pub control_node&#x2F;action geometry_msgs&#x2F;msg&#x2F;TwistStamped “{header: {stamp:{sec: 0, nanosec: 0}, frame_id: control_node}, twist: {linear: {x: 0.3, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 0.0}}}” 4 interface相关命令4.1 ros2 interface list 命令功能：按类显示系统内所有的接口，包括消息（Messages）、服务（Services）、动作（Actions）命令格式：ros2 interface list 4.3 ros2 interface packages 命令功能：显示所有接口包命令格式：ros2 interface packages 4.2 ros2 interface package 命令功能：显示指定接口包内的子接口命令格式：ros2 interface package &lt;interface_pkg&gt; 4.3 ros2 interface show 命令功能：显示指定接口的详细内容命令格式：ros2 interface show &lt;interface_name&gt; 4.4 ros2 interface proto 命令功能：显示消息模板命令格式：ros2 interface proto &lt;message_name&gt;","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"3-ROS2系统架构","slug":"ROS2基础/3-ROS2系统架构","date":"2023-08-20T09:29:19.124Z","updated":"2023-08-20T09:29:19.176Z","comments":true,"path":"2023/08/20/ROS2基础/3-ROS2系统架构/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/08/20/ROS2%E5%9F%BA%E7%A1%80/3-ROS2%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/","excerpt":"","text":"1 ROS2总体架构图 1.1 DDS实现层DDS，全称 Data Distribution Service (数据分发服务)。是由对象管理组 (OMG) 于 2003 年发布并于 2007 年修订的开分布式系统标准。通过类似于ROS中的话题发布和订阅形式来进行通信，同时提供了丰富的服务质量管理来保证可靠性、持久性、传输设置等。 DDS实现层其实就是对不同常见的DDS接口进行再次的封装，让其保持统一性，为DDS抽象层提供统一的API。 1.2 DDS抽象层（rmw）这一层将DDS实现层进一步的封装，使得DDS更容易使用。原因在于DDS需要大量的设置和配置（分区，主题名称，发现模式，消息创建,…），这些设置都是在ROS2的抽象层中完成的。 2 DDS 通信模型DDS的模型是非常容易理解，我们可以定义话题的数据结构（类似于ROS2中的接口类型）。下图中的例子: Pos：一个编号id的车子的位置x,y DDS的参与者(Participant)通过发布和订阅主题数据进行通信。 DDS的应用层通过DDS进行数据订阅发布，DDS通过传输层进行数据的收发。 2.1. DDS的优势与劣势**优势** 发布&#x2F;订阅模型：简单解耦，可以轻松实现系统解耦 性能：在发布&#x2F;订阅模式中，与请求&#x2F;回复模式相比，延迟更低，吞吐量更高。 远程参与者的自动发现：此机制是 DDS 的主要功能之一。通信是匿名的、解耦的，开发者不必担心远程参与者的本地化。 丰富的 Qos 参数集，允许调整通信的各个方面：可靠性、持久性、冗余、寿命、传输设置、资源…… 实时发布订阅协议 ( RTPS )：该协议几乎可以通过任何传输实现，允许在 UDP、TCP、共享内存和用户传输中使用 DDS，并实现不同 DDS 实现之间的真正互操作性。 劣势 API复杂，DDS 的灵活性是以复杂性为代价的。 系统开销相对较大，有待数据论证。 社区支持问题，但ROS2近两年来使用DDS后社区表现还是不错的。 2.2 ROS2使用DDS的几个理由 DDS已经应用在军事、潜艇各个领域，稳定性实时性经过实际检验。 使用DDS需要维护的代码要少得多，可以让ROS2开发人员腾出手专注机器人开发。 DDS有定义好的行为和规范并且有完善的文档。 DDS提供了推荐的用例和软件API，有较好的语言支持。","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"2-ROS2安装(X86篇)","slug":"ROS2基础/2-ROS2安装(X86篇)","date":"2023-08-20T09:29:18.740Z","updated":"2023-08-20T09:29:18.792Z","comments":true,"path":"2023/08/20/ROS2基础/2-ROS2安装(X86篇)/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/08/20/ROS2%E5%9F%BA%E7%A1%80/2-ROS2%E5%AE%89%E8%A3%85(X86%E7%AF%87)/","excerpt":"","text":"本篇安装环境如下： CPU架构：amd_64操作系统：ubuntu20.04 1 更换镜像源（可选）更换镜像源可以加速各种依赖库下载速度，这里提供常用的 ubuntu镜像源 和 pip源。 1.1 更换ubuntu镜像源这里采用清华源，同学们可到该网站 https://mirror.tuna.tsinghua.edu.cn/help/ubuntu/ 寻找自己系统版本对应的源。需要注意的是，大部分高校提供的源都是X86架构的，对于arm设备需要在源加上‘-ports’ 。amd_64&#x2F; ubuntu20.04的源如下： mv &#x2F;etc&#x2F;apt&#x2F;sources.list &#x2F;etc&#x2F;apt&#x2F;sources.list.bakvim &#x2F;etc&#x2F;apt&#x2F;sources.list 123456789# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse 1.2 更换 PIP 源这里同样采用清华的pip源，可加速python第三方库的下载，命令行输入以下命令即可。 12pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplepip config set global.trusted-host https://pypi.tuna.tsinghua.edu.cn 2 设置 locale12345sudo apt update &amp;&amp; sudo apt install localessudo locale-gen en_US en_US.UTF-8sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8export LANG=en_US.UTF-8locale # verify settings 3 添加ROS2 存储库12345678910111213# 1 确保启用universe存储库sudo apt install software-properties-commonsudo add-apt-repository universe# 2 添加ROS2 GPG 密钥sudo apt update &amp;&amp; sudo apt install curl -ysudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg# 3 添加存储库到 sources listecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main&quot; | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null# 4 更新aptsudo apt apdate 4 安装ROS21sudo apt install ros-foxy-desktop python3-colcon-common-extensions 5 设置环境变量12source /opt/ros/foxy/setup.bashecho &quot; source /opt/ros/foxy/setup.bash&quot; &gt;&gt; ~/.bashrc 6 测试6.1 你说我听12345## 运行talkerros2 run demo_nodes_cpp talker## 新起另一个终端，运行listenerros2 run demo_nodes_py listener 6.2 小海龟12345## 运行海龟界面ros2 run turtlesim turtlesim_node## 新启一个终端，运行遥控器ros2 run turtlesim turtle_teleop_key","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"1-ROS2安装(armhf篇)","slug":"ROS2基础/1-ROS2安装(armhf篇)","date":"2023-08-20T09:29:18.360Z","updated":"2023-08-20T09:29:18.408Z","comments":true,"path":"2023/08/20/ROS2基础/1-ROS2安装(armhf篇)/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/08/20/ROS2%E5%9F%BA%E7%A1%80/1-ROS2%E5%AE%89%E8%A3%85(armhf%E7%AF%87)/","excerpt":"","text":"由于ROS官方并没有提供armhf CPU架构的ROS2二进制安装文件，本篇整理了从ROS2源码编译安装的方法。本篇安装环境如下： CPU架构：armv7l操作系统：ubuntu20.04 1 更换镜像源（可选）更换镜像源可以加速各种依赖库下载速度，这里提供常用的 ubuntu镜像源 和 pip源。 1.1 更换ubuntu镜像源这里采用清华源，同学们可到该网站 https://mirror.tuna.tsinghua.edu.cn/help/ubuntu/ 寻找自己系统版本对应的源。需要注意的是，大部分高校提供的源都是X86架构的，对于arm设备需要在源加上‘-ports’ 。armv7l &#x2F; ubuntu20.04的源如下： mv &#x2F;etc&#x2F;apt&#x2F;sources.list &#x2F;etc&#x2F;apt&#x2F;sources.list.bakvim &#x2F;etc&#x2F;apt&#x2F;sources.list 123456789# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse 1.2 更换 PIP 源这里同样采用清华的pip源，可加速python第三方库的下载（后面需要），命令行输入以下命令即可。 12pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplepip config set global.trusted-host https://pypi.tuna.tsinghua.edu.cn 2 设置 locale12345sudo apt update &amp;&amp; sudo apt install localessudo locale-gen en_US en_US.UTF-8sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8export LANG=en_US.UTF-8locale # verify settings 3 添加ROS2 存储库12345678910111213# 1 确保启用universe存储库sudo apt install software-properties-commonsudo add-apt-repository universe# 2 添加ROS2 GPG 密钥sudo apt update &amp;&amp; sudo apt install curl -ysudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg# 3 添加存储库到 sources listecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main&quot; | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null# 4 更新aptsudo apt apdate 4 安装编译工具123456789101112131415161718192021222324252627sudo apt update &amp;&amp; sudo apt install -y \\ libbullet-dev \\ python3-pip \\ python3-pytest-cov \\ ros-dev-tools# install some pip packages needed for testingpython3 -m pip install -U \\ argcomplete \\ flake8-blind-except \\ flake8-builtins \\ flake8-class-newline \\ flake8-comprehensions \\ flake8-deprecated \\ flake8-docstrings \\ flake8-import-order \\ flake8-quotes \\ pytest-repeat \\ pytest-rerunfailures \\ pytest# install Fast-RTPS dependenciessudo apt install --no-install-recommends -y \\ libasio-dev \\ libtinyxml2-dev# install Cyclone DDS dependenciessudo apt install --no-install-recommends -y \\ libcunit1-dev 5 获取ROS2源码12345mkdir -p ~/ros2_foxy/srccd ~/ros2_foxywget https://raw.githubusercontent.com/ros2/ros2/foxy/ros2.repos --no-check-certificate## github下载不稳定，可自行修改repos文件，添加代理前缀 https://ghproxy.com/vcs import --input ./ros2.repos src 6 使用Rosdep安装依赖1234sudo apt upgradecd /etc/ros/rosdep/sources.list.d &amp;&amp; wget https://mirrors.tuna.tsinghua.edu.cn/github-raw/ros/rosdistro/master/rosdep/sources.list.d/20-default.listrosdep updaterosdep install --from-paths src --ignore-src -y --skip-keys &quot;fastcdr rti-connext-dds-5.3.1 urdfdom_headers&quot; 7 编译ROS2源码12cd ~/ros2_foxy/colcon build --symlink-install 8 设置环境变量1. ~/ros2_foxy/install/local_setup.bash 9 测试1234567## 运行talker. ~/ros2_foxy/install/local_setup.bashros2 run demo_nodes_cpp talker## 新起另一个终端，运行listener. ~/ros2_foxy/install/local_setup.bashros2 run demo_nodes_py listener","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"5-模型调参","slug":"pytorch基础/5-模型调参","date":"2023-07-26T09:21:38.260Z","updated":"2023-07-26T09:21:38.312Z","comments":true,"path":"2023/07/26/pytorch基础/5-模型调参/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/07/26/pytorch%E5%9F%BA%E7%A1%80/5-%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/","excerpt":"","text":"1 超参数超参数是可调整的参数，让你控制模型优化过程。不同的超参数值会影响模型的训练和收敛率。 常用的超参数如下： epoch : 在整个数据集上迭代的次数。 batch : 每一次更新参数（反向传播）所用到的数据样本数。 学习率 : 每个batch 更新模型参数的步进幅度。 123learning_rate = 1e-3batch_size = 64epochs = 5 2 损失函数当遇到一些训练数据时，我们未经训练的网络很可能不会给出正确的答案。损失函数衡量的是获得的结果与目标值的不相似程度，它是我们在训练期间想要最小化的损失函数。为了计算损失，我们使用给定数据样本的输入进行预测，并与真实数据标签值进行比较。 常见的损失函数包括用于回归任务的nn.MSELoss（均方误差）和用于分类的nn.NLLLoss（负对数似然）。nn.CrossEntropyLoss结合了nn.LogSoftmax和nn.NLLLoss。 我们将模型的输出对数传递给 nn.CrossEntropyLoss，它将对对数进行标准化处理并计算预测误差。 12# Initialize the loss functionloss_fn = nn.CrossEntropyLoss() 3 优化器优化是在每个训练步骤中调整模型参数以减少模型误差的过程。优化算法定义了这个过程是如何进行的（在这个例子中，我们使用随机梯度下降法）。所有的优化逻辑都被封装在优化器对象中。在这里，我们使用SGD优化器；此外，PyTorch中还有许多不同的优化器，如Adam和RMSProp，它们对不同类型的模型和数据有更好的效果。 我们通过注册需要训练的模型参数来初始化优化器，并传入学习率超参数。 1optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) 4 调参过程我们定义了train_loop和test_loop，train_loop负责循环我们的优化代码，test_loop负责根据测试数据评估模型的性能。 12345678910111213141516171819202122232425262728293031def train_loop(dataloader, model, loss_fn, optimizer): size = len(dataloader.dataset) for batch, (X, y) in enumerate(dataloader): # Compute prediction and loss pred = model(X) loss = loss_fn(pred, y) # Backpropagation optimizer.zero_grad() loss.backward() optimizer.step() if batch % 100 == 0: loss, current = loss.item(), batch * len(X) print(f&quot;loss: &#123;loss:&gt;7f&#125; [&#123;current:&gt;5d&#125;/&#123;size:&gt;5d&#125;]&quot;)def test_loop(dataloader, model, loss_fn): size = len(dataloader.dataset) num_batches = len(dataloader) test_loss, correct = 0, 0 with torch.no_grad(): for X, y in dataloader: pred = model(X) test_loss += loss_fn(pred, y).item() correct += (pred.argmax(1) == y).type(torch.float).sum().item() test_loss /= num_batches correct /= size print(f&quot;Test Error: \\n Accuracy: &#123;(100*correct):&gt;0.1f&#125;%, Avg loss: &#123;test_loss:&gt;8f&#125; \\n&quot;) 123456789loss_fn = nn.CrossEntropyLoss()optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)epochs = 10for t in range(epochs): print(f&quot;Epoch &#123;t+1&#125;\\n-------------------------------&quot;) train_loop(train_dataloader, model, loss_fn, optimizer) test_loop(test_dataloader, model, loss_fn)print(&quot;Done!&quot;) 请确保在推理前调用model.eval()方法，以将dropout和batch normalization层设置为eval模式。如果不这样做，将产生不一致的推理结果。 5 保存&amp;加载5.1 保存状态字典123torch.save(model.state_dict(), &#x27;model_weights.pth&#x27;)model = Model_Net() # 需要实例化训练时相同的类model.load_state_dict(torch.load(&#x27;model_weights.pth&#x27;)) 5.2 保存整个模型类123# 这种方法在序列化模型时使用Python的pickle模块，所以它在加载模型时，依赖于实际的可用的类定义。torch.save(model, &#x27;model.pth&#x27;)model = torch.load(&#x27;model.pth&#x27;) 5.3 导出ONNX模型123# 由于PyTorch执行图的动态性质，导出过程必须遍历执行图以产生持久的ONNX模型。出于这个原因，应该向导出程序传递一个适当大小的测试变量。input_image = torch.zeros((1,3,224,224))onnx.export(model, input_image, &#x27;model.onnx&#x27;) 5.4 导出JIT模型该种方法加载模型时无需 模型类，导出 JIT 模型的方式有两种：trace 和 script。 采用 torch.jit.trace 的方式来导出 JIT 模型，这种方式会根据一个输入将模型跑一遍，然后记录下执行过程。这种方式的问题在于对于有分支判断的模型不能很好的应对，因为一个输入不能覆盖到所有的分支。但是在我们 ResNet50 模型中不会遇到分支判断，因此这里是合适的。 12345# trace 方法保存example_input = torch.rand(1, 3, 224, 224)jit_model = torch.jit.trace(model, example_input)torch.jit.save(jit_model, &#x27;resnet50_jit.pth&#x27;)module = torch.jit.load(&#x27;resnet50_jit.pth&#x27;) 如果模型有 if else 等分支语句, 应该用script方法保存模型。 1234# script 方法保存script_module = torch.jit.script(model) torch.jit.save(script_module, &#x27;model.pth&#x27;)module = torch.jit.load(&#x27;model.pth&#x27;)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"4-模型搭建","slug":"pytorch基础/4-模型搭建","date":"2023-07-26T09:18:44.419Z","updated":"2023-07-26T09:18:44.467Z","comments":true,"path":"2023/07/26/pytorch基础/4-模型搭建/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/07/26/pytorch%E5%9F%BA%E7%A1%80/4-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA/","excerpt":"","text":"1 神经网络搭建1.1 通过 forward 构建我们可以通过继承 nn.Module，构建我们自己的类来定义我们的神经网络。其中，我们在__init__方法中实现各个子Module的初始化，并在forward 方法中组织这些子Module，形成神经网络。 12345678910111213141516171819class NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10), ) def forward(self, x): x = self.flatten(x) logits = self.linear_relu_stack(x) return logitsmodel = NeuralNetwork().to(device)logits = model(input_image) 1.2 通过 Sequential 构建nn.Sequential是一个有序模块的容器。数据以定义的顺序通过所有的模块。你可以使用 序列容器来组建一个快速的网络。 1234567seq_modules = nn.Sequential( flatten, layer1, nn.ReLU(), nn.Linear(20, 10))logits = seq_modules(input_image) 2 模型参数神经网络中的许多层都是参数化的，也就是说，层相关的权重和偏置在训练中被优化。nn.Module的子类会自动跟踪你的模型对象中定义的所有字段，并使用你的模型的 parameters() 或 named_parameters() 方法访问所有参数。 在这个例子中，我们遍历每个参数，并打印其大小和预览其值。 1234print(&quot;Model structure: &quot;, model, &quot;\\n\\n&quot;)for name, param in model.named_parameters(): print(f&quot;Layer: &#123;name&#125; | Size: &#123;param.size()&#125; | Values : &#123;param[:2]&#125; \\n&quot;) 3 反向传播在训练神经网络时，最常使用的算法是反向传播算法。在这种算法中，参数（模型权重）是根据损失函数相对于给定参数的梯度来调整的。 3.1 自动梯度计算为了计算这些梯度，PyTorch有一个内置的微分引擎，叫做torch.autograd。它支持对任何计算图的梯度进行自动计算。考虑最简单的单层神经网络，输入x，参数w和b，以及一些损失函数。 在这个网络中，w和b是参数，我们需要进行优化。因此，我们需要能够计算损失值相对于这些变量的梯度（梯度只对于模型参数有意义）。为了做到这一点，我们设置了这些tensor的 requires_grad 属性。它可以在PyTorch中以如下方式定义： 12345678910111213# 正向传播import torchx = torch.ones(5) # input tensory = torch.zeros(3) # expected outputw = torch.randn(5, 3, requires_grad=True) # 需要更新的weightb = torch.randn(3, requires_grad=True) # 需要更新的biasz = torch.matmul(x, w)+bloss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)#反向传播loss.backward() #该步骤包含对梯度的自动计算，梯度值通过以下查看。print(w.grad)print(b.grad) 3.2 autograd的机制首先了解tensor有哪些属性： data : 被包装的张量 grad : 存储data的梯度 grad_fn : 创建 Tensor的 Function，是自动求导的关键 requires_grad：指示是否需要梯度 is_leaf : 指示是否是叶子结点 dtype：张量的数据类型 shape：张量的形状，如(64，3，224，224) device：张量所在设备，GPU&#x2F;CPU Tensor和Function互相结合就可以构建一个记录有整个计算过程的有向无环图(Directed Acyclic Graph，DAG)。每个Tensor都有一个.grad_fn属性，该属性即创建该Tensor的Function。 DAG的节点是Function对象，边表示数据依赖，从输出指向输入。 每当对Tensor施加一个运算的时候，就会产生一个Function对象，它产生运算的结果，记录运算的发生，并且记录运算的输入。Tensor使用.grad_fn属性记录这个计算图的入口。反向传播过程中，autograd引擎会按照逆序，通过Function的backward依次计算梯度。 注意事项 （1）梯度不自动清零，如果不清零梯度会累加，所以需要在每次梯度后人为清零。（2）依赖于叶子结点的结点，requires_grad默认为True。（3）叶子结点不可执行in-place，因为其他节点在计算梯度时需要用到叶子节点，所以叶子地址中的值不得改变否则会是其他节点求梯度时出错。所以叶子节点不能进行原位计算。（4）在 y.backward()时，如果 y 是标量量，则不需要为backward()传⼊入任何参数；否则，需要传⼊一个与y同形的Tensor。 （5）只能获得计算图的叶子节点的grad属性，这些节点的requires_grad属性设置为True。对于图中的所有其他节点，梯度将不可用。 （6）只能在一个给定的图上使用一次backward来进行梯度计算。如果需要在同一个图上进行多次backward调用，需要在backward调用中传递 retain_graph&#x3D;True。 （7）在PyTorch中，DAG是动态的。需要注意的是，图是从头开始重新创建的；在每次调用.backward()后，autograd开始填充一个新的图。这正是允许你在模型中使用控制流语句的原因；如果需要，你可以在每次迭代时改变形状、大小和操作。 3.3 禁用梯度跟踪123456789101112# 方法一：利用torch.no_grad()块包围正向传播代码with torch.no_grad(): z = torch.matmul(x, w)+b# 方法二：利用detach方法z = torch.matmul(x, w)+bz_det = z.detach()# 方法三：设置requires_gradfor name, param in model.named_parameters(): param.requires_grad = False","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"3-数据准备","slug":"pytorch基础/3-数据准备","date":"2023-07-25T06:38:09.422Z","updated":"2023-07-25T06:38:09.474Z","comments":true,"path":"2023/07/25/pytorch基础/3-数据准备/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/07/25/pytorch%E5%9F%BA%E7%A1%80/3-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87/","excerpt":"","text":"1 Dataset1.1 图像（path+label形式）12345678910111213141516171819202122232425import osimport pandas as pdfrom torchvision.io import read_imagefrom torchvision import datasetsfrom torchvision import transformsclass CustomImageDataset(Dataset): def __init__(self, annotations_file, img_dir, transform=None, target_transform=None): self.img_labels = pd.read_csv(annotations_file) self.img_dir = img_dir self.transform = transform self.target_transform = target_transform def __len__(self): return len(self.img_labels) def __getitem__(self, idx): img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]) image = read_image(img_path) label = self.img_labels.iloc[idx, 1] if self.transform: image = self.transform(image) if self.target_transform: label = self.target_transform(label) return image, label 1.2 图像（文件夹名为label 形式）12345data_dir = &#x27;data/hymenoptera_data&#x27;train_datasets = datasets.ImageFolder( os.path.join(data_dir, &quot;train&quot;) ,data_transforms[&quot;train&quot;])val_datasets = datasets.ImageFolder( os.path.join(data_dir, &quot;val&quot;) ,data_transforms[&quot;val&quot;]) 1.3 图像（在线拉取）12345train_data = datasets.MNIST(root=&#x27;data&#x27;, train=True, download=True, transform=data_transforms[&quot;train&quot;], target_transform=xxx) 1.4 图片转换1234567891011121314151617# input变换data_transforms = transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])# RandomResizedCrop: 随机长宽比裁剪# RandomHorizontalFlip: 随机水平翻转# RandomVerticalFlip: 随机垂直翻转# ToTensor: 转换为tensor# Normalize: 像素值进行归一化处理# target 变换# 把整数变成一个one-hot的tensortarget_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float) \\ .scatter_(dim=0, index=torch.tensor(y), value=1)) 2 DataLoader123456train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)for batch, (X, y) in enumerate(train_dataloader): X, y = X.to(device), y.to(device)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"2-tensor基础","slug":"pytorch基础/2-tensor操作","date":"2023-07-24T09:18:03.276Z","updated":"2023-07-25T06:26:52.819Z","comments":true,"path":"2023/07/24/pytorch基础/2-tensor操作/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/07/24/pytorch%E5%9F%BA%E7%A1%80/2-tensor%E6%93%8D%E4%BD%9C/","excerpt":"","text":"1 tensor属性1.1 tensor初始化1234shape = (2,3,)rand_tensor = torch.rand(shape)ones_tensor = torch.ones(shape)zeros_tensor = torch.zeros(shape) 1.2 tensor性质1234tensor = torch.rand(3,4)print(f&quot;Shape of tensor: &#123;tensor.shape&#125;&quot;)print(f&quot;Datatype of tensor: &#123;tensor.dtype&#125;&quot;)print(f&quot;Device tensor is stored on: &#123;tensor.device&#125;&quot;) 2 对象转换2.1 list – tensor123456data = [[1, 2], [3, 4]]# list--&gt; tensor# 数据类型是自动推断出来x_tensor = torch.tensor(data)# tensor--&gt; listx_list = x_tensor.tolist() 2.2 numpy – tensor12345np_array = np.array(data)# numpy --&gt; tensorx_tensor = torch.from_numpy(np_array)# tensor --&gt; numpyx_numpy = x_tensor.numpy() 2.3 tensor – tensor12x_ones = torch.ones_like(x_data) # retains the properties of x_datax_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data 3 运算&amp;操作3.1 矩阵乘法1234y1 = tensor @ tensor.Ty2 = tensor.matmul(tensor.T)y3 = torch.rand_like(tensor)torch.matmul(tensor, tensor.T, out=y3) 3.2 矩阵点乘12345z1 = tensor * tensorz2 = tensor.mul(tensor)z3 = torch.rand_like(tensor)torch.mul(tensor, tensor, out=z3) 3.3 矩阵拼接1234# 指定的dim 数量增加，除了dim之外的dim需要相同才行t1 = torch.cat([tensor, tensor, tensor], dim=1)# 两个要进行stack的tensor的dim数量应该相同，stack操作之后得到的结果会多出一维，即dim的数量会+1。t1 = torch.stack([tensor, tensor, tensor], dim=1) 3.4 矩阵升降维123456# 升维。插入指定维度，值为1tensor.unsqueeze(dim=0)# 降维。压缩指定维度，该维度值必须为1# 当dim不指定时，压缩所有维度值为1的维tensor.squeeze(dim=0)tensor.squeeze()","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"1-pytorch快速开始","slug":"pytorch基础/1-pytorch快速开始","date":"2023-07-24T09:15:16.547Z","updated":"2023-07-24T10:01:37.638Z","comments":true,"path":"2023/07/24/pytorch基础/1-pytorch快速开始/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/07/24/pytorch%E5%9F%BA%E7%A1%80/1-pytorch%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/","excerpt":"","text":"0 导库123456import torchfrom torch import nnfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision.transforms import ToTensor, Lambda, Composeimport matplotlib.pyplot as plt 1 数据准备torchvision.datasets模块包含了许多真实世界的视觉数据的数据集对象，如CIFAR、COCO。以下通过datasets在线加载FashionMNIST数据集。 123456789101112131415# Download training data from open datasets.training_data = datasets.FashionMNIST( root=&quot;data&quot;, train=True, download=True, transform=ToTensor(),)# Download test data from open datasets.test_data = datasets.FashionMNIST( root=&quot;data&quot;, train=False, download=True, transform=ToTensor(),) 将dataset装载入DataLoader中，DataLoader可认为是一个数据迭代器，其支持数据的自动批处理、采样、洗牌和多进程数据加载。这里定义一个 batch&#x3D;64，即dataloader可迭代的每个元素将返回一个批次，包括64个元素的特征和标签。 123456789batch_size = 64# Create data loaders.train_dataloader = DataLoader(training_data, batch_size=batch_size)test_dataloader = DataLoader(test_data, batch_size=batch_size)for X, y in test_dataloader: print(&quot;Shape of X [N, C, H, W]: &quot;, X.shape) print(&quot;Shape of y: &quot;, y.shape, y.dtype) break 2 创建模型为了在PyTorch中定义一个神经网络，我们创建一个继承自nn.Module的类。我们在__init__函数中定义网络的层，并在forward函数中指定数据将如何通过网络。为了加速神经网络的操作，如果有GPU的话，我们把它移到GPU上。 1234567891011121314151617181920212223# Get cpu or gpu device for training.device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;# Define modelclass NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10) ) def forward(self, x): x = self.flatten(x) logits = self.linear_relu_stack(x) return logitsmodel = NeuralNetwork().to(device)print(model) 3 优化模型参数3.1 模型训练函数12345678910111213141516171819202122loss_fn = nn.CrossEntropyLoss()optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)def train(dataloader, model, loss_fn, optimizer): size = len(dataloader.dataset) model.train() for batch, (X, y) in enumerate(dataloader): X, y = X.to(device), y.to(device) # Compute prediction error pred = model(X) loss = loss_fn(pred, y) # Backpropagation optimizer.zero_grad() loss.backward() optimizer.step() if batch % 100 == 0: loss, current = loss.item(), batch * len(X) print(f&quot;loss: &#123;loss:&gt;7f&#125; [&#123;current:&gt;5d&#125;/&#123;size:&gt;5d&#125;]&quot;) 3.2 模型评估函数1234567891011121314def test(dataloader, model, loss_fn): size = len(dataloader.dataset) num_batches = len(dataloader) model.eval() test_loss, correct = 0, 0 with torch.no_grad(): for X, y in dataloader: X, y = X.to(device), y.to(device) pred = model(X) test_loss += loss_fn(pred, y).item() correct += (pred.argmax(1) == y).type(torch.float).sum().item() test_loss /= num_batches correct /= size print(f&quot;Test Error: \\n Accuracy: &#123;(100*correct):&gt;0.1f&#125;%, Avg loss: &#123;test_loss:&gt;8f&#125; \\n&quot;)1 3.3 启动训练&amp;评估123456epochs = 5for t in range(epochs): print(f&quot;Epoch &#123;t+1&#125;\\n-------------------------------&quot;) train(train_dataloader, model, loss_fn, optimizer) test(test_dataloader, model, loss_fn)print(&quot;Done!&quot;) 4 保存模型12torch.save(model.state_dict(), &quot;model.pth&quot;)print(&quot;Saved PyTorch Model State to model.pth&quot;) 5 加载模型12model = NeuralNetwork()model.load_state_dict(torch.load(&quot;model.pth&quot;)) 6 模型推理12345678910111213141516171819classes = [ &quot;T-shirt/top&quot;, &quot;Trouser&quot;, &quot;Pullover&quot;, &quot;Dress&quot;, &quot;Coat&quot;, &quot;Sandal&quot;, &quot;Shirt&quot;, &quot;Sneaker&quot;, &quot;Bag&quot;, &quot;Ankle boot&quot;,]model.eval()x, y = test_data[0][0], test_data[0][1]with torch.no_grad(): pred = model(x) predicted, actual = classes[pred[0].argmax(0)], classes[y] print(f&#x27;Predicted: &quot;&#123;predicted&#125;&quot;, Actual: &quot;&#123;actual&#125;&quot;&#x27;)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-07-21T10:28:18.087Z","updated":"2023-07-23T10:23:20.541Z","comments":true,"path":"2023/07/21/hello-world/","link":"","permalink":"https://xie-peiquan.gitee.io/2023/07/21/hello-world/","excerpt":"","text":"今天坑坑洼洼可算是把网站给搭好了，看着简洁漂亮的首页，想着以后就有专属自己的网站，就很开心。背景图是《权游》里面的某一幕的简画，守夜人面对夜鬼的来袭，背水一战，颇为壮观。 为什么要做个人博客呢？说实话，没有特别的理由。或许是出于新鲜感；或许是工作太无聊；或许是外界太嘈杂，想在数字世界中寻找一片净土；或许是想把有趣的、新奇的东西系统地放进来，有一天可以带朋友来参观，看！这是我曾经的快乐和珍藏。 现实世界有太多约束，说话做事写文章处处存在隐形的规矩，这些规矩容易消磨本身藏在事物的乐趣。我想，在这里就少点规矩吧，说说废话，吹吹牛逼又怎么样呢？有时候写点生活感悟也不怕别人说我假正经。嗯，没错，这是我的展厅！当然，对于涉及实操性或理论性的文章，行文还是遵从逻辑，便于理解和回顾。 那么，第一篇写点啥呢，emmm…","categories":[{"name":"建站","slug":"建站","permalink":"https://xie-peiquan.gitee.io/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"建站","slug":"建站","permalink":"https://xie-peiquan.gitee.io/tags/%E5%BB%BA%E7%AB%99/"}]}],"categories":[{"name":"音乐","slug":"音乐","permalink":"https://xie-peiquan.gitee.io/categories/%E9%9F%B3%E4%B9%90/"},{"name":"C++并发编程基础","slug":"C-并发编程基础","permalink":"https://xie-peiquan.gitee.io/categories/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"},{"name":"混合编程","slug":"混合编程","permalink":"https://xie-peiquan.gitee.io/categories/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"},{"name":"C++那些事","slug":"C-那些事","permalink":"https://xie-peiquan.gitee.io/categories/C-%E9%82%A3%E4%BA%9B%E4%BA%8B/"},{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/categories/ROS1/"},{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/categories/ROS2%E5%9F%BA%E7%A1%80/"},{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/categories/Pytorch%E5%9F%BA%E7%A1%80/"},{"name":"建站","slug":"建站","permalink":"https://xie-peiquan.gitee.io/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"聊点音乐","slug":"聊点音乐","permalink":"https://xie-peiquan.gitee.io/tags/%E8%81%8A%E7%82%B9%E9%9F%B3%E4%B9%90/"},{"name":"并发编程","slug":"并发编程","permalink":"https://xie-peiquan.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"混合编程","slug":"混合编程","permalink":"https://xie-peiquan.gitee.io/tags/%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B/"},{"name":"C++库","slug":"C-库","permalink":"https://xie-peiquan.gitee.io/tags/C-%E5%BA%93/"},{"name":"ROS1","slug":"ROS1","permalink":"https://xie-peiquan.gitee.io/tags/ROS1/"},{"name":"ROS2基础","slug":"ROS2基础","permalink":"https://xie-peiquan.gitee.io/tags/ROS2%E5%9F%BA%E7%A1%80/"},{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"https://xie-peiquan.gitee.io/tags/Pytorch%E5%9F%BA%E7%A1%80/"},{"name":"建站","slug":"建站","permalink":"https://xie-peiquan.gitee.io/tags/%E5%BB%BA%E7%AB%99/"}]}