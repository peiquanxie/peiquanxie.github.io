{"meta":{"title":"PQ.XIE BLOG","subtitle":"","description":"个人博客","author":"PQ.XIE","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2023-07-22T02:40:44.436Z","updated":"2023-07-22T02:40:44.436Z","comments":true,"path":"404.html","permalink":"http://example.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2023-07-28T09:11:55.709Z","updated":"2023-07-28T09:11:55.709Z","comments":true,"path":"baidu_verify_codeva-3bR1bjdnkE.html","permalink":"http://example.com/baidu_verify_codeva-3bR1bjdnkE.html","excerpt":"","text":"e522504a2b93d12f0dc162fcc0572c79"},{"title":"","date":"2023-07-28T09:26:16.461Z","updated":"2023-07-28T09:26:16.461Z","comments":true,"path":"googlef847041eb4e8ca77.html","permalink":"http://example.com/googlef847041eb4e8ca77.html","excerpt":"","text":"google-site-verification: googlef847041eb4e8ca77.html"},{"title":"","date":"2023-07-26T09:27:47.030Z","updated":"2023-07-26T09:27:47.030Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"联系方式邮箱：&#x32;&#x31;&#50;&#x39;&#53;&#x31;&#x36;&#x39;&#50;&#64;&#x71;&#x71;&#x2e;&#x63;&#x6f;&#x6d; 版权声明站点内的所有原创内容（包括但不限于文章、图像等）除特别声明外均采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议，任何人都可以自由传播，但不得用于商用且必须署名并以相同方式分享。本站部分内容转载于网络，有出处的已在文中署名作者并附加原文链接，出处已不可寻的皆已标注来源于网络。若您认为本站点有部分内容侵犯了您的权益，请在电邮告知，我将认真处理。"},{"title":"所有分类","date":"2023-07-22T02:37:26.591Z","updated":"2023-07-22T02:37:26.591Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2023-07-26T09:31:42.263Z","updated":"2023-07-26T09:31:42.263Z","comments":false,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2023-07-22T02:37:59.687Z","updated":"2023-07-22T02:37:59.687Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"1-ROS2安装(armhf篇)","slug":"ROS2基础/1-ROS2安装(armhf篇)","date":"2023-08-18T09:34:12.047Z","updated":"2023-08-18T09:34:12.091Z","comments":true,"path":"2023/08/18/ROS2基础/1-ROS2安装(armhf篇)/","link":"","permalink":"http://example.com/2023/08/18/ROS2%E5%9F%BA%E7%A1%80/1-ROS2%E5%AE%89%E8%A3%85(armhf%E7%AF%87)/","excerpt":"","text":"由于ROS官方并没有提供armhf CPU架构的ROS2二进制安装文件，本篇整理了从ROS2源码编译安装的方法。本篇安装环境如下： CPU架构：armv7l操作系统：ubuntu20.04 1 更换镜像源（可选）更换镜像源可以加速各种依赖库下载速度，这里提供常用的 ubuntu镜像源 和 pip源。 1.1 更换ubuntu镜像源这里采用清华源，同学们可到该网站 https://mirror.tuna.tsinghua.edu.cn/help/ubuntu/ 寻找自己系统版本对应的源。需要注意的是，大部分高校提供的源都是X86架构的，对于arm设备需要在源加上‘-ports’ 。armv7l &#x2F; ubuntu20.04的源如下： mv &#x2F;etc&#x2F;apt&#x2F;sources.list &#x2F;etc&#x2F;apt&#x2F;sources.list.bakvim &#x2F;etc&#x2F;apt&#x2F;sources.list 123456789# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ focal-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse 1.2 更换 PIP 源这里同样采用清华的pip源，可加速python第三方库的下载（后面需要），命令行输入以下命令即可。 12pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplepip config set global.trusted-host https://pypi.tuna.tsinghua.edu.cn 2 设置 locale12345sudo apt update &amp;&amp; sudo apt install localessudo locale-gen en_US en_US.UTF-8sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8export LANG=en_US.UTF-8locale # verify settings 3 添加ROS2 存储库12345678910111213# 1 确保启用universe存储库sudo apt install software-properties-commonsudo add-apt-repository universe# 2 添加ROS2 GPG 密钥sudo apt update &amp;&amp; sudo apt install curl -ysudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg# 3 添加存储库到 sources listecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main&quot; | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null# 4 更新aptsudo apt apdate 4 安装编译工具123456789101112131415161718192021222324252627sudo apt update &amp;&amp; sudo apt install -y \\ libbullet-dev \\ python3-pip \\ python3-pytest-cov \\ ros-dev-tools# install some pip packages needed for testingpython3 -m pip install -U \\ argcomplete \\ flake8-blind-except \\ flake8-builtins \\ flake8-class-newline \\ flake8-comprehensions \\ flake8-deprecated \\ flake8-docstrings \\ flake8-import-order \\ flake8-quotes \\ pytest-repeat \\ pytest-rerunfailures \\ pytest# install Fast-RTPS dependenciessudo apt install --no-install-recommends -y \\ libasio-dev \\ libtinyxml2-dev# install Cyclone DDS dependenciessudo apt install --no-install-recommends -y \\ libcunit1-dev 5 获取ROS2源码12345mkdir -p ~/ros2_foxy/srccd ~/ros2_foxywget https://raw.githubusercontent.com/ros2/ros2/foxy/ros2.repos --no-check-certificate## github下载不稳定，可自行修改repos文件，添加代理前缀 https://ghproxy.com/vcs import --input ./ros2.repos src 6 使用Rosdep安装依赖1234sudo apt upgradecd /etc/ros/rosdep/sources.list.d &amp;&amp; wget https://mirrors.tuna.tsinghua.edu.cn/github-raw/ros/rosdistro/master/rosdep/sources.list.d/20-default.listrosdep updaterosdep install --from-paths src --ignore-src -y --skip-keys &quot;fastcdr rti-connext-dds-5.3.1 urdfdom_headers&quot; 7 编译ROS2源码12cd ~/ros2_foxy/colcon build --symlink-install 8 设置环境变量1. ~/ros2_foxy/install/local_setup.bash 9 测试1234567## 运行talker. ~/ros2_foxy/install/local_setup.bashros2 run demo_nodes_cpp talker## 新起另一个终端，运行listener. ~/ros2_foxy/install/local_setup.bashros2 run demo_nodes_py listener","categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"http://example.com/categories/ROS2%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"http://example.com/tags/ROS2%E5%9F%BA%E7%A1%80/"}]},{"title":"1-西方哲学摘录","slug":"哲学思考/1-西方哲学摘录","date":"2023-07-26T16:16:41.776Z","updated":"2023-07-26T16:20:24.385Z","comments":true,"path":"2023/07/27/哲学思考/1-西方哲学摘录/","link":"","permalink":"http://example.com/2023/07/27/%E5%93%B2%E5%AD%A6%E6%80%9D%E8%80%83/1-%E8%A5%BF%E6%96%B9%E5%93%B2%E5%AD%A6%E6%91%98%E5%BD%95/","excerpt":"","text":"黑格尔哲学形而上学形而上学的根本特征是以思维（概念）规定感性（事物），在概念中确认哲学所追求的“最高原因的基本原理”。这种基本原理可以使人类经验中的各种各样的事物得到统一性的解释，或者可以被解释为某种普遍本质的各种具体表现，从而使思维实现其把握和解释世界的“全体自由性”。 黑格尔哲学特点黑格尔以辩证法改造形而上学，是通过对构成旧形而上学的抽象理性的批判，以概念的辩证运动实现思维规定感性的形而上学，把“全体的自由性”与“环节的必然性”统一起来，从而把形而上学构建成本体论、认识论和逻辑学相统一的辩证法。这就是黑格尔在哲学上的贡献，将辩证法和形而上学“合流”，也可以认为是形而上学的“完成”。 黑格尔概念辩证法的出发点是双重的，一是思维与存在的同一性，即概念是思维和存在同一的规定性；二是思维与存在的差别的内在的发生，即概念是在自身的辩证运动中所达到的思存同一性。 黑格尔哲学意义在哲学史意义上，黑格尔的概念辩证法，构成了一种双重的“何以可能”：一是“认识何以可能”的逻辑；二是“自由何以可能”的逻辑。前者把认识的可能性归结为概念的辩证运动，即思维与存在的统一展现为概念由抽象的同一到具体的同一的运动过程。后者把自由何以可能得问题同样归结为概念的辩证运动，即概念由抽象的普遍性（自在的全体的自由性）到具体的普遍性（环节的必然性）的运动过程。 为何要加入辩证法在黑格尔看来，之所以把形而上学改造成辩证法，是因为作为真理的哲学必须是使“心灵深入于这些内容，借他们而得到教训，增进力量”，“引导一个个体使之从它的未受教养状态变为有知识的，这是个任务”。“每个个体都必须走过普遍精神所走过的那些发展阶段”。 如何看待黑格尔思想黑格尔思想既是对传统形而上学的否定，又是对传统形而上学的完成。否定是因为它在思维规定感性的形而上学传统中，揭示了概念——思维规定感性的主体和实体的内在矛盾性，迫使形而上学于辩证法合流。完成是指它在思维规定感性的形而上学传统中，确认了概念（普遍理性）作为唯一的主体和实体的地位，又把辩证法变成了概念形而上学。 从深层的社会根源上看，黑格尔则是以哲学的方式表征了他所处资本主义社会的内在矛盾性：一方面，资产阶级除非使全部社会关系不断地革命化便不能生存下去，“否定”构成资本主义生产方式的内在要求；另一方面，资产阶级社会的商品交换原则的同一性构成全部社会生活的根本模式，“概念”成为规范一切生活领域的意识形态。 马克思哲学哲学使命的跃迁 “人的自我异化的神圣形象被揭穿之后，揭露非神圣形象的自我异化，就成为了为历史服务的哲学的迫切任务。于是对天国的批判就变成了对尘世的批判，对宗教的批判就变成对法的批判，对神学的批判就变成了对政治的批判。” 近代的西方历史，从经济形态上来说，是以市场经济取代自然经济的过程；从人的存在形态上说，是人从人对人的“依附性”存在转换为“以物的依赖性为基础的人的独立性”的过程；从文化形态上说，则是从“神学文化”转换为“哲学科学文化”的过程。这个历史过程所构成的时代精神的变革，是哲学使命的历史性转换的最重要的生活基础。 现代哲学使命两个“消解”和两种“归还”：近代以来的哲学是“消解”人在“神圣形象”中的“自我异化”，把异化给“神圣形象”的人的本质“归还”给人；现代哲学的使命则是“消解”人在“非神圣形象”中的“自我异化”，把异化给“非神圣形象”的人的本质“归还”给人。 如何理解第一种消解？自然经济所要求的是经济上禁欲，精神上蒙昧，政治上专制，从而造成人在“神圣形象”中的“自我异化”。而取代自然经济的市场经济反对禁欲而要求人的现实幸福，反对蒙昧而要求人的理性自由，反对专制而要求人的天赋人权，也即市场经济的三个基本取向：功利主义的价值取向，工具理性的思维取向，民主法治的政治取向。这三种基本取向也即马克思说的，以物的依赖性为基础的人的独立性。本质上，第一种消解是理性取代上帝的过程。 如何理解第二种消解？近代哲学又使人在“理性”中造成了新的“自我异化”，即把理性变成了凌驾于人之上的“本质主义的肆虐”。近代哲学本质上是以理论的方式表达了正在受“抽象”统治的近代以来的人的生存状态，也就是人的“独立性”建立在对物的依赖性的基础之上的生存状态。如果说近代哲学表征的是“理性的时代”，则现代哲学可概括为“理性的批判”，其表征的是“反省理性的时代”。","categories":[{"name":"哲学笔记","slug":"哲学笔记","permalink":"http://example.com/categories/%E5%93%B2%E5%AD%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"哲学笔记","slug":"哲学笔记","permalink":"http://example.com/tags/%E5%93%B2%E5%AD%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"5-模型调参","slug":"pytorch基础/5-模型调参","date":"2023-07-26T09:21:38.260Z","updated":"2023-07-26T09:21:38.312Z","comments":true,"path":"2023/07/26/pytorch基础/5-模型调参/","link":"","permalink":"http://example.com/2023/07/26/pytorch%E5%9F%BA%E7%A1%80/5-%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/","excerpt":"","text":"1 超参数超参数是可调整的参数，让你控制模型优化过程。不同的超参数值会影响模型的训练和收敛率。 常用的超参数如下： epoch : 在整个数据集上迭代的次数。 batch : 每一次更新参数（反向传播）所用到的数据样本数。 学习率 : 每个batch 更新模型参数的步进幅度。 123learning_rate = 1e-3batch_size = 64epochs = 5 2 损失函数当遇到一些训练数据时，我们未经训练的网络很可能不会给出正确的答案。损失函数衡量的是获得的结果与目标值的不相似程度，它是我们在训练期间想要最小化的损失函数。为了计算损失，我们使用给定数据样本的输入进行预测，并与真实数据标签值进行比较。 常见的损失函数包括用于回归任务的nn.MSELoss（均方误差）和用于分类的nn.NLLLoss（负对数似然）。nn.CrossEntropyLoss结合了nn.LogSoftmax和nn.NLLLoss。 我们将模型的输出对数传递给 nn.CrossEntropyLoss，它将对对数进行标准化处理并计算预测误差。 12# Initialize the loss functionloss_fn = nn.CrossEntropyLoss() 3 优化器优化是在每个训练步骤中调整模型参数以减少模型误差的过程。优化算法定义了这个过程是如何进行的（在这个例子中，我们使用随机梯度下降法）。所有的优化逻辑都被封装在优化器对象中。在这里，我们使用SGD优化器；此外，PyTorch中还有许多不同的优化器，如Adam和RMSProp，它们对不同类型的模型和数据有更好的效果。 我们通过注册需要训练的模型参数来初始化优化器，并传入学习率超参数。 1optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) 4 调参过程我们定义了train_loop和test_loop，train_loop负责循环我们的优化代码，test_loop负责根据测试数据评估模型的性能。 12345678910111213141516171819202122232425262728293031def train_loop(dataloader, model, loss_fn, optimizer): size = len(dataloader.dataset) for batch, (X, y) in enumerate(dataloader): # Compute prediction and loss pred = model(X) loss = loss_fn(pred, y) # Backpropagation optimizer.zero_grad() loss.backward() optimizer.step() if batch % 100 == 0: loss, current = loss.item(), batch * len(X) print(f&quot;loss: &#123;loss:&gt;7f&#125; [&#123;current:&gt;5d&#125;/&#123;size:&gt;5d&#125;]&quot;)def test_loop(dataloader, model, loss_fn): size = len(dataloader.dataset) num_batches = len(dataloader) test_loss, correct = 0, 0 with torch.no_grad(): for X, y in dataloader: pred = model(X) test_loss += loss_fn(pred, y).item() correct += (pred.argmax(1) == y).type(torch.float).sum().item() test_loss /= num_batches correct /= size print(f&quot;Test Error: \\n Accuracy: &#123;(100*correct):&gt;0.1f&#125;%, Avg loss: &#123;test_loss:&gt;8f&#125; \\n&quot;) 123456789loss_fn = nn.CrossEntropyLoss()optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)epochs = 10for t in range(epochs): print(f&quot;Epoch &#123;t+1&#125;\\n-------------------------------&quot;) train_loop(train_dataloader, model, loss_fn, optimizer) test_loop(test_dataloader, model, loss_fn)print(&quot;Done!&quot;) 请确保在推理前调用model.eval()方法，以将dropout和batch normalization层设置为eval模式。如果不这样做，将产生不一致的推理结果。 5 保存&amp;加载5.1 保存状态字典123torch.save(model.state_dict(), &#x27;model_weights.pth&#x27;)model = Model_Net() # 需要实例化训练时相同的类model.load_state_dict(torch.load(&#x27;model_weights.pth&#x27;)) 5.2 保存整个模型类123# 这种方法在序列化模型时使用Python的pickle模块，所以它在加载模型时，依赖于实际的可用的类定义。torch.save(model, &#x27;model.pth&#x27;)model = torch.load(&#x27;model.pth&#x27;) 5.3 导出ONNX模型123# 由于PyTorch执行图的动态性质，导出过程必须遍历执行图以产生持久的ONNX模型。出于这个原因，应该向导出程序传递一个适当大小的测试变量。input_image = torch.zeros((1,3,224,224))onnx.export(model, input_image, &#x27;model.onnx&#x27;) 5.4 导出JIT模型该种方法加载模型时无需 模型类，导出 JIT 模型的方式有两种：trace 和 script。 采用 torch.jit.trace 的方式来导出 JIT 模型，这种方式会根据一个输入将模型跑一遍，然后记录下执行过程。这种方式的问题在于对于有分支判断的模型不能很好的应对，因为一个输入不能覆盖到所有的分支。但是在我们 ResNet50 模型中不会遇到分支判断，因此这里是合适的。 12345# trace 方法保存example_input = torch.rand(1, 3, 224, 224)jit_model = torch.jit.trace(model, example_input)torch.jit.save(jit_model, &#x27;resnet50_jit.pth&#x27;)module = torch.jit.load(&#x27;resnet50_jit.pth&#x27;) 如果模型有 if else 等分支语句, 应该用script方法保存模型。 1234# script 方法保存script_module = torch.jit.script(model) torch.jit.save(script_module, &#x27;model.pth&#x27;)module = torch.jit.load(&#x27;model.pth&#x27;)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"4-模型搭建","slug":"pytorch基础/4-模型搭建","date":"2023-07-26T09:18:44.419Z","updated":"2023-07-26T09:18:44.467Z","comments":true,"path":"2023/07/26/pytorch基础/4-模型搭建/","link":"","permalink":"http://example.com/2023/07/26/pytorch%E5%9F%BA%E7%A1%80/4-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA/","excerpt":"","text":"1 神经网络搭建1.1 通过 forward 构建我们可以通过继承 nn.Module，构建我们自己的类来定义我们的神经网络。其中，我们在__init__方法中实现各个子Module的初始化，并在forward 方法中组织这些子Module，形成神经网络。 12345678910111213141516171819class NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10), ) def forward(self, x): x = self.flatten(x) logits = self.linear_relu_stack(x) return logitsmodel = NeuralNetwork().to(device)logits = model(input_image) 1.2 通过 Sequential 构建nn.Sequential是一个有序模块的容器。数据以定义的顺序通过所有的模块。你可以使用 序列容器来组建一个快速的网络。 1234567seq_modules = nn.Sequential( flatten, layer1, nn.ReLU(), nn.Linear(20, 10))logits = seq_modules(input_image) 2 模型参数神经网络中的许多层都是参数化的，也就是说，层相关的权重和偏置在训练中被优化。nn.Module的子类会自动跟踪你的模型对象中定义的所有字段，并使用你的模型的 parameters() 或 named_parameters() 方法访问所有参数。 在这个例子中，我们遍历每个参数，并打印其大小和预览其值。 1234print(&quot;Model structure: &quot;, model, &quot;\\n\\n&quot;)for name, param in model.named_parameters(): print(f&quot;Layer: &#123;name&#125; | Size: &#123;param.size()&#125; | Values : &#123;param[:2]&#125; \\n&quot;) 3 反向传播在训练神经网络时，最常使用的算法是反向传播算法。在这种算法中，参数（模型权重）是根据损失函数相对于给定参数的梯度来调整的。 3.1 自动梯度计算为了计算这些梯度，PyTorch有一个内置的微分引擎，叫做torch.autograd。它支持对任何计算图的梯度进行自动计算。考虑最简单的单层神经网络，输入x，参数w和b，以及一些损失函数。 在这个网络中，w和b是参数，我们需要进行优化。因此，我们需要能够计算损失值相对于这些变量的梯度（梯度只对于模型参数有意义）。为了做到这一点，我们设置了这些tensor的 requires_grad 属性。它可以在PyTorch中以如下方式定义： 12345678910111213# 正向传播import torchx = torch.ones(5) # input tensory = torch.zeros(3) # expected outputw = torch.randn(5, 3, requires_grad=True) # 需要更新的weightb = torch.randn(3, requires_grad=True) # 需要更新的biasz = torch.matmul(x, w)+bloss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)#反向传播loss.backward() #该步骤包含对梯度的自动计算，梯度值通过以下查看。print(w.grad)print(b.grad) 3.2 autograd的机制首先了解tensor有哪些属性： data : 被包装的张量 grad : 存储data的梯度 grad_fn : 创建 Tensor的 Function，是自动求导的关键 requires_grad：指示是否需要梯度 is_leaf : 指示是否是叶子结点 dtype：张量的数据类型 shape：张量的形状，如(64，3，224，224) device：张量所在设备，GPU&#x2F;CPU Tensor和Function互相结合就可以构建一个记录有整个计算过程的有向无环图(Directed Acyclic Graph，DAG)。每个Tensor都有一个.grad_fn属性，该属性即创建该Tensor的Function。 DAG的节点是Function对象，边表示数据依赖，从输出指向输入。 每当对Tensor施加一个运算的时候，就会产生一个Function对象，它产生运算的结果，记录运算的发生，并且记录运算的输入。Tensor使用.grad_fn属性记录这个计算图的入口。反向传播过程中，autograd引擎会按照逆序，通过Function的backward依次计算梯度。 注意事项 （1）梯度不自动清零，如果不清零梯度会累加，所以需要在每次梯度后人为清零。（2）依赖于叶子结点的结点，requires_grad默认为True。（3）叶子结点不可执行in-place，因为其他节点在计算梯度时需要用到叶子节点，所以叶子地址中的值不得改变否则会是其他节点求梯度时出错。所以叶子节点不能进行原位计算。（4）在 y.backward()时，如果 y 是标量量，则不需要为backward()传⼊入任何参数；否则，需要传⼊一个与y同形的Tensor。 （5）只能获得计算图的叶子节点的grad属性，这些节点的requires_grad属性设置为True。对于图中的所有其他节点，梯度将不可用。 （6）只能在一个给定的图上使用一次backward来进行梯度计算。如果需要在同一个图上进行多次backward调用，需要在backward调用中传递 retain_graph&#x3D;True。 （7）在PyTorch中，DAG是动态的。需要注意的是，图是从头开始重新创建的；在每次调用.backward()后，autograd开始填充一个新的图。这正是允许你在模型中使用控制流语句的原因；如果需要，你可以在每次迭代时改变形状、大小和操作。 3.3 禁用梯度跟踪123456789101112# 方法一：利用torch.no_grad()块包围正向传播代码with torch.no_grad(): z = torch.matmul(x, w)+b# 方法二：利用detach方法z = torch.matmul(x, w)+bz_det = z.detach()# 方法三：设置requires_gradfor name, param in model.named_parameters(): param.requires_grad = False","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"3-数据准备","slug":"pytorch基础/3-数据准备","date":"2023-07-25T06:38:09.422Z","updated":"2023-07-25T06:38:09.474Z","comments":true,"path":"2023/07/25/pytorch基础/3-数据准备/","link":"","permalink":"http://example.com/2023/07/25/pytorch%E5%9F%BA%E7%A1%80/3-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87/","excerpt":"","text":"1 Dataset1.1 图像（path+label形式）12345678910111213141516171819202122232425import osimport pandas as pdfrom torchvision.io import read_imagefrom torchvision import datasetsfrom torchvision import transformsclass CustomImageDataset(Dataset): def __init__(self, annotations_file, img_dir, transform=None, target_transform=None): self.img_labels = pd.read_csv(annotations_file) self.img_dir = img_dir self.transform = transform self.target_transform = target_transform def __len__(self): return len(self.img_labels) def __getitem__(self, idx): img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]) image = read_image(img_path) label = self.img_labels.iloc[idx, 1] if self.transform: image = self.transform(image) if self.target_transform: label = self.target_transform(label) return image, label 1.2 图像（文件夹名为label 形式）12345data_dir = &#x27;data/hymenoptera_data&#x27;train_datasets = datasets.ImageFolder( os.path.join(data_dir, &quot;train&quot;) ,data_transforms[&quot;train&quot;])val_datasets = datasets.ImageFolder( os.path.join(data_dir, &quot;val&quot;) ,data_transforms[&quot;val&quot;]) 1.3 图像（在线拉取）12345train_data = datasets.MNIST(root=&#x27;data&#x27;, train=True, download=True, transform=data_transforms[&quot;train&quot;], target_transform=xxx) 1.4 图片转换1234567891011121314151617# input变换data_transforms = transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])# RandomResizedCrop: 随机长宽比裁剪# RandomHorizontalFlip: 随机水平翻转# RandomVerticalFlip: 随机垂直翻转# ToTensor: 转换为tensor# Normalize: 像素值进行归一化处理# target 变换# 把整数变成一个one-hot的tensortarget_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float) \\ .scatter_(dim=0, index=torch.tensor(y), value=1)) 2 DataLoader123456train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)for batch, (X, y) in enumerate(train_dataloader): X, y = X.to(device), y.to(device)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"2-tensor基础","slug":"pytorch基础/2-tensor操作","date":"2023-07-24T09:18:03.276Z","updated":"2023-07-25T06:26:52.819Z","comments":true,"path":"2023/07/24/pytorch基础/2-tensor操作/","link":"","permalink":"http://example.com/2023/07/24/pytorch%E5%9F%BA%E7%A1%80/2-tensor%E6%93%8D%E4%BD%9C/","excerpt":"","text":"1 tensor属性1.1 tensor初始化1234shape = (2,3,)rand_tensor = torch.rand(shape)ones_tensor = torch.ones(shape)zeros_tensor = torch.zeros(shape) 1.2 tensor性质1234tensor = torch.rand(3,4)print(f&quot;Shape of tensor: &#123;tensor.shape&#125;&quot;)print(f&quot;Datatype of tensor: &#123;tensor.dtype&#125;&quot;)print(f&quot;Device tensor is stored on: &#123;tensor.device&#125;&quot;) 2 对象转换2.1 list – tensor123456data = [[1, 2], [3, 4]]# list--&gt; tensor# 数据类型是自动推断出来x_tensor = torch.tensor(data)# tensor--&gt; listx_list = x_tensor.tolist() 2.2 numpy – tensor12345np_array = np.array(data)# numpy --&gt; tensorx_tensor = torch.from_numpy(np_array)# tensor --&gt; numpyx_numpy = x_tensor.numpy() 2.3 tensor – tensor12x_ones = torch.ones_like(x_data) # retains the properties of x_datax_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data 3 运算&amp;操作3.1 矩阵乘法1234y1 = tensor @ tensor.Ty2 = tensor.matmul(tensor.T)y3 = torch.rand_like(tensor)torch.matmul(tensor, tensor.T, out=y3) 3.2 矩阵点乘12345z1 = tensor * tensorz2 = tensor.mul(tensor)z3 = torch.rand_like(tensor)torch.mul(tensor, tensor, out=z3) 3.3 矩阵拼接1234# 指定的dim 数量增加，除了dim之外的dim需要相同才行t1 = torch.cat([tensor, tensor, tensor], dim=1)# 两个要进行stack的tensor的dim数量应该相同，stack操作之后得到的结果会多出一维，即dim的数量会+1。t1 = torch.stack([tensor, tensor, tensor], dim=1) 3.4 矩阵升降维123456# 升维。插入指定维度，值为1tensor.unsqueeze(dim=0)# 降维。压缩指定维度，该维度值必须为1# 当dim不指定时，压缩所有维度值为1的维tensor.squeeze(dim=0)tensor.squeeze()","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"1-pytorch快速开始","slug":"pytorch基础/1-pytorch快速开始","date":"2023-07-24T09:15:16.547Z","updated":"2023-07-24T10:01:37.638Z","comments":true,"path":"2023/07/24/pytorch基础/1-pytorch快速开始/","link":"","permalink":"http://example.com/2023/07/24/pytorch%E5%9F%BA%E7%A1%80/1-pytorch%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/","excerpt":"","text":"0 导库123456import torchfrom torch import nnfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision.transforms import ToTensor, Lambda, Composeimport matplotlib.pyplot as plt 1 数据准备torchvision.datasets模块包含了许多真实世界的视觉数据的数据集对象，如CIFAR、COCO。以下通过datasets在线加载FashionMNIST数据集。 123456789101112131415# Download training data from open datasets.training_data = datasets.FashionMNIST( root=&quot;data&quot;, train=True, download=True, transform=ToTensor(),)# Download test data from open datasets.test_data = datasets.FashionMNIST( root=&quot;data&quot;, train=False, download=True, transform=ToTensor(),) 将dataset装载入DataLoader中，DataLoader可认为是一个数据迭代器，其支持数据的自动批处理、采样、洗牌和多进程数据加载。这里定义一个 batch&#x3D;64，即dataloader可迭代的每个元素将返回一个批次，包括64个元素的特征和标签。 123456789batch_size = 64# Create data loaders.train_dataloader = DataLoader(training_data, batch_size=batch_size)test_dataloader = DataLoader(test_data, batch_size=batch_size)for X, y in test_dataloader: print(&quot;Shape of X [N, C, H, W]: &quot;, X.shape) print(&quot;Shape of y: &quot;, y.shape, y.dtype) break 2 创建模型为了在PyTorch中定义一个神经网络，我们创建一个继承自nn.Module的类。我们在__init__函数中定义网络的层，并在forward函数中指定数据将如何通过网络。为了加速神经网络的操作，如果有GPU的话，我们把它移到GPU上。 1234567891011121314151617181920212223# Get cpu or gpu device for training.device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;# Define modelclass NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10) ) def forward(self, x): x = self.flatten(x) logits = self.linear_relu_stack(x) return logitsmodel = NeuralNetwork().to(device)print(model) 3 优化模型参数3.1 模型训练函数12345678910111213141516171819202122loss_fn = nn.CrossEntropyLoss()optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)def train(dataloader, model, loss_fn, optimizer): size = len(dataloader.dataset) model.train() for batch, (X, y) in enumerate(dataloader): X, y = X.to(device), y.to(device) # Compute prediction error pred = model(X) loss = loss_fn(pred, y) # Backpropagation optimizer.zero_grad() loss.backward() optimizer.step() if batch % 100 == 0: loss, current = loss.item(), batch * len(X) print(f&quot;loss: &#123;loss:&gt;7f&#125; [&#123;current:&gt;5d&#125;/&#123;size:&gt;5d&#125;]&quot;) 3.2 模型评估函数1234567891011121314def test(dataloader, model, loss_fn): size = len(dataloader.dataset) num_batches = len(dataloader) model.eval() test_loss, correct = 0, 0 with torch.no_grad(): for X, y in dataloader: X, y = X.to(device), y.to(device) pred = model(X) test_loss += loss_fn(pred, y).item() correct += (pred.argmax(1) == y).type(torch.float).sum().item() test_loss /= num_batches correct /= size print(f&quot;Test Error: \\n Accuracy: &#123;(100*correct):&gt;0.1f&#125;%, Avg loss: &#123;test_loss:&gt;8f&#125; \\n&quot;)1 3.3 启动训练&amp;评估123456epochs = 5for t in range(epochs): print(f&quot;Epoch &#123;t+1&#125;\\n-------------------------------&quot;) train(train_dataloader, model, loss_fn, optimizer) test(test_dataloader, model, loss_fn)print(&quot;Done!&quot;) 4 保存模型12torch.save(model.state_dict(), &quot;model.pth&quot;)print(&quot;Saved PyTorch Model State to model.pth&quot;) 5 加载模型12model = NeuralNetwork()model.load_state_dict(torch.load(&quot;model.pth&quot;)) 6 模型推理12345678910111213141516171819classes = [ &quot;T-shirt/top&quot;, &quot;Trouser&quot;, &quot;Pullover&quot;, &quot;Dress&quot;, &quot;Coat&quot;, &quot;Sandal&quot;, &quot;Shirt&quot;, &quot;Sneaker&quot;, &quot;Bag&quot;, &quot;Ankle boot&quot;,]model.eval()x, y = test_data[0][0], test_data[0][1]with torch.no_grad(): pred = model(x) predicted, actual = classes[pred[0].argmax(0)], classes[y] print(f&#x27;Predicted: &quot;&#123;predicted&#125;&quot;, Actual: &quot;&#123;actual&#125;&quot;&#x27;)","categories":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-07-21T10:28:18.087Z","updated":"2023-07-23T10:23:20.541Z","comments":true,"path":"2023/07/21/hello-world/","link":"","permalink":"http://example.com/2023/07/21/hello-world/","excerpt":"","text":"今天坑坑洼洼可算是把网站给搭好了，看着简洁漂亮的首页，想着以后就有专属自己的网站，就很开心。背景图是《权游》里面的某一幕的简画，守夜人面对夜鬼的来袭，背水一战，颇为壮观。 为什么要做个人博客呢？说实话，没有特别的理由。或许是出于新鲜感；或许是工作太无聊；或许是外界太嘈杂，想在数字世界中寻找一片净土；或许是想把有趣的、新奇的东西系统地放进来，有一天可以带朋友来参观，看！这是我曾经的快乐和珍藏。 现实世界有太多约束，说话做事写文章处处存在隐形的规矩，这些规矩容易消磨本身藏在事物的乐趣。我想，在这里就少点规矩吧，说说废话，吹吹牛逼又怎么样呢？有时候写点生活感悟也不怕别人说我假正经。嗯，没错，这是我的展厅！当然，对于涉及实操性或理论性的文章，行文还是遵从逻辑，便于理解和回顾。 那么，第一篇写点啥呢，emmm…","categories":[{"name":"建站","slug":"建站","permalink":"http://example.com/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"建站","slug":"建站","permalink":"http://example.com/tags/%E5%BB%BA%E7%AB%99/"}]}],"categories":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"http://example.com/categories/ROS2%E5%9F%BA%E7%A1%80/"},{"name":"哲学笔记","slug":"哲学笔记","permalink":"http://example.com/categories/%E5%93%B2%E5%AD%A6%E7%AC%94%E8%AE%B0/"},{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/categories/Pytorch%E5%9F%BA%E7%A1%80/"},{"name":"建站","slug":"建站","permalink":"http://example.com/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"ROS2基础","slug":"ROS2基础","permalink":"http://example.com/tags/ROS2%E5%9F%BA%E7%A1%80/"},{"name":"哲学笔记","slug":"哲学笔记","permalink":"http://example.com/tags/%E5%93%B2%E5%AD%A6%E7%AC%94%E8%AE%B0/"},{"name":"Pytorch基础","slug":"Pytorch基础","permalink":"http://example.com/tags/Pytorch%E5%9F%BA%E7%A1%80/"},{"name":"建站","slug":"建站","permalink":"http://example.com/tags/%E5%BB%BA%E7%AB%99/"}]}